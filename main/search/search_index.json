{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Mindtrace","text":"<p>Unifying asset inspection under a single package, Mindtrace brings together industrial hardware, machine learning, and automation, bridging the gap between edge devices and scalable intelligence.</p> <p>Monitor, automate, and scale your on-prem AI solutions effortlessly with Mindtrace package. From training robust AI models, hardware integration to deploying and scaling edge intelligence for Asset inspection, Mindtrace enables full-cycle orchestration.  </p> <p>It seamlessly connects hardware, data, and machine learning, empowering teams to deploy context-aware decision systems, derive real-time insights, and visualize results through interactive dashboards</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p> Unified Architecture     Integrates data ingestion, model training, deployment, and system coordination under one modular ecosystem that scales seamlessly across services and clusters.</p> </li> <li> <p> Hardware-Aware Intelligence     Connect directly to PLCs, cameras, and sensors for real-time inference, control, and closed-loop feedback across industrial environments.</p> </li> <li> <p> ML-Native Design     Provides end-to-end pipelines for dataset management, model registry, and distributed training workflows.</p> </li> <li> <p> Datalake Integration     Built-in connectors and APIs for storing, indexing, and retrieving structured or unstructured data \u2014 powering analytics, retraining, and traceability.</p> </li> <li> <p> Cluster-Aware Orchestration     Enables coordinated operation across multiple nodes or services, supporting distributed execution and horizontal scaling.</p> </li> <li> <p> Service Collaboration Layer     Seamlessly launch, register, and interconnect FastAPI or MCP-based microservices through a unified control plane and shared state system.</p> </li> </ul>"},{"location":"#layered-architecture","title":"Layered Architecture","text":"<p>Mindtrace is organized into a layered workspace to support ML components as Python modules with clearly defined boundaries and dependencies. We use a level-based system for organizing modules based on dependency direction and build order.</p>"},{"location":"#level-1-core","title":"Level 1: Core","text":"<ul> <li><code>core</code>: Foundational utilities and base classes used across all other modules.</li> </ul>"},{"location":"#level-2-core-consumers","title":"Level 2: Core Consumers","text":"<ul> <li><code>jobs</code>: Job execution and backend interfaces.</li> <li><code>registry</code>: Artifact and metadata management.</li> <li><code>database</code>: Redis, Mongo, and DB access layers.</li> <li><code>services</code>: Service base classes, authentication, and gateways.</li> <li><code>storage</code>: Storage functionality for cloud storage integration.</li> <li><code>ui</code>: Optional UI libraries and components.</li> </ul>"},{"location":"#level-3-infrastructure-modules","title":"Level 3: Infrastructure Modules","text":"<ul> <li><code>hardware</code>: Interfaces for cameras, PLCs, scanners, etc.</li> <li><code>cluster</code>: Runtime cluster management, nodes, and workers.</li> <li><code>datalake</code>: Dataset interfaces for HuggingFace and Mindtrace datasets.</li> <li><code>models</code>: Core model definitions and leaderboard utilities.</li> </ul>"},{"location":"#level-4-automation","title":"Level 4: Automation","text":"<ul> <li><code>automation</code>: Integration of pipelines and orchestration using level 2\u20133 modules.</li> </ul>"},{"location":"#level-5-applications","title":"Level 5: Applications","text":"<ul> <li><code>apps</code>: End-user applications composed of all previous levels.</li> <li>E.g., Demo pipelines</li> </ul>"},{"location":"#dependency-flow","title":"Dependency Flow","text":"<p>Each layer only depends on modules in lower levels.</p> Module Depends On <code>core</code> \u2013 <code>jobs</code> <code>core</code> <code>registry</code> <code>core</code> <code>database</code> <code>core</code>, <code>registry</code> <code>services</code> <code>core</code> <code>storage</code> \u2013 <code>ui</code> <code>core</code> <code>cluster</code> <code>core</code>, <code>jobs</code>, <code>registry</code>, <code>database</code>, <code>services</code> <code>datalake</code> <code>core</code>, <code>registry</code>, <code>database</code>, <code>services</code> <code>models</code> <code>core</code>, <code>registry</code>, <code>services</code> <code>hardware</code> <code>core</code>, <code>services</code>, <code>storage</code> <code>automation</code> <code>core</code>, <code>registry</code>, <code>database</code>, <code>services</code>, <code>datalake</code>, <code>models</code>, <code>cluster</code> <code>apps</code> <code>core</code>, <code>registry</code>, <code>database</code>, <code>services</code>, <code>datalake</code>, <code>models</code>, <code>cluster</code>, <code>jobs</code>, <code>hardware</code>, <code>ui</code>, <code>automation</code>"},{"location":"#useful-links","title":"Useful Links","text":"<ul> <li> GitHub Repository</li> <li> PyPI Package</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Install the full Mindtrace package\nuv add mindtrace\n\n# Or install a minimal dependency chain\nuv add mindtrace-datalake\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>from mindtrace import core, registry, database, services\n</code></pre>"},{"location":"#contribute","title":"Contribute","text":"<p>We welcome contributions! Whether you're fixing bugs, adding features, or improving documentation, your help makes Mindtrace better.</p> <ul> <li> Contributing Guide - Learn how to get started</li> <li> GitHub Issues - Report bugs or suggest features</li> <li> Pull Requests - Submit your contributions</li> </ul>"},{"location":"cluster/","title":"Cluster","text":""},{"location":"cluster/#mindtrace-cluster-module","title":"Mindtrace Cluster Module","text":"<p>The Mindtrace Cluster module provides a distributed computing framework for managing and orchestrating jobs across multiple worker nodes. It enables scalable, fault-tolerant job execution with support for various execution environments including Git repositories and Docker containers.</p>"},{"location":"cluster/#overview","title":"Overview","text":"<p>The cluster module consists of three main components:</p> <ul> <li>ClusterManager: Central orchestrator that manages job distribution and worker coordination</li> <li>Node: Worker node that can launch and manage workers</li> <li>Worker: Executable units that process jobs</li> </ul>"},{"location":"cluster/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ClusterManager \u2502    \u2502      Node       \u2502    \u2502     Worker      \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 Job routing   \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Worker launch \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Job execution \u2502\n\u2502 \u2022 Status tracking\u2502    \u2502 \u2022 Registry access\u2502    \u2502 \u2022 Environment mgmt\u2502\n\u2502 \u2022 Worker mgmt   \u2502    \u2502 \u2022 Resource mgmt \u2502    \u2502 \u2022 Status reporting\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"cluster/#core-components","title":"Core Components","text":""},{"location":"cluster/#clustermanager","title":"ClusterManager","text":"<p>The central orchestrator that: - Routes jobs to appropriate endpoints or workers - Tracks job and worker status - Manages worker registration and auto-connection - Provides a unified API for job submission and monitoring</p> <p>Key Features: - Job schema targeting (direct endpoint routing vs orchestrator) - Worker type registration with Git/Docker support - Automatic worker-to-job schema connection - Real-time status monitoring</p>"},{"location":"cluster/#node","title":"Node","text":"<p>A worker node that: - Launches workers from the registry - Manages worker lifecycle - Provides resource isolation</p> <p>Key Features: - Worker registry integration - Automatic cluster registration - Worker process management</p>"},{"location":"cluster/#worker","title":"Worker","text":"<p>Executable units that: - Process individual jobs - Report status back to cluster - Support various execution environments</p> <p>Key Features: - Abstract base class for custom workers - Built-in status tracking - Cluster communication - Environment management</p>"},{"location":"cluster/#built-in-workers","title":"Built-in Workers","text":""},{"location":"cluster/#echoworker","title":"EchoWorker","text":"<p>A simple worker that echoes messages with optional delay:</p> <pre><code>from mindtrace.cluster.workers.echo_worker import EchoWorker\n\n# Usage\nworker = EchoWorker()\nresult = worker._run({\"message\": \"Hello World\", \"delay\": 2})\n# Returns: {\"status\": \"completed\", \"output\": {\"echoed\": \"Hello World\"}}\n</code></pre>"},{"location":"cluster/#runscriptworker","title":"RunScriptWorker","text":"<p>A worker that executes scripts in isolated environments. For git repositories, will sync the environment using <code>uv sync</code>.</p> <pre><code>from mindtrace.cluster.workers.run_script_worker import RunScriptWorker\n\n# Git environment example\njob_data = {\n    \"environment\": {\n        \"git\": {\n            \"repo_url\": \"https://github.com/user/repo\",\n            \"branch\": \"main\",\n            \"working_dir\": \"scripts\"\n        }\n    },\n    \"command\": \"python process_data.py\"\n}\n\n# Docker environment example\njob_data = {\n    \"environment\": {\n        \"docker\": {\n            \"image\": \"python:3.9\",\n            \"working_dir\": \"/app\",\n            \"volumes\": {\"/host/path\": \"/container/path\"},\n            \"environment\": {\"ENV_VAR\": \"value\"}\n        }\n    },\n    \"command\": \"python script.py\"\n}\n</code></pre>"},{"location":"cluster/#usage-examples","title":"Usage Examples","text":""},{"location":"cluster/#basic-cluster-setup","title":"Basic Cluster Setup","text":"<pre><code>from mindtrace.cluster import ClusterManager, Node\nfrom mindtrace.jobs import JobSchema, job_from_schema\n\n# Launch cluster manager\ncluster = ClusterManager.launch(host=\"localhost\", port=8002)\n\n# Launch node\nnode = Node.launch(\n    host=\"localhost\", \n    port=8003, \n    cluster_url=str(cluster.url)\n)\n\n# Register worker type\ncluster.register_worker_type(\n    worker_name=\"myworker\",\n    worker_class=\"myapp.workers.MyWorker\",\n    worker_params={}\n)\n\n# Launch worker\nworker_url = \"http://localhost:8004\"\nnode.launch_worker(worker_type=\"myworker\", worker_url=worker_url)\n\n# Submit job\njob = job_from_schema(my_job_schema, input_data={\"key\": \"value\"})\nresult = cluster.submit_job(job)\n</code></pre>"},{"location":"cluster/#gateway-mode","title":"Gateway Mode","text":"<p>Use ClusterManager as a gateway to route requests:</p> <pre><code>from mindtrace.cluster import ClusterManager\n\n# Launch as gateway\ngateway = ClusterManager.launch(port=8097)\n\n# Register service\ngateway.register_job_to_endpoint(\n    job_type=\"echo_job\", \n    endpoint=\"echo/run\"\n)\n\n# Submit job (automatically routed to endpoint)\njob = job_from_schema(echo_job_schema, input_data={\"message\": \"Hello\"})\nresult = gateway.submit_job(job)\n</code></pre>"},{"location":"cluster/#git-based-worker","title":"Git-based Worker","text":"<p>Launch workers from Git repositories:</p> <pre><code># Register worker from Git\ncluster.register_worker_type(\n    worker_name=\"gitworker\",\n    worker_class=\"myapp.worker.MyWorker\",\n    worker_params={},\n    git_repo_url=\"https://github.com/user/worker-repo\",\n    git_branch=\"main\",\n    git_working_dir=\"worker\"\n)\n\n# Launch worker (automatically clones repo)\nnode.launch_worker(worker_type=\"gitworker\", worker_url=\"http://localhost:8005\")\n</code></pre>"},{"location":"cluster/#configuration","title":"Configuration","text":""},{"location":"cluster/#environment-variables","title":"Environment Variables","text":"<pre><code># Redis configuration\nMINDTRACE_CLUSTER__DEFAULT_REDIS_URL=redis://localhost:6379\nMINDTRACE_WORKER__DEFAULT_REDIS_URL=redis://localhost:6379\n\n# MinIO configuration (for worker registry)\nMINDTRACE_CLUSTER__MINIO_ENDPOINT=localhost:9000\nMINDTRACE_CLUSTER__MINIO_ACCESS_KEY=minioadmin\nMINDTRACE_CLUSTER__MINIO_SECRET_KEY=minioadmin\nMINDTRACE_CLUSTER__MINIO_BUCKET=workers\n</code></pre>"},{"location":"cluster/#database-models","title":"Database Models","text":"<p>The cluster uses several database models for tracking:</p> <ul> <li>JobStatus: Tracks job execution status and results</li> <li>JobSchemaTargeting: Maps job types to endpoints</li> <li>WorkerStatus: Tracks worker availability and current job</li> <li>WorkerAutoConnect: Maps worker types to job schemas</li> <li>WorkerStatusLocal: Local worker status tracking</li> </ul>"},{"location":"cluster/#api-reference","title":"API Reference","text":"<p>Since these are Services, the normal way to use them is via a ConnectionManager, but they can also be accessed dirctly.</p>"},{"location":"cluster/#clustermanager-endpoints","title":"ClusterManager Endpoints","text":"<ul> <li><code>POST /submit_job</code> - Submit a job for execution</li> <li><code>POST /register_job_to_endpoint</code> - Route job type to specific endpoint</li> <li><code>POST /register_job_to_worker</code> - Connect job type to worker</li> <li><code>POST /get_job_status</code> - Get job execution status</li> <li><code>POST /register_worker_type</code> - Register new worker type</li> <li><code>POST /launch_worker</code> - Launch worker on node, automatically connecting it to the Orchestrator if it's registered to a job type</li> <li><code>POST /get_worker_status</code> - Get worker status</li> <li><code>POST /query_worker_status</code> - Query live worker status</li> </ul>"},{"location":"cluster/#node-endpoints","title":"Node Endpoints","text":"<ul> <li><code>POST /launch_worker</code> - Launch worker from registry</li> </ul>"},{"location":"cluster/#worker-endpoints","title":"Worker Endpoints","text":"<ul> <li><code>POST /run</code> - Execute a job</li> <li><code>POST /connect_to_cluster</code> - Connect to cluster orchestrator</li> <li><code>POST /get_status</code> - Get worker status</li> <li><code>POST /start</code> - Initialize worker</li> </ul>"},{"location":"cluster/#examples","title":"Examples","text":"<p>See the <code>samples/cluster/</code> directory for examples:</p> <ul> <li><code>cluster_as_gateway.py</code> - Using ClusterManager as a gateway</li> <li><code>cluster_with_node.py</code> - Basic cluster with node setup</li> <li><code>cluster_with_node_autoregister.py</code> - Automatic worker registration</li> <li><code>run_script/</code> - RunScriptWorker examples</li> <li><code>multiprocess/</code> - Multi-process cluster examples</li> <li><code>separate_node/</code> - Distributed node examples</li> </ul>"},{"location":"cluster/api/","title":"Cluster Package API Reference","text":""},{"location":"core/","title":"Core","text":""},{"location":"core/#mindtrace-core","title":"Mindtrace Core","text":"<p>The foundational module of the Mindtrace ML framework, providing essential utilities, base classes, and core abstractions used across all other Mindtrace modules.</p>"},{"location":"core/#purpose","title":"Purpose","text":"<p><code>mindtrace-core</code> serves as the foundation layer (Level 1) in the Mindtrace architecture, offering:</p> <ul> <li>Base Classes: Abstract base classes and metaclasses for consistent architecture</li> <li>Configuration Management: Centralized configuration handling</li> <li>Event System: Observable patterns and event bus for inter-component communication</li> <li>Utilities: Common utility functions for dynamic imports, type checking, and more</li> <li>Logging: Structured logging capabilities</li> </ul>"},{"location":"core/#installation","title":"Installation","text":"<pre><code># Install as standalone package\nuv add mindtrace-core\n\n# Or install as part of full Mindtrace\nuv add mindtrace\n</code></pre>"},{"location":"core/#architecture","title":"Architecture","text":"<p>The core module is organized into several submodules:</p>"},{"location":"core/#base-classes-base","title":"Base Classes (<code>base/</code>)","text":"<ul> <li><code>MindtraceABC</code>: Abstract base class for all Mindtrace components</li> <li><code>MindtraceMeta</code>: Metaclass providing common functionality</li> <li><code>Mindtrace</code>: Main base class with core functionality</li> </ul>"},{"location":"core/#configuration-config","title":"Configuration (<code>config/</code>)","text":"<ul> <li><code>Config</code>: Centralized configuration management system</li> </ul>"},{"location":"core/#observables-observables","title":"Observables (<code>observables/</code>)","text":"<ul> <li><code>EventBus</code>: Publish-subscribe event system</li> <li><code>ObservableContext</code>: Context management with observation capabilities</li> <li><code>ContextListener</code>: Event listening and handling</li> </ul>"},{"location":"core/#utilities-utils","title":"Utilities (<code>utils/</code>)","text":"<ul> <li><code>checks</code>: Type checking and validation utilities</li> <li><code>dynamic</code>: Dynamic class instantiation and import helpers</li> </ul>"},{"location":"core/#logging-logging","title":"Logging (<code>logging/</code>)","text":"<ul> <li>Structured logging configuration and utilities</li> </ul>"},{"location":"core/#core-classes","title":"Core Classes","text":""},{"location":"core/#mindtrace","title":"<code>Mindtrace</code>","text":"<p>Base class for all Mindtrace components.</p> <pre><code>class MyProcessor(Mindtrace):\n    def __init__(self):\n        super().__init__()\n</code></pre>"},{"location":"core/#config","title":"<code>Config</code>","text":"<p>The Config class in Mindtrace provides a configuration layer designed to unify various sources of configuration\u2014 Pydantic models, Settings, Dict objects in a single, easy-to-use object with attribute access, and dynamic overrides.</p> <pre><code>from mindtrace.core.config import Config\n\n# Pass a dictionary\nconfig = Config({\"MINDTRACE_DIR_PATHS\":{\"TEMP\":\"~/tmp\"}})\n\n# Access config values\nprint(config[\"MINDTRACE_DIR_PATHS\"][\"TEMP\"])      \n# Attribute-style access\nprint(config.MINDTRACE_DIR_PATHS.TEMP)\n</code></pre> <p>For detailed usage of the Config class\u2014including how it's used within the Mindtrace class\u2014refer to the Usage documentation</p>"},{"location":"core/#logging","title":"<code>Logging</code>","text":"<p>The <code>get_logger</code> function provides a unified way to configure logging across your application. It can return either a standard Python logger or a structlog  logger, based on user-defined arguments or below CoreConfig settings (lower priority). <pre><code>[MINDTRACE_DIR_PATHS]\nSTRUCT_LOGGER_DIR = ${MINDTRACE_DIR_PATHS:ROOT}/structlogs\nLOGGER_DIR = ${MINDTRACE_DIR_PATHS:ROOT}/logs\n[MINDTRACE_LOGGER]\nUSE_STRUCTLOG = False\n</code></pre></p>"},{"location":"core/#basic-logger","title":"Basic Logger","text":"<p>Setup basic logger to produce logs in <code>~/.cache/mindtrace/logs</code>.  Here, by default propogation is set to true, and you should be able to see logs in <code>tail -f ~/.cache/mindtrace/logs/mindtrace.log</code> and <code>tail -f ~/.cache/mindtrace/logs/modules/mindtrace.core.module.log</code> files</p> <pre><code>from mindtrace.core.logging.logger import get_logger\n\n# Create a standard logger\nlogger = get_logger(\"core.module\")\nlogger.info(\"Logger configured with custom settings.\")\n</code></pre>"},{"location":"core/#structured-logger","title":"Structured Logger","text":"<p>Setup structlog to log structured events: dictionaries of key-value pairs that can later be searched, filtered, or transformed (e.g., into JSON). Here, by default propogation is set to true, and you should be able to see structured logs in <code>tail -f ~/.cache/mindtrace/structlogs/mindtrace.log</code> and <code>tail -f ~/.cache/mindtrace/structlogs/modules/mindtrace.core.module.log</code> files <pre><code>from mindtrace.core.logging.logger import get_logger\n\n# Create a structlog logger with custom bindings\nslogger = get_logger(\n    \"core.module\",\n    use_structlog=True,\n    structlog_bind={\"service\": \"my-service\"},\n)\n\nslogger.info(\"Structured log\", user_id=\"123\")\n</code></pre> In above example, we illustrate structlog\u2019s ability to  - bind context to a logger, which ensures that certain fields are automatically included in every log message. This is especially useful for adding consistent metadata like service name, environment, or version without repeating it in every log call. - Extra fields like user_id=\"123\" can be passed per log call, allowing dynamic, event-specific data to be added.</p>"},{"location":"core/#mindtrace-autolog","title":"Mindtrace autolog","text":"<p><code>Mindtrace.autolog</code> automatically logs function execution (start, end, duration, exceptions, and optional system metrics). It supports sync, async, and static functions with both standard and structured logging formats. See a full usage example here</p> <pre><code>from mindtrace.core import Mindtrace\n\nclass DataProcessor(Mindtrace):\n    @Mindtrace.autolog()\n    def process_data(self, data_list, batch_size=100):\n        # Function automatically logged\n        return [item * 2 for item in data_list]\n</code></pre>"},{"location":"core/#observables","title":"Observables","text":"<p>The Observables module enables lightweight observability and reactivity for class objects, automatically turning selected properties into observable variables. This framework allows external components (listeners) to be notified whenever specific values change, without hard-coding the coupling between the source and observers.</p> <p>There are three main classes included in the <code>observables</code> module:</p>"},{"location":"core/#1-eventbus","title":"1. <code>EventBus</code>","text":"<p>The <code>EventBus</code> is a lightweight internal publish-subscribe system for event dispatching. </p> <p>API:</p> <p>Event buses expose three main methods, which may be used to <code>subscribe</code>/<code>unsubscribe</code> individual listeners and <code>emit</code> event messages.</p> <pre><code>subscribe(handler: Callable, event_name: str) -&gt; str\nunsubscribe(handler_or_id: Union[str, Callable], event_name: str)\nemit(event_name: str, **kwargs)\n</code></pre> <p>Example Usage: To use an event bus, subscribe a handler to the bus with an associated event name. The handler will be called any time the event name is emitted. </p> <pre><code>from mindtrace.core import EventBus\n\nbus = EventBus()    \n\ndef handler(**kwargs):\n    print(kwargs)\n\nbus.subscribe(handler, \"event\")\nbus.emit(\"event\", x=\"1\", y=\"2\")  # {'x': '1', 'y': '2'}\n\nbus.unsubscribe(handler, \"event\")\nbus.emit(\"event\", x=\"1\", y=\"2\")  # No output\n</code></pre>"},{"location":"core/#2-observablecontext","title":"2. <code>ObservableContext</code>","text":"<p>The <code>ObservableContext</code> class decorator automatically turns specified properties into observable fields and wires up listener support.</p> <p>The <code>ObservableContext</code> class supports two specific event types, with associated event names:</p> <ol> <li><code>context_updated(source: str, var: str, old: any, new: any)</code>: May be used when any observed variable changes. The name of the variable will be given as the <code>var</code> argument, with associated old and new values.</li> <li><code>{var}_updated(source: str, old: any, new: any)</code>: May be used to listen to specific variables. </li> </ol> <p>API:</p> <p>The <code>ObservableContext</code> decorator adds <code>subscribe</code> and <code>unsubscribe</code> methods onto a wrapped class, which may be used directly analogously to with the <code>EventBus</code>.</p> <pre><code>subscribe(handler, event_name)\nunsubscribe(handler_or_id, event_name)\n</code></pre> <p>Example Usage:</p> <p>When subscribing a class-derived listener, define a <code>context_updated</code> method which will be notified anytime any observable variable is updated, or specific <code>{var}_updated</code> methods, which will be notified when the associated variable is updated.</p> <pre><code>class MyListener:\n    def context_updated(self, source, var, old, new):  # May be omitted, `{var}_updated` methods will be called automatically\n        if var == \"x\":\n            return self.x_updated(source, old, new)\n        elif var == \"y\":\n            return self.y_updated(source, old, new)\n    def x_updated(...): ...\n    def y_updated(...): ...\n</code></pre> <p>Listeners may subscribe to any class that has been decorated with the <code>ObservableContext</code> decorator, listening to any of the listed <code>vars</code> in the decorator.</p> <pre><code>from mindtrace.core import ObservableContext\n\n@ObservableContext(vars=[\"x\", \"y\"])\nclass MyContext:\n    def __init__(self):\n        self.x = 0\n        self.y = 0\n\nclass MyListener:\n    def x_changed(self, source, old, new):\n        print(f\"[{source}] x changed from {old} to {new}\")\n\nmy_context = MyContext()\nmy_context.subscribe(MyListener())\n\nmy_context.x = 1  # [MyContext] x changed from 0 to 1\n</code></pre>"},{"location":"core/#3-contextlistenermindtrace","title":"3. <code>ContextListener(Mindtrace)</code>","text":"<p>The <code>ContextListener</code> class is a helper class for defining observers that respond to context changes. This class is meant to provide two benefits: (1) deriving from the <code>Mindtrace</code> base class, it provides for uniform logging of events and (2) the default ContextListener class can be used to automatically log changes to variables, optionally with a custom logger.</p> <p>Example usage: <pre><code>from mindtrace.core import ContextListener, ObservableContext\n\n@ObservableContext(vars={\"x\": int, \"y\": int})\nclass MyContext:\n    def __init__(self):\n        self.x = 0\n        self.y = 0\n\nmy_context = MyContext()\nmy_context.subscribe(ContextListener(autolog=[\"x\", \"y\"], logger=...))  # May provide custom logger if desired\n\nmy_context.x = 1\nmy_context.y = 2\n\n# Logs:\n# [MyContext] x changed: 0 \u2192 1\n# [MyContext] y changed: 0 \u2192 2  \n</code></pre></p>"},{"location":"core/#utility-functions","title":"Utility Functions","text":""},{"location":"core/#check_libslibs","title":"<code>check_libs(*libs)</code>","text":"<p>Verify required libraries are installed.</p> <pre><code>from mindtrace.core import check_libs\ncheck_libs(\"numpy\", \"pandas\")  # Raises ImportError if missing\n</code></pre>"},{"location":"core/#ifnonevalue-default","title":"<code>ifnone(value, default)</code>","text":"<p>Return default if value is None.</p> <pre><code>from mindtrace.core import ifnone\nresult = ifnone(potentially_none_value, \"default\")\n</code></pre>"},{"location":"core/#instantiate_targettarget-kwargs","title":"<code>instantiate_target(target, **kwargs)</code>","text":"<p>Dynamically instantiate a class from string reference.</p> <pre><code>from mindtrace.core import instantiate_target\ninstance = instantiate_target(\"my.module.MyClass\", param=\"value\")\n</code></pre>"},{"location":"core/api/","title":"Core Package API Reference","text":""},{"location":"core/api/#base-classes","title":"Base Classes","text":"<p>Mindtrace class. Provides unified configuration, logging and context management.</p>"},{"location":"core/api/#mindtrace.core.base.mindtrace_base.MindtraceMeta","title":"MindtraceMeta","text":"<pre><code>MindtraceMeta(name, bases, attr_dict)\n</code></pre> <p>               Bases: <code>type</code></p> <p>Metaclass for Mindtrace class.</p> <p>The MindtraceMeta metaclass enables classes deriving from Mindtrace to automatically use the same default logger within class methods as it does within instance methods. i.e. consider the following class:</p> Usage <pre><code>from mindtrace.core import Mindtrace\n\nclass MyClass(Mindtrace):\n    def __init__(self):\n        super().__init__()\n\n    def instance_method(self):\n        self.logger.info(f\"Using logger: {self.logger.name}\")  # Using logger: mindtrace.my_module.MyClass\n\n    @classmethod\n    def class_method(cls):\n        cls.logger.info(f\"Using logger: {cls.logger.name}\")  # Using logger: mindtrace.my_module.MyClass\n</code></pre>"},{"location":"core/api/#mindtrace.core.base.mindtrace_base.Mindtrace","title":"Mindtrace","text":"<pre><code>Mindtrace(\n    suppress: bool = False,\n    *,\n    config_overrides: SettingsLike | None = None,\n    **kwargs\n)\n</code></pre> <p>Base class for all Mindtrace package core classes.</p> <p>The Mindtrace class adds default context manager and logging methods. All classes that derive from Mindtrace can be used as context managers and will use a unified logging format.</p> <p>The class automatically provides logging capabilities for both class methods and instance methods. For example:</p> Usage <pre><code>from mindtrace.core import Mindtrace\n\nclass MyClass(Mindtrace):\n    def __init__(self):\n        super().__init__()\n\n    def instance_method(self):\n        self.logger.info(f\"Using logger: {self.logger.name}\")  # Using logger: mindtrace.my_module.MyClass\n\n    @classmethod\n    def class_method(cls):\n        cls.logger.info(f\"Using logger: {cls.logger.name}\")  # Using logger: mindtrace.my_module.MyClass\n</code></pre> <p>The logging functionality is automatically provided through the MindtraceMeta metaclass, which ensures consistent logging behavior across all method types.</p> <p>Initialize the Mindtrace object.</p> <p>Parameters:</p> Name Type Description Default <code>suppress</code> <code>bool</code> <p>Whether to suppress exceptions in context manager use.</p> <code>False</code> <code>config_overrides</code> <code>SettingsLike | None</code> <p>Additional settings to override the default config.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments. Logger-related kwargs are passed to <code>get_logger</code>. Valid logger kwargs: log_dir, logger_level, stream_level, file_level, file_mode, propagate, max_bytes, backup_count</p> <code>{}</code>"},{"location":"core/api/#mindtrace.core.base.mindtrace_base.Mindtrace.autolog","title":"autolog  <code>classmethod</code>","text":"<pre><code>autolog(\n    log_level=logging.DEBUG,\n    prefix_formatter: Optional[Callable] = None,\n    suffix_formatter: Optional[Callable] = None,\n    exception_formatter: Optional[Callable] = None,\n    self: Optional[Mindtrace] = None,\n)\n</code></pre> <p>Decorator that adds logger.log calls to the decorated method before and after the method is called.</p> <p>By default, the autolog decorator will log the method name, arguments and keyword arguments before the method is called, and the method name and result after the method completes. This behavior can be modified by passing in prefix and suffix formatters.</p> <p>The autolog decorator will also catch and log all Exceptions, re-raising any exception after logging it. The behavior for autologging exceptions can be modified by passing in an exception_formatter.</p> <p>The autolog decorator expects a logger to exist at self.logger, and hence can only be used by Mindtrace subclasses or classes that have a logger attribute.</p> <p>Parameters:</p> Name Type Description Default <code>log_level</code> <p>The log_level passed to logger.log().</p> <code>DEBUG</code> <code>prefix_formatter</code> <code>Optional[Callable]</code> <p>The formatter used to log the command before the wrapped method runs. The prefix_formatter will be given (and must accept) three arguments, in the following order: - function: The function being wrapped. - args: The args passed into the function. - kwargs: The kwargs passed into the function.</p> <code>None</code> <code>suffix_formatter</code> <code>Optional[Callable]</code> <p>The formatter used to log the command after the wrapped method runs. The suffix_formatter will be given (and must accept) two arguments, in the following order: - function: The function being wrapped. - result: The result returned from the wrapped method.</p> <code>None</code> <code>exception_formatter</code> <code>Optional[Callable]</code> <p>The formatter used to log any errors. The exception_formatter will be given (and must accept) three arguments, in the following order: - function: The function being wrapped. - error: The caught Exception. - stack trace: The stack trace, as provided by traceback.format_exc().</p> <code>None</code> <code>self</code> <code>Optional[Mindtrace]</code> <p>The instance of the class that the method is being called on. Self only needs to be passed in if the wrapped method does not have self as the first argument. Refer to the example below for more details.</p> <code>None</code> Usage <pre><code>from mindtrace.core import Mindtrace\n\n    class MyClass(Mindtrace):\n        def __init__(self):\n            super().__init__()\n\n        @Mindtrace.autolog()\n        def divide(self, arg1, arg2):\n            self.logger.info(\"We are about to divide\")\n            result = arg1 / arg2\n            self.logger.info(\"We have divided\")\n            return result\n\n    my_instance = MyClass()\n    my_instance.divide(1, 2)\n    my_instance.divide(1, 0)\n</code></pre> <p>The resulting log file should contain something similar to the following:</p> <p><pre><code>    MyClass - DEBUG - Calling divide with args: (1, 2) and kwargs: {}\n    MyClass - INFO - We are about to divide\n    MyClass - INFO - We have divided\n    MyClass - DEBUG - Finished divide with result: 0.5\n    MyClass - DEBUG - Calling divide with args: (1, 0) and kwargs: {}\n    MyClass - INFO - We are about to divide\n    MyClass - ERROR - division by zero\n    Traceback (most recent call last):\n    ...\n</code></pre> If the wrapped method does not have self as the first argument, self must be passed in as an argument to the autolog decorator.</p> Usage <pre><code>    from fastapi import FastAPI\n    from mindtrace.core import Mindtrace\n\n    class MyClass(Mindtrace):\n        def __init__():\n            super().__init__()\n\n        def create_app(self):\n            app_ = FastAPI()\n\n            @Mindtrace.autolog(self=self)  # self must be passed in as an argument as it is not captured in status()\n            @app_.post(\"/status\")\n            def status():\n                return {\"status\": \"Available\"}\n\n            return app_\n</code></pre>"},{"location":"core/api/#mindtrace.core.base.mindtrace_base.MindtraceABCMeta","title":"MindtraceABCMeta","text":"<pre><code>MindtraceABCMeta(name, bases, attr_dict)\n</code></pre> <p>               Bases: <code>MindtraceMeta</code>, <code>ABCMeta</code></p> <p>Metaclass that combines MindtraceMeta and ABC metaclasses.</p> <p>This metaclass resolves metaclass conflicts when creating classes that need to be both abstract (using ABC) and have MindtraceMeta functionality. Python only allows a class to have one metaclass, so this combined metaclass allows classes to inherit from both Mindtrace class and ABC simultaneously.</p> <p>Without this combined metaclass, trying to create a class that inherits from both Mindtrace class and ABC would raise a metaclass conflict error since they each have different metaclasses.</p>"},{"location":"core/api/#mindtrace.core.base.mindtrace_base.MindtraceABC","title":"MindtraceABC","text":"<pre><code>MindtraceABC(*args, **kwargs)\n</code></pre> <p>               Bases: <code>Mindtrace</code>, <code>ABC</code></p> <p>Abstract base class combining Mindtrace class functionality with ABC support.</p> <p>This class enables creating abstract classes that also have access to all Mindtrace features such as logging, configuration, and context management. Use this class instead of Mindtrace when you need to define abstract methods or properties in your class.</p> Usage <pre><code>from mindtrace.core import MindtraceABC\nfrom abc import abstractmethod\n\nclass MyAbstractService(MindtraceABC):\n    def __init__(self):\n        super().__init__()\n\n    @abstractmethod\n    def process_data(self, data):\n        '''Must be implemented by concrete subclasses.'''\n        pass\n</code></pre> Note <p>Without this class, attempting to create a class that inherits from both Mindtrace class and ABC would fail due to metaclass conflicts. MindtraceABC resolves this by using the CombinedABCMeta.</p>"},{"location":"core/api/#configuration-management","title":"Configuration Management","text":""},{"location":"core/api/#mindtrace.core.config.config.Config","title":"Config","text":"<pre><code>Config(\n    extra_settings: SettingsLike = None, *, apply_env_overrides: bool = True\n)\n</code></pre> <p>               Bases: <code>dict</code></p> <p>Unified configuration manager for Mindtrace components.</p> <p>The <code>Config</code> class consolidates configuration from sources including dictionaries, Pydantic <code>BaseSettings</code> or <code>BaseModel</code> objects. It supports user provided arguments and environment variable overrides, path normalization by expanding the <code>~</code> character.</p> <p>Key Features:</p> <ul> <li>Accepts multiple configuration formats: <code>dict</code>, <code>BaseModel</code>, <code>BaseSettings</code>, or lists of these.</li> <li>Attr-style and dict-style access to nested keys.</li> <li>Supports secret fields using <code>pydantic.SecretStr</code>, preserving masking them by default.</li> <li>Overlays environment variables (<code>ENV_VAR__NESTED_KEY</code>) over default configs.</li> <li>Provides cloning, JSON export, and dynamic override capabilities.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>extra_settings</code> <code>SettingsLike</code> <p>Configuration overrides or full config objects. Can be a <code>dict</code>, <code>BaseSettings</code>, <code>BaseModel</code>, or list of any of these.</p> <code>None</code> <code>apply_env_overrides</code> <code>bool</code> <p>Whether to apply environment variable overrides. If True, environment variables will be applied over the default configs. If False, environment variables will not be applied.</p> <code>True</code> <p>Examples:</p> <p>Basic usage with CoreSettings: <pre><code>from mindtrace.core.config import Config, CoreSettings\nconfig = Config(CoreSettings())\nprint(config[\"MINDTRACE_API_KEYS\"][\"OPENAI\"])  # ******** (masked)\nprint(config.get_secret(\"MINDTRACE_API_KEYS\", \"OPENAI\"))  # Real secret value\n</code></pre></p> <p>Load from INI file with overrides: <pre><code>from pathlib import Path\nfrom mindtrace.core.config import Config\nfrom mindtrace.core.utils import load_ini_as_dict\n\ndef my_loader():\n    file_path = Path(\"sample.ini\")\n    return load_ini_as_dict(file_path)\n\ndefaults = my_loader()\noverrides = {\n    \"MINDTRACE_DIR_PATHS\": {\n        \"TEMP_DIR\": \"/tmp/logs\",\n        \"REGISTRY_DIR\": \"/tmp/registry\"\n    }\n}\nconfig = Config.load(defaults=defaults, overrides=overrides)\n</code></pre></p> <p>Access values in multiple ways: <pre><code># Attribute style access\nprint(config.MINDTRACE_DIR_PATHS.TEMP_DIR)\n\n# Dict style access\nprint(config[\"MINDTRACE_DIR_PATHS\"][\"TEMP_DIR\"])\n\n# Get method\nprint(config.get(\"MINDTRACE_DIR_PATHS\").get(\"TEMP_DIR\"))\n</code></pre></p> <p>Save and reload configuration: <pre><code># Save config to JSON\nconfig.save_json(\"saved_config.json\")\n\n# Load config back\nreloaded = Config.load_json(\"saved_config.json\")\n</code></pre></p> <p>Clone config with overrides (original unchanged): <pre><code>cloned = config.clone_with_overrides({\n    \"MINDTRACE_DIR_PATHS\": {\n        \"TEMP_DIR\": \"/tmp/clone/logs\"\n    }\n})\nprint(\"Original:\", config.MINDTRACE_DIR_PATHS.TEMP_DIR)  # Unchanged\nprint(\"Cloned:\", cloned.MINDTRACE_DIR_PATHS.TEMP_DIR)   # New value\n</code></pre></p> <p>Working with secret fields: <pre><code>from pydantic import BaseModel, SecretStr\nfrom mindtrace.core.config import Config\n\nclass APIKeys(BaseModel):\n    OPENAI: SecretStr\n    DISCORD: SecretStr\n\nclass AppSettings(BaseModel):\n    API_KEYS: APIKeys\n\nconfig = Config(AppSettings(API_KEYS=APIKeys(\n    OPENAI=SecretStr(\"sk-abc123\"),\n    DISCORD=SecretStr(\"discord-token\")\n)))\n\n# Access masked values\nprint(config.API_KEYS.OPENAI)           # ********\nprint(config.API_KEYS.DISCORD)          # ********\n\n# Get real secret values\nprint(config.get_secret(\"API_KEYS\", \"OPENAI\"))   # sk-abc123\nprint(config.get_secret(\"API_KEYS\", \"DISCORD\"))  # discord-token\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.config.config.Config.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(\n    *,\n    defaults: Optional[Union[Dict[str, Any], BaseSettings, BaseModel]] = None,\n    overrides: Optional[\n        Union[\n            Dict[str, Any],\n            List[Union[Dict[str, Any], BaseSettings, BaseModel]],\n            BaseSettings,\n            BaseModel,\n        ]\n    ] = None,\n    file_loader: Optional[Callable[[], Dict[str, Any]]] = None\n) -&gt; Config\n</code></pre> <p>Create a Config from optional defaults, optional file loader, and runtime overrides.</p> <p>This is the recommended way to create a Config instance with proper precedence order: 1. File loader (lowest precedence) 2. Defaults 3. Environment variables 4. Runtime overrides (highest precedence)</p> <p>Parameters:</p> Name Type Description Default <code>defaults</code> <code>Optional[Union[Dict[str, Any], BaseSettings, BaseModel]]</code> <p>Base configuration as dict, BaseSettings, or BaseModel</p> <code>None</code> <code>overrides</code> <code>Optional[Union[Dict[str, Any], List[Union[Dict[str, Any], BaseSettings, BaseModel]], BaseSettings, BaseModel]]</code> <p>Runtime overrides that take highest precedence</p> <code>None</code> <code>file_loader</code> <code>Optional[Callable[[], Dict[str, Any]]]</code> <p>Optional callable that returns a dict (e.g., from INI file)</p> <code>None</code> <p>Returns:</p> Type Description <code>Config</code> <p>Config instance with all sources merged</p> <p>Examples:</p> <p>Load from INI file with overrides: <pre><code>from pathlib import Path\nfrom mindtrace.core.config import Config\nfrom mindtrace.core.utils import load_ini_as_dict\n\ndef ini_loader():\n    return load_ini_as_dict(Path(\"config.ini\"))\n\nconfig = Config.load(\n    file_loader=ini_loader,\n    overrides={\"MINDTRACE_DIR_PATHS\": {\"TEMP_DIR\": \"/custom/tmp\"}}\n)\n</code></pre></p> <p>Load with Pydantic model defaults: <pre><code>from pydantic import BaseModel\nfrom mindtrace.core.config import Config\n\nclass MySettings(BaseModel):\n    API_URL: str = \"http://localhost:8000\"\n    DEBUG: bool = False\n\nconfig = Config.load(\n    defaults=MySettings(),\n    overrides={\"DEBUG\": True}\n)\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.config.config.Config.load_json","title":"load_json  <code>classmethod</code>","text":"<pre><code>load_json(path: str | Path) -&gt; Config\n</code></pre> <p>Load configuration from a JSON file with environment variable overrides and secret masking.</p> <p>This method loads configuration data from a JSON file and applies the same processing as the main Config class: environment variable overrides and automatic masking of secret fields.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the JSON file (string or Path object)</p> required <p>Returns:</p> Type Description <code>Config</code> <p>Config instance loaded from the JSON file</p> <p>Examples:</p> <p>Load from JSON file: <pre><code>from mindtrace.core.config import Config\n\n# Load configuration from JSON file\nconfig = Config.load_json(\"config.json\")\nprint(config.MINDTRACE_DIR_PATHS.TEMP_DIR)\n</code></pre></p> <p>Load with environment overrides: <pre><code>import os\nos.environ[\"MINDTRACE_DEFAULT_HOST_URLS__SERVICE\"] = \"http://env-override:8000\"\n\nconfig = Config.load_json(\"config.json\")\n# Environment variable will override the value from JSON\nprint(config.MINDTRACE_DEFAULT_HOST_URLS.SERVICE)  # http://env-override:8000\n</code></pre></p> Note <p>The JSON file should contain the same structure as expected by Config. Secret fields will be automatically masked when accessed normally.</p>"},{"location":"core/api/#mindtrace.core.config.config.Config.save_json","title":"save_json","text":"<pre><code>save_json(\n    path: str | Path, *, reveal_secrets: bool = False, indent: int = 4\n) -&gt; None\n</code></pre> <p>Save configuration to a JSON file with optional secret revelation.</p> <p>This method serializes the current configuration to a JSON file. By default, secret fields are masked (shown as **) for security. You can optionally reveal the actual secret values by setting reveal_secrets=True.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path where to save the JSON file (string or Path object)</p> required <code>reveal_secrets</code> <code>bool</code> <p>If True, writes actual secret values instead of masked ones</p> <code>False</code> <code>indent</code> <code>int</code> <p>JSON indentation level for pretty printing (default: 4)</p> <code>4</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If file writing or JSON serialization fails</p> <p>Examples:</p> <p>Save with masked secrets (default): <pre><code>config = Config(CoreSettings())\nconfig.save_json(\"config.json\")\n# Secret fields will be saved as \"********\"\n</code></pre></p> <p>Save with revealed secrets: <pre><code>config.save_json(\"config.json\", reveal_secrets=True)\n# Secret fields will be saved with actual values\n</code></pre></p> <p>Save with custom indentation: <pre><code>config.save_json(\"config.json\", indent=2)\n</code></pre></p> Note <p>Parent directories are created automatically if they don't exist. Use reveal_secrets=True only when necessary for debugging or migration.</p>"},{"location":"core/api/#mindtrace.core.config.config.Config.to_revealed_strings","title":"to_revealed_strings","text":"<pre><code>to_revealed_strings() -&gt; Dict[str, Any]\n</code></pre> <p>Convert the config to a dictionary with revealed secret values.</p>"},{"location":"core/api/#mindtrace.core.config.config.Config.clone_with_overrides","title":"clone_with_overrides","text":"<pre><code>clone_with_overrides(*overrides: SettingsLike) -&gt; Config\n</code></pre> <p>Return a new Config clone with overrides applied (original remains unchanged).</p> <p>This method creates a deep copy of the current config and applies the provided overrides without modifying the original configuration. Useful for creating temporary configurations or testing different settings.</p> <p>Parameters:</p> Name Type Description Default <code>*overrides</code> <code>SettingsLike</code> <p>Configuration overrides as dict, BaseSettings, BaseModel, or lists of these</p> <code>()</code> <p>Returns:</p> Type Description <code>Config</code> <p>New Config instance with overrides applied</p> <p>Examples:</p> <p>Clone with simple overrides: <pre><code>original = Config({\"API_URL\": \"http://prod:8000\", \"DEBUG\": False})\ncloned = original.clone_with_overrides({\"DEBUG\": True})\n\nprint(original.DEBUG)  # False (unchanged)\nprint(cloned.DEBUG)   # True (new value)\n</code></pre></p> <p>Clone with nested overrides: <pre><code>cloned = config.clone_with_overrides({\n    \"MINDTRACE_DIR_PATHS\": {\n        \"TEMP_DIR\": \"/tmp/testing\",\n        \"REGISTRY_DIR\": \"/tmp/test_registry\"\n    }\n})\n</code></pre></p> <p>Clone with multiple overrides: <pre><code>cloned = config.clone_with_overrides(\n    {\"DEBUG\": True},\n    {\"API_URL\": \"http://test:8000\"},\n    {\"LOGGING_LEVEL\": \"DEBUG\"}\n)\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.config.config.Config.get_secret","title":"get_secret","text":"<pre><code>get_secret(*path: str) -&gt; Optional[str]\n</code></pre> <p>Retrieve a secret by dotted path components.</p> <p>This method accesses the real (unmasked) value of secret fields that were defined using pydantic.SecretStr. The secret values are stored internally and can be retrieved using this method.</p> <p>Parameters:</p> Name Type Description Default <code>*path</code> <code>str</code> <p>Path components to the secret field (e.g., \"API_KEYS\", \"OPENAI\")</p> <code>()</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The real secret value as string, or None if not found</p> <p>Examples:</p> <p>Get OpenAI API key: <pre><code>config = Config(CoreSettings())\napi_key = config.get_secret(\"MINDTRACE_API_KEYS\", \"OPENAI\")\nprint(api_key)  # \"sk-abc123...\" (real value)\n</code></pre> Working with custom secret fields: <pre><code>from pydantic import BaseModel, SecretStr\nfrom mindtrace.core.config import Config\n\nclass APIKeys(BaseModel):\n    OPENAI: SecretStr\n    DISCORD: SecretStr\n\nconfig = Config(APIKeys(\n    OPENAI=SecretStr(\"sk-abc123\"),\n    DISCORD=SecretStr(\"discord-token\")\n))\n\n# Access masked value\nprint(config.OPENAI)  # ********\n\n# Get real value\nprint(config.get_secret(\"OPENAI\"))  # sk-abc123\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.config.config.Config.secret_paths","title":"secret_paths","text":"<pre><code>secret_paths() -&gt; List[str]\n</code></pre> <p>Return dotted paths of fields considered secrets.</p>"},{"location":"core/api/#mindtrace.core.config.config.CoreConfig","title":"CoreConfig","text":"<pre><code>CoreConfig(extra_settings: SettingsLike = None)\n</code></pre> <p>               Bases: <code>Config</code></p> <p>Configuration wrapper that automatically includes CoreSettings with environment variable support.</p> <p>CoreConfig is a convenience class that wraps the base Config class and automatically loads CoreSettings as the default configuration. This includes support for environment variables, .env files, and INI configuration files with automatic path expansion.</p> <p>Parameters:</p> Name Type Description Default <code>extra_settings</code> <code>SettingsLike</code> <p>Additional configuration overrides (highest precedence)</p> <code>None</code> <code>apply_env_overrides</code> <p>Whether to apply environment variable overrides</p> required <p>Examples:</p> <p>Basic usage with default CoreSettings: <pre><code>from mindtrace.core.config import CoreConfig\n\n# Loads CoreSettings with env overrides\nconfig = CoreConfig()\nprint(config.MINDTRACE_DEFAULT_HOST_URLS.SERVICE)\n</code></pre></p> <p>With additional overrides: <pre><code>config = CoreConfig({\n    \"MINDTRACE_DIR_PATHS\": {\n        \"TEMP_DIR\": \"/custom/tmp\"\n    }\n})\n# Override takes precedence over CoreSettings defaults\n</code></pre></p> <p>Environment variable overrides: <pre><code>import os\nos.environ[\"MINDTRACE_DEFAULT_HOST_URLS__SERVICE\"] = \"http://custom:8000\"\n\nconfig = CoreConfig()\n# Environment variable overrides the INI file value\nprint(config.MINDTRACE_DEFAULT_HOST_URLS.SERVICE)  # http://custom:8000\n</code></pre></p> Note <p>Environment variables are applied at the CoreSettings level, not at the Config level. Additional overrides passed to CoreConfig take the highest precedence.</p>"},{"location":"core/api/#logging","title":"Logging","text":""},{"location":"core/api/#mindtrace.core.logging.logger.default_formatter","title":"default_formatter","text":"<pre><code>default_formatter(fmt: Optional[str] = None) -&gt; logging.Formatter\n</code></pre> <p>Create a logging formatter with a standardized default format.</p> <p>This function returns a Python logging Formatter instance configured with a default format string that includes timestamp, log level, logger name, and message. If a custom format string is provided, it will be used instead.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>Optional[str]</code> <p>Optional custom format string. If None, uses the default format: <code>\"[%(asctime)s] %(levelname)s: %(name)s: %(message)s\"</code> - <code>%(asctime)s</code>: Timestamp when the log record was created - <code>%(levelname)s</code>: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) - <code>%(name)s</code>: Name of the logger - <code>%(message)s</code>: The actual log message</p> <code>None</code> <p>Returns:</p> Type Description <code>Formatter</code> <p>logging.Formatter: Configured formatter instance ready to use with handlers.</p> <p>Examples:</p> <p>Use default format: <pre><code>formatter = default_formatter()\nhandler.setFormatter(formatter)\n# Output: [2024-01-15 10:30:45,123] INFO: mindtrace.core: Operation completed\n</code></pre></p> <p>Use custom format: <pre><code>custom_fmt = \"%(levelname)s - %(message)s\"\nformatter = default_formatter(fmt=custom_fmt)\nhandler.setFormatter(formatter)\n# Output: INFO - Operation completed\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.logging.logger.setup_logger","title":"setup_logger","text":"<pre><code>setup_logger(\n    name: str = \"mindtrace\",\n    *,\n    log_dir: Optional[Path] = None,\n    logger_level: int = logging.DEBUG,\n    stream_level: int = logging.ERROR,\n    add_stream_handler: bool = True,\n    file_level: int = logging.DEBUG,\n    file_mode: str = \"a\",\n    add_file_handler: bool = True,\n    propagate: bool = False,\n    max_bytes: int = 10 * 1024 * 1024,\n    backup_count: int = 5,\n    use_structlog: Optional[bool] = None,\n    structlog_json: Optional[bool] = True,\n    structlog_pre_chain: Optional[list] = None,\n    structlog_processors: Optional[list] = None,\n    structlog_renderer: Optional[object] = None,\n    structlog_bind: Optional[object] = None\n) -&gt; Logger | structlog.BoundLogger\n</code></pre> <p>Configure and initialize logging for Mindtrace components programmatically.</p> <p>Sets up a rotating file handler and a console handler on the given logger. Log file defaults to ~/.cache/mindtrace/{name}.log.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Logger name, defaults to \"mindtrace\".</p> <code>'mindtrace'</code> <code>log_dir</code> <code>Optional[Path]</code> <p>Custom directory for log file.</p> <code>None</code> <code>logger_level</code> <code>int</code> <p>Overall logger level.</p> <code>DEBUG</code> <code>stream_level</code> <code>int</code> <p>StreamHandler level (e.g., ERROR).</p> <code>ERROR</code> <code>add_stream_handler</code> <code>bool</code> <p>Whether to add a stream handler.</p> <code>True</code> <code>file_level</code> <code>int</code> <p>FileHandler level (e.g., DEBUG).</p> <code>DEBUG</code> <code>file_mode</code> <code>str</code> <p>Mode for file handler, default is 'a' (append).</p> <code>'a'</code> <code>add_file_handler</code> <code>bool</code> <p>Whether to add a file handler.</p> <code>True</code> <code>propagate</code> <code>bool</code> <p>Whether the logger should propagate messages to ancestor loggers.</p> <code>False</code> <code>max_bytes</code> <code>int</code> <p>Maximum size in bytes before rotating log file.</p> <code>10 * 1024 * 1024</code> <code>backup_count</code> <code>int</code> <p>Number of backup files to retain.</p> <code>5</code> <code>use_structlog</code> <code>Optional[bool]</code> <p>Optional bool. If True, configure and return a structlog BoundLogger.</p> <code>None</code> <code>structlog_json</code> <code>Optional[bool]</code> <p>Optional bool. If True, render JSON; otherwise use console/dev renderer.</p> <code>True</code> <code>structlog_pre_chain</code> <code>Optional[list]</code> <p>Optional list of pre-processors for stdlib log records.</p> <code>None</code> <code>structlog_processors</code> <code>Optional[list]</code> <p>Optional list of processors after pre_chain (before render).</p> <code>None</code> <code>structlog_renderer</code> <code>Optional[object]</code> <p>Optional custom renderer processor. Overrides <code>structlog_json</code>.</p> <code>None</code> <code>structlog_bind</code> <code>Optional[object]</code> <p>Optional dict or callable(name)-&gt;dict to bind fields.</p> <code>None</code> <p>Returns:</p> Type Description <code>Logger | BoundLogger</code> <p>Logger | structlog.BoundLogger: Configured logger instance.</p>"},{"location":"core/api/#mindtrace.core.logging.logger.get_logger","title":"get_logger","text":"<pre><code>get_logger(\n    name: str | None = \"mindtrace\", use_structlog: bool | None = None, **kwargs\n) -&gt; logging.Logger | structlog.BoundLogger\n</code></pre> <p>Create or retrieve a named logger instance.</p> <p>This function wraps Python's built-in <code>logging.getLogger()</code> to provide a standardized logger for Mindtrace components. If the logger with the given name already exists, it returns the existing instance; otherwise, it creates a new one with optional configuration overrides.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger. Defaults to \"mindtrace\".</p> <code>'mindtrace'</code> <code>use_structlog</code> <code>bool</code> <p>Whether to use structured logging. If None, uses config default.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>setup_logger</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Logger | BoundLogger</code> <p>logging.Logger | structlog.BoundLogger: A configured logger instance.</p> <p>Example: <pre><code>from mindtrace.core.logging.logger import get_logger\n\nlogger = get_logger(\"core.module\", stream_level=logging.INFO, propagate=True)\nlogger.info(\"Logger configured with custom settings.\")\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.logging.logger.track_operation","title":"track_operation","text":"<pre><code>track_operation(\n    name: str = None,\n    timeout: float | None = None,\n    logger: Any | None = None,\n    logger_name: str | None = None,\n    include_args: list[str] | None = None,\n    log_level: int = logging.DEBUG,\n    include_system_metrics: bool = False,\n    system_metrics: list[str] | None = None,\n    **context: Any\n)\n</code></pre> <p>Unified function that works as both context manager and decorator.</p> <p>This function can be used in two ways: 1. As a context manager: <code>async with track_operation(\"name\") as log:</code> 2. As a decorator: <code>@track_operation(\"name\")</code></p> <p>Provides structured logging for operations, automatically logging start, completion, timeout, and errors with duration metrics. Requires structlog to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the operation being tracked. When used as decorator, defaults to the function name if not provided.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>Optional timeout in seconds. If provided, raises asyncio.TimeoutError when exceeded. If FastAPI is available, raises HTTPException(504) instead.</p> <code>None</code> <code>logger</code> <code>Any | None</code> <p>Optional structlog logger instance. If None, creates a new logger.</p> <code>None</code> <code>logger_name</code> <code>str | None</code> <p>Optional logger name. If None, uses \"mindtrace.operations.{name}\" for context manager or \"mindtrace.methods.{name}\" for decorator.</p> <code>None</code> <code>include_args</code> <code>list[str] | None</code> <p>List of argument names to include in the log context (decorator only). If None, no arguments are logged. Only works with bound methods (self as first arg).</p> <code>None</code> <code>log_level</code> <code>int</code> <p>Log level for the operation logs. Defaults to logging.DEBUG.</p> <code>DEBUG</code> <code>include_system_metrics</code> <code>bool</code> <p>If True, include system metrics in the log context.</p> <code>False</code> <code>system_metrics</code> <code>list[str] | None</code> <p>Optional list of metric names to include. If None, include all available metrics.</p> <code>None</code> <code>**context</code> <code>Any</code> <p>Additional context fields to bind to the logger for this operation.</p> <code>{}</code> <p>Yields (context manager):     structlog.BoundLogger: A bound logger with operation context for logging.</p> <p>Returns (decorator):     Callable: The decorated method with automatic logging.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If timeout is exceeded and FastAPI is not available.</p> <code>HTTPException</code> <p>If timeout is exceeded and FastAPI is available (status_code=504).</p> <code>Exception</code> <p>Re-raises any exception that occurs during operation execution.</p> <p>Examples:</p> <p>Context manager usage: .. code-block:: python</p> <pre><code>import asyncio\nfrom mindtrace.core.logging.logger import track_operation\n\nasync def fetch_data():\n    async with track_operation(\"fetch_data\", user_id=\"123\") as log:\n        # Your async operation here\n        result = await some_async_operation()\n        log.info(\"Data fetched successfully\", records_count=len(result))\n        return result\n</code></pre> <p>Decorator usage on async function: .. code-block:: python</p> <pre><code>@track_operation(\"process_data\", batch_id=\"batch_123\", timeout=5.0)\nasync def process_data(data: list) -&gt; list:\n    # Method execution is automatically logged\n    return [item.upper() for item in data]\n</code></pre> <p>Decorator usage on class method: .. code-block:: python</p> <pre><code>class DataProcessor:\n    def __init__(self):\n        self.logger = structlog.get_logger(\"data_processor\")\n\n    @track_operation(\"process_batch\", include_args=[\"batch_id\"])\n    async def process_batch(self, batch_id: str, data: list):\n        # Logs will include batch_id in context\n        return await self._process_data(data)\n</code></pre> <p>With timeout: .. code-block:: python</p> <pre><code>async def fetch_with_timeout():\n    try:\n        async with track_operation(\"fetch_data\", timeout=30.0, service=\"api\") as log:\n            result = await slow_operation()\n            return result\n    except asyncio.TimeoutError:\n        # Operation timed out after 30 seconds\n        return None\n</code></pre>"},{"location":"core/api/#types","title":"Types","text":""},{"location":"core/api/#mindtrace.core.types.bounding_box","title":"bounding_box","text":""},{"location":"core/api/#mindtrace.core.types.bounding_box.BoundingBox","title":"BoundingBox  <code>dataclass</code>","text":"<pre><code>BoundingBox(x: float, y: float, width: float, height: float)\n</code></pre> <p>Axis-aligned rectangle in image or world coordinates.</p> <p>Coordinates follow OpenCV/Pascal VOC convention: (x, y, width, height), where (x, y) is the top-left corner.</p>"},{"location":"core/api/#mindtrace.core.types.bounding_box.BoundingBox.to_roi_slices","title":"to_roi_slices","text":"<pre><code>to_roi_slices() -&gt; Tuple[slice, slice]\n</code></pre> <p>Return (rows_slice, cols_slice) for NumPy image indexing: img[rows, cols].</p>"},{"location":"core/api/#mindtrace.core.types.bounding_box.BoundingBox.draw_on_pil","title":"draw_on_pil","text":"<pre><code>draw_on_pil(\n    image: Image,\n    color: Tuple[int, int, int] = (255, 0, 0),\n    width: int = 2,\n    fill: Optional[Tuple[int, int, int, int]] = None,\n    label: Optional[str] = None,\n    label_color: Tuple[int, int, int] = (255, 255, 255),\n    label_bg: Tuple[int, int, int] = (255, 0, 0),\n    font: Optional[ImageFont] = None,\n) -&gt; Image\n</code></pre> <p>Draw the bounding box (and optional label) directly onto a PIL Image and return it.</p>"},{"location":"core/api/#mindtrace.core.types.bounding_box.BoundingBox.to_corners","title":"to_corners","text":"<pre><code>to_corners() -&gt; List[Tuple[float, float]]\n</code></pre> <p>Return corners as [(x1,y1), (x2,y1), (x2,y2), (x1,y2)] without NumPy.</p>"},{"location":"core/api/#mindtrace.core.types.rotated_rect","title":"rotated_rect","text":""},{"location":"core/api/#mindtrace.core.types.rotated_rect.RotatedRect","title":"RotatedRect  <code>dataclass</code>","text":"<pre><code>RotatedRect(\n    cx: float, cy: float, width: float, height: float, angle_deg: float = 0.0\n)\n</code></pre> <p>Rotated rectangle represented by center (cx, cy), size (width, height), and rotation angle (degrees).</p> <p>Angle follows OpenCV convention in degrees, counter-clockwise, where 0 aligns the rectangle's width along +X axis.</p>"},{"location":"core/api/#mindtrace.core.types.rotated_rect.RotatedRect.draw_on_pil","title":"draw_on_pil","text":"<pre><code>draw_on_pil(\n    image: Image,\n    color: Tuple[int, int, int] = (0, 255, 0),\n    width: int = 2,\n    fill: Optional[Tuple[int, int, int, int]] = None,\n    label: Optional[str] = None,\n    label_color: Tuple[int, int, int] = (255, 255, 255),\n    label_bg: Tuple[int, int, int] = (0, 128, 0),\n    font: Optional[ImageFont] = None,\n) -&gt; Image\n</code></pre> <p>Draw the rotated rectangle (and optional label) onto a PIL Image and return it.</p>"},{"location":"core/api/#mindtrace.core.types.task_schema","title":"task_schema","text":""},{"location":"core/api/#mindtrace.core.types.task_schema.TaskSchema","title":"TaskSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>A task schema with strongly-typed input and output models.</p>"},{"location":"core/api/#utilities","title":"Utilities","text":""},{"location":"core/api/#mindtrace.core.utils.SystemMetricsCollector","title":"SystemMetricsCollector","text":"<pre><code>SystemMetricsCollector(\n    interval: int | None = None, metrics_to_collect: list[str] | None = None\n)\n</code></pre> <p>Class for collecting various system metrics.</p> <p>This class allows collection of CPU, memory, disk usage, network I/O, etc. Users can specify which metrics to collect and optionally enable periodic background updates.</p> Available metrics include <ul> <li>\"cpu_percent\": Overall CPU usage percentage.</li> <li>\"per_core_cpu_percent\": CPU usage percentage per core.</li> <li>\"memory_percent\": Memory usage percentage.</li> <li>\"disk_usage\": Disk usage percentage.</li> <li>\"network_io\": Network I/O statistics (bytes sent and received).</li> <li>\"load_average\": System load average (if available).</li> </ul> <p>Example Usage:</p> <pre><code>from time import sleep\nfrom mindtrace.core.utils import SystemMetricsCollector\n\nwith SystemMetricsCollector(interval=3) as collector:\n    for _ in range(10):\n        print(collector())\n        sleep(1)\n</code></pre> <p>Alternative (manual stop):</p> <pre><code>from time import sleep\nfrom mindtrace.core.utils import SystemMetricsCollector\n\ncollector = SystemMetricsCollector(interval=3)\ntry:\n    for _ in range(10):\n        print(collector())\n        sleep(1)\nfinally:\n    collector.stop()\n</code></pre> <p>On-demand usage (no background thread):</p> <pre><code>from mindtrace.core.utils import SystemMetricsCollector\n\ncollector = SystemMetricsCollector()  # no interval; collected on demand\nprint(collector())\n</code></pre> <p>Initialize the system metrics collector.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>int | None</code> <p>Interval in seconds for periodic metrics collection. If provided, metrics will be updated to a separate cache periodically, instead of being collected on demand. Using a cache in this way can be less resource intensive than collecting metrics on demand. If None, metrics will be collected on demand.</p> <code>None</code> <code>metrics_to_collect</code> <code>list[str] | None</code> <p>List of metrics to collect. If None, all available metrics will be collected.</p> <code>None</code>"},{"location":"core/api/#mindtrace.core.utils.SystemMetricsCollector.fetch","title":"fetch","text":"<pre><code>fetch() -&gt; dict[str, float | list | dict]\n</code></pre> <p>Get the current system metrics.</p> <p>Returns:</p> Type Description <code>dict[str, float | list | dict]</code> <p>A dictionary containing system metrics. If metrics are cached, return them; otherwise, collect new metrics.</p>"},{"location":"core/api/#mindtrace.core.utils.SystemMetricsCollector.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Stop the background collection thread if running.</p> <p>Prefer using the context manager (<code>with SystemMetricsCollector(...) as collector:</code>) which stops the thread automatically on exit.</p>"},{"location":"core/api/#mindtrace.core.utils.check_libs","title":"check_libs","text":"<pre><code>check_libs(required_libs: str | list[str]) -&gt; list[str]\n</code></pre> <p>Check if all required libraries are available.</p> <p>Parameters:</p> Name Type Description Default <code>required_libs</code> <code>str | list[str]</code> <p>A list of library names to check.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of missing libraries.</p>"},{"location":"core/api/#mindtrace.core.utils.first_not_none","title":"first_not_none","text":"<pre><code>first_not_none(vals: Iterable[T1 | None], default: T2 = None) -&gt; T1 | T2\n</code></pre> <p>Returns the first not-None value in the given iterable, else returns the default.</p>"},{"location":"core/api/#mindtrace.core.utils.ifnone","title":"ifnone","text":"<pre><code>ifnone(val: T1 | None, default: T2) -&gt; T1 | T2\n</code></pre> <p>Return the given value if it is not None, else return the default.</p>"},{"location":"core/api/#mindtrace.core.utils.ifnone_url","title":"ifnone_url","text":"<pre><code>ifnone_url(url: str | Url | None, default: str | Url) -&gt; Url\n</code></pre> <p>Wraps ifnone to always return a URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>The Url to return. If none, the default value will be returned instead.</p> required <code>default</code> <code>str | Url</code> <p>The default URL to use if url is None.</p> required <p>Returns:</p> Type Description <code>Url</code> <p>The Url object.</p>"},{"location":"core/api/#mindtrace.core.utils.download_and_extract_tarball","title":"download_and_extract_tarball","text":"<pre><code>download_and_extract_tarball(\n    url: str,\n    extract_to: Union[str, Path],\n    filename: Optional[str] = None,\n    remove_after_extract: bool = True,\n) -&gt; Path\n</code></pre> <p>Download a tarball (tar.gz, tar.bz2, etc.) from URL and extract it to the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to download the tarball from</p> required <code>extract_to</code> <code>Union[str, Path]</code> <p>Directory to extract the tarball to</p> required <code>filename</code> <code>Optional[str]</code> <p>Optional filename for the downloaded file (if None, uses URL basename)</p> <code>None</code> <code>remove_after_extract</code> <code>bool</code> <p>Whether to remove the downloaded tarball after extraction</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the extracted directory</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If download or extraction fails</p>"},{"location":"core/api/#mindtrace.core.utils.download_and_extract_zip","title":"download_and_extract_zip","text":"<pre><code>download_and_extract_zip(\n    url: str,\n    extract_to: Union[str, Path],\n    filename: Optional[str] = None,\n    remove_after_extract: bool = True,\n) -&gt; Path\n</code></pre> <p>Download a ZIP file from URL and extract it to the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to download the ZIP file from</p> required <code>extract_to</code> <code>Union[str, Path]</code> <p>Directory to extract the ZIP file to</p> required <code>filename</code> <code>Optional[str]</code> <p>Optional filename for the downloaded file (if None, uses URL basename)</p> <code>None</code> <code>remove_after_extract</code> <code>bool</code> <p>Whether to remove the downloaded ZIP file after extraction</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the extracted directory</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If download or extraction fails</p>"},{"location":"core/api/#mindtrace.core.utils.instantiate_target","title":"instantiate_target","text":"<pre><code>instantiate_target(target: str, **kwargs) -&gt; Any\n</code></pre> <p>Instantiates a target object from a string.</p> <p>The target string should be in the same format as expected from Hydra targets. I.e. 'module_name.class_name'.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>A string representing a target object.</p> required <p>Example::</p> <pre><code>from mindtrace.core import instantiate_target\n\ntarget = 'mindtrace.core.config.Config'\nconfig = instantiate_target(target)\n\nprint(type(config))  # &lt;class 'mindtrace.core.config.Config'&gt;\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.load_ini_as_dict","title":"load_ini_as_dict","text":"<pre><code>load_ini_as_dict(ini_path: Path) -&gt; Dict[str, Any]\n</code></pre> <p>Load and parse an INI file into a nested dictionary with normalized keys.</p> <ul> <li>Section names and keys are uppercased for uniform access</li> <li>Values with leading '~' are expanded to the user home directory</li> <li>Returns an empty dict if the file does not exist</li> </ul>"},{"location":"core/api/#mindtrace.core.utils.named_lambda","title":"named_lambda","text":"<pre><code>named_lambda(name: str, lambda_func: Callable) -&gt; Callable\n</code></pre> <p>Assigns a name to the given lambda function.</p> <p>This method is useful when passing lambda functions to other functions that require a name attribute. For example, when using the autolog decorator, the wrapped function will be logged according the function name. If the original function is a lambda function, it's name attribute will be set to the generic name ''. <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to assign to the lambda function.</p> required <code>lambda_func</code> <code>Callable</code> <p>The lambda function to assign the name to.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The lambda function with the name attribute set to the given name.</p> <p>Example::</p> <pre><code>    from mindtrace.core import Mindtrace, named_lambda\n\n    class HyperRunner(Mindtrace):\n        def __init__(self):\n            super().__init__()\n\n        def run_command(self, command: Callable, data: Any):  # cannot control the name of the command\n            return Mindtrace.autolog(command(data))()\n\n    hyper_runner = HyperRunner()\n    hyper_runner.run_command(lambda x, y: x + y, data=(1, 2))  # autologs to '&lt;lambda&gt;'\n    hyper_runner.run_command(named_lambda(\"add\", lambda x, y: x + y), data=(1, 2))  # autologs to 'add'\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.expand_tilde","title":"expand_tilde","text":"<pre><code>expand_tilde(obj: Any) -&gt; Any\n</code></pre> <p>Recursively expand leading '~' across strings in nested structures.</p> <p>Supports dict, list/tuple/set, and str. Other types are returned unchanged.</p>"},{"location":"core/api/#mindtrace.core.utils.expand_tilde_str","title":"expand_tilde_str","text":"<pre><code>expand_tilde_str(value: str) -&gt; str\n</code></pre> <p>Expand leading '~' in a string value; return unchanged if not present.</p>"},{"location":"core/api/#mindtrace.core.utils.checks","title":"checks","text":""},{"location":"core/api/#mindtrace.core.utils.checks.ifnone","title":"ifnone","text":"<pre><code>ifnone(val: T1 | None, default: T2) -&gt; T1 | T2\n</code></pre> <p>Return the given value if it is not None, else return the default.</p>"},{"location":"core/api/#mindtrace.core.utils.checks.first_not_none","title":"first_not_none","text":"<pre><code>first_not_none(vals: Iterable[T1 | None], default: T2 = None) -&gt; T1 | T2\n</code></pre> <p>Returns the first not-None value in the given iterable, else returns the default.</p>"},{"location":"core/api/#mindtrace.core.utils.checks.ifnone_url","title":"ifnone_url","text":"<pre><code>ifnone_url(url: str | Url | None, default: str | Url) -&gt; Url\n</code></pre> <p>Wraps ifnone to always return a URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>The Url to return. If none, the default value will be returned instead.</p> required <code>default</code> <code>str | Url</code> <p>The default URL to use if url is None.</p> required <p>Returns:</p> Type Description <code>Url</code> <p>The Url object.</p>"},{"location":"core/api/#mindtrace.core.utils.checks.check_libs","title":"check_libs","text":"<pre><code>check_libs(required_libs: str | list[str]) -&gt; list[str]\n</code></pre> <p>Check if all required libraries are available.</p> <p>Parameters:</p> Name Type Description Default <code>required_libs</code> <code>str | list[str]</code> <p>A list of library names to check.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of missing libraries.</p>"},{"location":"core/api/#mindtrace.core.utils.conversions","title":"conversions","text":"<p>Utility methods relating to image conversion.</p>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_ascii","title":"pil_to_ascii","text":"<pre><code>pil_to_ascii(image: Image) -&gt; str\n</code></pre> <p>Serialize PIL Image to ascii.</p> Example <pre><code>import PIL\nfrom mindtrace.core import pil_to_ascii, ascii_to_pil\n\nimage = PIL.Image.open('tests/resources/hopper.png')\nascii_image = pil_to_ascii(image)\ndecoded_image = ascii_to_pil(ascii_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.ascii_to_pil","title":"ascii_to_pil","text":"<pre><code>ascii_to_pil(ascii_image: str) -&gt; Image\n</code></pre> <p>Convert ascii image to PIL Image.</p> Example <pre><code>import PIL\nfrom mindtrace.core import pil_to_ascii, ascii_to_pil\n\nimage = PIL.Image.open('tests/resources/hopper.png')\nascii_image = pil_to_ascii(image)\ndecoded_image = ascii_to_pil(ascii_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_bytes","title":"pil_to_bytes","text":"<pre><code>pil_to_bytes(image: Image) -&gt; bytes\n</code></pre> <p>Serialize PIL Image into io.BytesIO stream.</p> Example <pre><code>import PIL\nfrom mindtrace.core import pil_to_bytes, bytes_to_pil\n\nimage = PIL.Image.open('tests/resources/hopper.png')\nbytes_image = pil_to_bytes(image)\ndecoded_image = bytes_to_pil(bytes_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.bytes_to_pil","title":"bytes_to_pil","text":"<pre><code>bytes_to_pil(bytes_image: bytes) -&gt; Image\n</code></pre> <p>Convert io.BytesIO stream to PIL Image.</p> Example <pre><code>import PIL\nfrom mindtrace.core import pil_to_bytes, bytes_to_pil\n\nimage = PIL.Image.open('tests/resources/hopper.png')\nbytes_image = pil_to_bytes(image)\ndecoded_image = bytes_to_pil(bytes_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_tensor","title":"pil_to_tensor","text":"<pre><code>pil_to_tensor(image: Image) -&gt; torch.Tensor\n</code></pre> <p>Convert PIL Image to Torch Tensor.</p> Example <pre><code>from PIL import Image\nfrom mindtrace.core import pil_to_tensor\n\nimage = Image.open('tests/resources/hopper.png')\ntensor = pil_to_tensor(image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.tensor_to_pil","title":"tensor_to_pil","text":"<pre><code>tensor_to_pil(image: Tensor, mode=None, min_val=None, max_val=None) -&gt; Image\n</code></pre> <p>Convert Torch Tensor to PIL Image.</p> <p>Note that PIL float images must be scaled [0, 1]. It is often the case, however, that torch tensor images may have a different range (e.g. zero mean or [-1, 1]). As such, the input torch tensor will automatically be scaled to fit in the range [0, 1]. If no min / max value is provided, the output range will be identically 0 / 1, respectively. Else you may pass in min / max range values explicitly.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Tensor</code> <p>The input image.</p> required <code>mode</code> <p>The mode of the output image. One of {'L', 'RGB', 'RGBA'}.</p> <code>None</code> <code>min_val</code> <p>The minimum value of the input image. If None, it will be inferred from the input image.</p> <code>None</code> <code>max_val</code> <p>The maximum value of the input image. If None, it will be inferred from the input image.</p> <code>None</code> Example <pre><code>from PIL import Image\nfrom mindtrace.core import pil_to_tensor, tensor_to_pil\n\nimage = Image.open('tests/resources/hopper.png')\ntensor_image = pil_to_tensor(image)\npil_image = tensor_to_pil(tensor_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_ndarray","title":"pil_to_ndarray","text":"<pre><code>pil_to_ndarray(image: Image, image_format='RGB') -&gt; np.ndarray\n</code></pre> <p>Convert PIL image to numpy ndarray.</p> <p>If an alpha channel is present, it will automatically be copied over as well.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>The input image.</p> required <code>image_format</code> <p>Determines the number and order of channels in the output image. One of {'L', 'RGB', 'BGR'}.</p> <code>'RGB'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An np.ndarray image in the specified format.</p>"},{"location":"core/api/#mindtrace.core.utils.conversions.ndarray_to_pil","title":"ndarray_to_pil","text":"<pre><code>ndarray_to_pil(image: ndarray, image_format: str = 'RGB')\n</code></pre> <p>Convert numpy ndarray to PIL image.</p> <p>The input image can either be a float array with values in the range [0, 1], an int array with values in the range [0, 255], or a bool array.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The input image. It should be a numpy array with 1, 3 or 4 channels.</p> required <code>image_format</code> <code>str</code> <p>The format of the input image. One of {'RGB', 'BGR'}</p> <code>'RGB'</code> <p>Returns:</p> Type Description <p>A PIL image.</p> Example <pre><code>from matplotlib import image, pyplot as plt\nfrom mindtrace.core import ndarray_to_pil\n\nndarray_image = image.imread('tests/resources/hopper.png')\npil_image = ndarray_to_pil(ndarray_image, image_format='RGB')\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_cv2","title":"pil_to_cv2","text":"<pre><code>pil_to_cv2(image: Image) -&gt; np.ndarray\n</code></pre> <p>Convert PIL image to cv2 image.</p> <p>Note that, in addition to cv2 images being numpy arrays, PIL Images follow RGB format while cv2 images follow BGR format.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>The input image.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An np.ndarray image in 'BGR' (cv2) format.</p> <p>Example:</p> <pre><code>```python\nimport PIL\nfrom mindtrace.core import pil_to_cv2\n\npil_image = PIL.Image.open('tests/resources/hopper.png')\ncv2_image = pil_to_cv2(pil_image)\n```\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.cv2_to_pil","title":"cv2_to_pil","text":"<pre><code>cv2_to_pil(image: ndarray) -&gt; Image\n</code></pre> <p>Convert PIL image to cv2 image.</p> <p>Note that, in addition to cv2 images being numpy arrays, PIL Images follow RGB format while cv2 images follow BGR format.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The input image. Should be a np.ndarray in 'BGR' (cv2) format.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>A PIL image.</p> Example <pre><code>import cv2\nfrom mindtrace.core import cv2_to_pil\n\ncv2_image = cv2.imread('tests/resources/hopper.png')\npil_image = cv2_to_pil(cv2_image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_base64","title":"pil_to_base64","text":"<pre><code>pil_to_base64(image: Image) -&gt; str\n</code></pre> <p>Convert a PIL Image to a base64-encoded string.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>The image to be converted.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The base64-encoded string representing the image.</p> Example <pre><code>from PIL import Image\nfrom mindtrace.core import pil_to_base64\n\nimage = Image.open(\"path_to_image.png\")\nencoded_image = pil_to_base64(image)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.base64_to_pil","title":"base64_to_pil","text":"<pre><code>base64_to_pil(base64_str: str) -&gt; Image\n</code></pre> <p>Convert a base64-encoded string back to a PIL Image.</p> <p>Parameters:</p> Name Type Description Default <code>base64_str</code> <code>str</code> <p>The base64-encoded string.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>PIL.Image: The decoded image object.</p> Example <pre><code>from mindtrace.core import base64_to_pil\n\nbase64_str = \"...\"  # Base64 string obtained earlier\nimage = base64_to_pil(base64_str)\nimage.show()  # Display the decoded image\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.pil_to_discord_file","title":"pil_to_discord_file","text":"<pre><code>pil_to_discord_file(image: Image, filename: str = 'image.png') -&gt; File\n</code></pre> <p>Convert a PIL Image to a Discord File object for uploading.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>The PIL image to be sent.</p> required <code>filename</code> <code>str</code> <p>The filename for the image file (default is \"image.png\").</p> <code>'image.png'</code> <p>Returns:</p> Type Description <code>File</code> <p>discord.File: A Discord file object that can be sent in a message.</p> Example <pre><code>from PIL import Image\nfrom mindtrace.core import pil_to_discord_file\nfrom discord import File\n\nimage = Image.open(\"path_to_image.png\")\ndiscord_file = pil_to_discord_file(image)\nawait message.reply(file=discord_file)\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.discord_file_to_pil","title":"discord_file_to_pil  <code>async</code>","text":"<pre><code>discord_file_to_pil(attachment: Attachment) -&gt; Image\n</code></pre> <p>Convert a Discord attachment to a PIL Image.</p> <p>Parameters:</p> Name Type Description Default <code>attachment</code> <code>Attachment</code> <p>The Discord file attachment to convert.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>The resulting PIL Image.</p> Example <pre><code>@commands.command(name=\"process_images\")\nasync def example_command(self, ctx):\n    attachments = ctx.message.attachments\n    if not attachments:\n        await ctx.send(\"No attachments found in the message.\")\n        return\n\n    # Process each attachment in the message\n    for i, attachment in enumerate(attachments, start=1):\n        if attachment.filename.endswith(('png', 'jpg', 'jpeg')):\n            image = await discord_file_to_pil(attachment)\n            # Do something with the image, e.g., send it back or process it\n            await ctx.send(f\"Attachment {i} processed as image.\")\n        else:\n            await ctx.send(f\"Attachment {i} is not a valid image file.\")\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.conversions.tensor_to_ndarray","title":"tensor_to_ndarray","text":"<pre><code>tensor_to_ndarray(tensor: Tensor) -&gt; np.ndarray\n</code></pre> <p>Convert a PyTorch tensor to a numpy array.</p> <p>Handles both single images (3D tensors) and batches (4D tensors), converting them to the numpy format.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>PyTorch tensor in format [C,H,W] or [B,C,H,W]</p> required <code>Returns</code> <p>For batched tensors: a list of numpy arrays in HWC format For single image: a numpy array in HWC format</p> required"},{"location":"core/api/#mindtrace.core.utils.conversions.ndarray_to_tensor","title":"ndarray_to_tensor","text":"<pre><code>ndarray_to_tensor(image: ndarray) -&gt; torch.Tensor\n</code></pre> <p>Convert a numpy array to a PyTorch tensor.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The numpy array to convert.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The PyTorch tensor.</p>"},{"location":"core/api/#mindtrace.core.utils.download","title":"download","text":""},{"location":"core/api/#mindtrace.core.utils.download.download_and_extract_zip","title":"download_and_extract_zip","text":"<pre><code>download_and_extract_zip(\n    url: str,\n    extract_to: Union[str, Path],\n    filename: Optional[str] = None,\n    remove_after_extract: bool = True,\n) -&gt; Path\n</code></pre> <p>Download a ZIP file from URL and extract it to the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to download the ZIP file from</p> required <code>extract_to</code> <code>Union[str, Path]</code> <p>Directory to extract the ZIP file to</p> required <code>filename</code> <code>Optional[str]</code> <p>Optional filename for the downloaded file (if None, uses URL basename)</p> <code>None</code> <code>remove_after_extract</code> <code>bool</code> <p>Whether to remove the downloaded ZIP file after extraction</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the extracted directory</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If download or extraction fails</p>"},{"location":"core/api/#mindtrace.core.utils.download.download_and_extract_tarball","title":"download_and_extract_tarball","text":"<pre><code>download_and_extract_tarball(\n    url: str,\n    extract_to: Union[str, Path],\n    filename: Optional[str] = None,\n    remove_after_extract: bool = True,\n) -&gt; Path\n</code></pre> <p>Download a tarball (tar.gz, tar.bz2, etc.) from URL and extract it to the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to download the tarball from</p> required <code>extract_to</code> <code>Union[str, Path]</code> <p>Directory to extract the tarball to</p> required <code>filename</code> <code>Optional[str]</code> <p>Optional filename for the downloaded file (if None, uses URL basename)</p> <code>None</code> <code>remove_after_extract</code> <code>bool</code> <p>Whether to remove the downloaded tarball after extraction</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the extracted directory</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If download or extraction fails</p>"},{"location":"core/api/#mindtrace.core.utils.dynamic","title":"dynamic","text":"<p>Utility methods relating to dynamically generating objects.</p>"},{"location":"core/api/#mindtrace.core.utils.dynamic.dynamic_instantiation","title":"dynamic_instantiation","text":"<pre><code>dynamic_instantiation(module_name: str, class_name: str, **kwargs) -&gt; Any\n</code></pre> <p>Dynamically instantiates a class from a module.</p>"},{"location":"core/api/#mindtrace.core.utils.dynamic.instantiate_target","title":"instantiate_target","text":"<pre><code>instantiate_target(target: str, **kwargs) -&gt; Any\n</code></pre> <p>Instantiates a target object from a string.</p> <p>The target string should be in the same format as expected from Hydra targets. I.e. 'module_name.class_name'.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>A string representing a target object.</p> required <p>Example::</p> <pre><code>from mindtrace.core import instantiate_target\n\ntarget = 'mindtrace.core.config.Config'\nconfig = instantiate_target(target)\n\nprint(type(config))  # &lt;class 'mindtrace.core.config.Config'&gt;\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.dynamic.get_class","title":"get_class","text":"<pre><code>get_class(target: str) -&gt; type\n</code></pre> <p>Gets a class from a module path string without instantiating it.</p> <p>The target string should be in the same format as expected from Hydra targets. I.e. 'module_name.class_name'.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>A string representing a target class path.</p> required <p>Returns:</p> Type Description <code>type</code> <p>The class object.</p> <p>Example::</p> <pre><code>from mindtrace.core import get_class\n\ntarget = 'mindtrace.core.config.Config'\nconfig_class = get_class(target)\n\nprint(config_class)  # &lt;class 'mindtrace.core.config.Config'&gt;\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.hashing","title":"hashing","text":""},{"location":"core/api/#mindtrace.core.utils.hashing.compute_dir_hash","title":"compute_dir_hash","text":"<pre><code>compute_dir_hash(directory_path: str | Path, chunk_size: int = 2 ** 20) -&gt; str\n</code></pre> <p>Compute SHA256 hash of directory contents.</p> <p>Hash is deterministic: files are sorted by path, then each file's content is hashed and combined. This ensures the same directory always produces the same hash.</p> <p>Parameters:</p> Name Type Description Default <code>directory_path</code> <code>str | Path</code> <p>Path to the directory to hash</p> required <code>chunk_size</code> <code>int</code> <p>Size of the chunks (in bytes) to read from the file</p> <code>2 ** 20</code> <p>Returns:     Hexadecimal SHA256 hash string</p>"},{"location":"core/api/#mindtrace.core.utils.ini","title":"ini","text":""},{"location":"core/api/#mindtrace.core.utils.ini.load_ini_as_dict","title":"load_ini_as_dict","text":"<pre><code>load_ini_as_dict(ini_path: Path) -&gt; Dict[str, Any]\n</code></pre> <p>Load and parse an INI file into a nested dictionary with normalized keys.</p> <ul> <li>Section names and keys are uppercased for uniform access</li> <li>Values with leading '~' are expanded to the user home directory</li> <li>Returns an empty dict if the file does not exist</li> </ul>"},{"location":"core/api/#mindtrace.core.utils.lambdas","title":"lambdas","text":""},{"location":"core/api/#mindtrace.core.utils.lambdas.named_lambda","title":"named_lambda","text":"<pre><code>named_lambda(name: str, lambda_func: Callable) -&gt; Callable\n</code></pre> <p>Assigns a name to the given lambda function.</p> <p>This method is useful when passing lambda functions to other functions that require a name attribute. For example, when using the autolog decorator, the wrapped function will be logged according the function name. If the original function is a lambda function, it's name attribute will be set to the generic name ''. <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to assign to the lambda function.</p> required <code>lambda_func</code> <code>Callable</code> <p>The lambda function to assign the name to.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The lambda function with the name attribute set to the given name.</p> <p>Example::</p> <pre><code>    from mindtrace.core import Mindtrace, named_lambda\n\n    class HyperRunner(Mindtrace):\n        def __init__(self):\n            super().__init__()\n\n        def run_command(self, command: Callable, data: Any):  # cannot control the name of the command\n            return Mindtrace.autolog(command(data))()\n\n    hyper_runner = HyperRunner()\n    hyper_runner.run_command(lambda x, y: x + y, data=(1, 2))  # autologs to '&lt;lambda&gt;'\n    hyper_runner.run_command(named_lambda(\"add\", lambda x, y: x + y), data=(1, 2))  # autologs to 'add'\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.paths","title":"paths","text":""},{"location":"core/api/#mindtrace.core.utils.paths.expand_tilde_str","title":"expand_tilde_str","text":"<pre><code>expand_tilde_str(value: str) -&gt; str\n</code></pre> <p>Expand leading '~' in a string value; return unchanged if not present.</p>"},{"location":"core/api/#mindtrace.core.utils.paths.expand_tilde","title":"expand_tilde","text":"<pre><code>expand_tilde(obj: Any) -&gt; Any\n</code></pre> <p>Recursively expand leading '~' across strings in nested structures.</p> <p>Supports dict, list/tuple/set, and str. Other types are returned unchanged.</p>"},{"location":"core/api/#mindtrace.core.utils.system_metrics_collector","title":"system_metrics_collector","text":""},{"location":"core/api/#mindtrace.core.utils.system_metrics_collector.SystemMetricsCollector","title":"SystemMetricsCollector","text":"<pre><code>SystemMetricsCollector(\n    interval: int | None = None, metrics_to_collect: list[str] | None = None\n)\n</code></pre> <p>Class for collecting various system metrics.</p> <p>This class allows collection of CPU, memory, disk usage, network I/O, etc. Users can specify which metrics to collect and optionally enable periodic background updates.</p> Available metrics include <ul> <li>\"cpu_percent\": Overall CPU usage percentage.</li> <li>\"per_core_cpu_percent\": CPU usage percentage per core.</li> <li>\"memory_percent\": Memory usage percentage.</li> <li>\"disk_usage\": Disk usage percentage.</li> <li>\"network_io\": Network I/O statistics (bytes sent and received).</li> <li>\"load_average\": System load average (if available).</li> </ul> <p>Example Usage:</p> <pre><code>from time import sleep\nfrom mindtrace.core.utils import SystemMetricsCollector\n\nwith SystemMetricsCollector(interval=3) as collector:\n    for _ in range(10):\n        print(collector())\n        sleep(1)\n</code></pre> <p>Alternative (manual stop):</p> <pre><code>from time import sleep\nfrom mindtrace.core.utils import SystemMetricsCollector\n\ncollector = SystemMetricsCollector(interval=3)\ntry:\n    for _ in range(10):\n        print(collector())\n        sleep(1)\nfinally:\n    collector.stop()\n</code></pre> <p>On-demand usage (no background thread):</p> <pre><code>from mindtrace.core.utils import SystemMetricsCollector\n\ncollector = SystemMetricsCollector()  # no interval; collected on demand\nprint(collector())\n</code></pre> <p>Initialize the system metrics collector.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>int | None</code> <p>Interval in seconds for periodic metrics collection. If provided, metrics will be updated to a separate cache periodically, instead of being collected on demand. Using a cache in this way can be less resource intensive than collecting metrics on demand. If None, metrics will be collected on demand.</p> <code>None</code> <code>metrics_to_collect</code> <code>list[str] | None</code> <p>List of metrics to collect. If None, all available metrics will be collected.</p> <code>None</code>"},{"location":"core/api/#mindtrace.core.utils.system_metrics_collector.SystemMetricsCollector.fetch","title":"fetch","text":"<pre><code>fetch() -&gt; dict[str, float | list | dict]\n</code></pre> <p>Get the current system metrics.</p> <p>Returns:</p> Type Description <code>dict[str, float | list | dict]</code> <p>A dictionary containing system metrics. If metrics are cached, return them; otherwise, collect new metrics.</p>"},{"location":"core/api/#mindtrace.core.utils.system_metrics_collector.SystemMetricsCollector.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Stop the background collection thread if running.</p> <p>Prefer using the context manager (<code>with SystemMetricsCollector(...) as collector:</code>) which stops the thread automatically on exit.</p>"},{"location":"core/api/#mindtrace.core.utils.timers","title":"timers","text":"<p>Utility class for simple Timer and TimerCollection classes.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer","title":"Timer","text":"<pre><code>Timer()\n</code></pre> <p>Utility timer class.</p> <p>This class can be used to time operations. It can be started, stopped, and reset. The duration of the timer can be retrieved at any time.</p> Usage <pre><code>import time\nfrom mindtrace.core import Timer\n\ntimer = Timer()\ntimer.start()\ntime.sleep(1)\ntimer.stop()\nprint(f'The timer ran for {timer.duration()} seconds.')  # The timer ran for 1.0000000000000002 seconds.\ntimer.reset()\ntimer.start()\ntime.sleep(2)\ntimer.stop()\nprint(f'The timer ran for {timer.duration()} seconds.')  # The timer ran for 2.0000000000000004 seconds.\n</code></pre>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer.start","title":"start","text":"<pre><code>start()\n</code></pre> <p>Start the timer.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Stop the timer.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer.duration","title":"duration","text":"<pre><code>duration() -&gt; float\n</code></pre> <p>Get the duration of the timer.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> <p>Reset the timer.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timer.restart","title":"restart","text":"<pre><code>restart()\n</code></pre> <p>Reset and start the timer.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerContext","title":"TimerContext","text":"<pre><code>TimerContext(timer_collection: TimerCollection, name: str)\n</code></pre> <p>Context manager for individual timers in a TimerCollection.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection","title":"TimerCollection","text":"<pre><code>TimerCollection()\n</code></pre> <p>Utility class for timing multiple operations.</p> <p>This class keeps a collection of named timers. Each timer can be started, stopped, and reset. The duration of each timer can be retrieved at any time. If a timer is stopped and restarted, the duration will be added to the previous duration. The timers can be reset individually, or all at once.</p> Usage <pre><code>import time\nfrom mindtrace.core import TimerCollection\n\ntc = TimerCollection()\ntc.start('Timer 1')\ntc.start('Timer 2')\ntime.sleep(1)\ntc.stop('Timer 1')\ntime.sleep(1)\ntc.stop('Timer 2')\ntc.start('Timer 3')\ntime.sleep(1)\ntc.reset('Timer 1')\nprint(tc)\n    # Timer 1: 0.000s\n    # Timer 2: 2.000s\n    # Timer 3: 1.000s\ntc.reset_all()\nprint(tc)\n    # Timer 1: 0.000s\n    # Timer 2: 0.000s\n    # Timer 3: 0.000s\n</code></pre> <p>Context Manager Usage:     <pre><code>import time\nfrom mindtrace.core import TimerCollection\n\ntc = TimerCollection()\nwith tc.start('Timer 1'):\n    with tc.start('Timer 2'):\n        time.sleep(1)\n    # stops \"Timer 2\"\n    with tc.start('Timer 3'):\n        time.sleep(2)\n    # stops \"Timer 3\"\n# stops \"Timer 1\"\n\nprint(tc)\n    # Timer 1: 3.000s\n    # Timer 2: 1.000s\n    # Timer 3: 2.000s\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.add_timer","title":"add_timer","text":"<pre><code>add_timer(name: str)\n</code></pre> <p>Add a timer with the given name. If the timer already exists, it will be replaced.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.start","title":"start","text":"<pre><code>start(name: str)\n</code></pre> <p>Start the timer with the given name. If the timer does not exist, it will be created.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.stop","title":"stop","text":"<pre><code>stop(name: str)\n</code></pre> <p>Stop the timer with the given name.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the timer with the given name does not exist.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.duration","title":"duration","text":"<pre><code>duration(name: str) -&gt; float\n</code></pre> <p>Get the duration of the timer with the given name.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the timer with the given name does not exist.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.reset","title":"reset","text":"<pre><code>reset(name: str)\n</code></pre> <p>Reset the timer with the given name.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the timer with the given name does not exist.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.restart","title":"restart","text":"<pre><code>restart(name: str)\n</code></pre> <p>Reset and start the timer with the given name.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the timer with the given name does not exist.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.reset_all","title":"reset_all","text":"<pre><code>reset_all()\n</code></pre> <p>Reset all timers.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.TimerCollection.names","title":"names","text":"<pre><code>names()\n</code></pre> <p>Get the names of all timers.</p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timeout","title":"Timeout","text":"<pre><code>Timeout(\n    timeout: float = 60.0,\n    retry_delay: float = 1.0,\n    exceptions: tuple[Type[Exception], ...] = (Exception,),\n    progress_bar: bool = False,\n    desc: str | None = None,\n)\n</code></pre> <p>Utility for adding a timeout to a given method.</p> <p>The given method will be run and rerun until an exception is not raised, or the timeout period is reached.</p> <p>If the method raises an exception that is in the exceptions tuple, that exception will be caught and ignored. After a retry_delay, the method will be run again. This process will continue until the method runs without raising an exception, or the timeout period is passed.</p> <p>If the timeout is reached, a TimeoutError will be raised. If the method ever raises an exception that is not in the exceptions tuple, the timeout process will stop and that exception will be reraised.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>The maximum time in seconds that the method can run before a TimeoutError is raised.</p> <code>60.0</code> <code>retry_delay</code> <code>float</code> <p>The time in seconds to wait between attempts to run the method.</p> <code>1.0</code> <code>exceptions</code> <code>tuple[Type[Exception], ...]</code> <p>A tuple of exceptions that will be caught and ignored. By default, all exceptions are caught.</p> <code>(Exception,)</code> <code>progress_bar</code> <code>bool</code> <p>A boolean indicating whether to display a progress bar while waiting for the timeout.</p> <code>False</code> <code>desc</code> <code>str | None</code> <p>A description to display in the progress bar.</p> <code>None</code> <p>Returns:</p> Type Description <p>The result of the given method.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If the timeout is reached.</p> <code>Exception</code> <p>Any raised exception not in the exceptions tuple will be reraised.</p> <p>Example\u2014 Running Timeout Manually:     <pre><code>import requests\nfrom urllib3.util.url import parse_url, Url\nfrom mindtrace.core import Timeout\nfrom mindtrace.services import Service\n\ndef get_server_status(url: Url):\n    # The following request may fail for two categories of reasons:\n    #   1. The server has not launched yet: Will raise a ConnectionError, we should retry.\n    #   2. Any other reason: Will raise some other exception, we should break out and reraise it.\n    # Both cases will be raised to the Timeout class. We will tell the Timeout object to ignore ConnectionError.\n    response = requests.request(\"POST\", str(url) + \"status\")\n\n    if response.status_code == 200:\n        return json.loads(response.content)[\"status\"]  # Server is up and responding\n    else:\n        raise HTTPException(response.status_code, response.content)  # Request completed but something is wrong\n\nurl = parse_url(\"http://localhost:8080/\")\ntimeout = Timeout(timeout=60.0, exceptions=(ConnectionRefusedError, requests.exceptions.ConnectionError))\n\nService.launch(url)\nstatus = timeout.run(get_server_status, url)  # Will wait up to 60 seconds for the server to launch.\nprint(f\"Server status: {status}\")\n</code></pre></p> <p>Example\u2014 Using Timeout as a Decorator:     <pre><code>import requests\nfrom urllib3.util.url import parse_url, Url\nfrom mindtrace.core import Timeout\nfrom mindtrace.services import Service\n\n@Timeout(timeout=60.0, exceptions=(ConnectionRefusedError, requests.exceptions.ConnectionError))\ndef get_server_status(url: Url):\n    response = requests.request(\"POST\", str(url) + \"status\")\n    if response.status_code == 200:\n        return json.loads(response.content)[\"status\"]\n    else:\n        raise HTTPException(response.status_code, response.content)\n\nurl = parse_url(\"http://localhost:8080/\")\nService.launch(url)\n\ntry:\n    status = get_server_status(url)  # Will wait up to 60 seconds for the server to launch.\nexcept TimeoutError as e:\n    print(f\"The server did not respond within the timeout period: {e}\")  # Timeout of 60 seconds reached.\nexcept Exception as e:  # Guaranteed not to be one of the given exceptions in the exceptions tuple.\n    print(f\"An unexpected error occurred: {e}\")\nelse:\n    print(f\"Server status: {status}\")\n</code></pre></p>"},{"location":"core/api/#mindtrace.core.utils.timers.Timeout.run","title":"run","text":"<pre><code>run(func, *args, **kwargs)\n</code></pre> <p>Run the given function with the given args and kwargs.</p>"},{"location":"database/","title":"Database","text":""},{"location":"database/#mindtrace-database-module","title":"Mindtrace Database Module","text":"<p>A powerful, flexible Object-Document Mapping (ODM) system that provides a unified interface for working with multiple database backends in the Mindtrace project. Write once, run on MongoDB, Redis, or both.</p>"},{"location":"database/#key-features","title":"Key Features","text":"<ul> <li>Unified Interface - One API for multiple databases</li> <li>Multi-Model Support - Manage multiple document types in a single ODM instance</li> <li>Dynamic Switching - Switch between MongoDB and Redis at runtime</li> <li>Simplified Document Models - Define once, use everywhere</li> <li>Full Async/Sync Support - Both MongoDB and Redis support sync and async interfaces</li> <li>Seamless Interface Compatibility - Use sync code with async databases and vice versa</li> <li>Advanced Querying - Rich query capabilities across all databases</li> <li>Comprehensive Error Handling - Clear, actionable error messages</li> <li>Full Test Coverage - Thoroughly tested with unit and integration tests</li> </ul>"},{"location":"database/#quick-start","title":"Quick Start","text":""},{"location":"database/#the-simple-way-unified-documents","title":"The Simple Way: Unified Documents","text":"<p>Define your document model once and use it with any database:</p> <pre><code>from mindtrace.database import UnifiedMindtraceDocument, UnifiedMindtraceODM, BackendType\n\nfrom pydantic import Field\n\n# 1. Define your document model (works with both MongoDB and Redis)\nclass User(UnifiedMindtraceDocument):\n    name: str = Field(description=\"User's full name\")\n    age: int = Field(ge=0, description=\"User's age\")\n    email: str = Field(description=\"User's email address\")\n    skills: list[str] = Field(default_factory=list)\n\n    class Meta:\n        collection_name = \"users\"\n        global_key_prefix = \"myapp\"\n        indexed_fields = [\"email\", \"name\"]\n        unique_fields = [\"email\"]\n\n# 2. Create ODM instance (supports both MongoDB and Redis)\ndb = UnifiedMindtraceODM(\n    unified_model_cls=User,\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"myapp\",\n    redis_url=\"redis://localhost:6379\",\n    preferred_backend=BackendType.MONGO  # Start with MongoDB\n    # init_mode=InitMode.ASYNC,  # Both use ASYNC (or SYNC)\n    # If None, MongoDB defaults to ASYNC and Redis defaults to SYNC\n)\n\n# 3. Use it (Same API regardless of database - both sync and async work)\nuser = User(name=\"Alice\", age=30, email=\"alice@example.com\", skills=[\"Python\"])\n\n# Async operations (work with both MongoDB and Redis)\ninserted_user = await db.insert_async(user)\nretrieved_user = await db.get_async(inserted_user.id)\nretrieved_user.age = 31\nupdated_user = await db.update_async(retrieved_user)\npython_users = await db.find_async({\"skills\": \"Python\"})\nall_users = await db.all_async()\n\n# Sync operations (also work with both MongoDB and Redis)\ninserted_user = db.insert(user)\nretrieved_user = db.get(inserted_user.id)\nretrieved_user.age = 31\nupdated_user = db.update(retrieved_user)\npython_users = db.find({\"skills\": \"Python\"})\nall_users = db.all()\n\n# Switch databases on the fly\ndb.switch_backend(BackendType.REDIS)\nredis_user = db.insert(user)  # Now using Redis (sync)\n# or\nredis_user = await db.insert_async(user)  # Redis with async interface\n\n# Multi-model mode (works with all ODMs)\ndb = UnifiedMindtraceODM(\n    unified_models={'user': User, 'address': Address},\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"myapp\",\n    redis_url=\"redis://localhost:6379\"\n)\n\n# Access models via attributes\naddress = await db.address.insert_async(Address(street=\"123 Main St\", city=\"NYC\"))\nuser = await db.user.insert_async(User(name=\"Alice\", email=\"alice@example.com\"))\n\n# All operations work per model\nusers = await db.user.all_async()\naddresses = await db.address.all_async()\n</code></pre>"},{"location":"database/#traditional-way-database-specific-models","title":"Traditional Way: Database-Specific Models","text":"<p>If you prefer more control, you can define database-specific models:</p> <pre><code>from mindtrace.database import (\n    MongoMindtraceODM, \n    RedisMindtraceODM,\n    MindtraceDocument,\n    MindtraceRedisDocument\n)\nfrom beanie import Indexed\nfrom redis_om import Field as RedisField\nfrom typing import Annotated\n\n# MongoDB model\nclass MongoUser(MindtraceDocument):\n    name: str\n    email: Annotated[str, Indexed(unique=True)]\n    age: int\n\n    class Settings:\n        name = \"users\"\n\n# Redis model\nclass RedisUser(MindtraceRedisDocument):\n    name: str = RedisField(index=True)\n    email: str = RedisField(index=True)\n    age: int = RedisField(index=True)\n\n    class Meta:\n        global_key_prefix = \"myapp\"\n\n# Use them separately\nmongo_db = MongoMindtraceODM(\n    model_cls=MongoUser,\n    db_uri=\"mongodb://localhost:27017\",\n    db_name=\"myapp\"\n)\n\nredis_db = RedisMindtraceODM(\n    model_cls=RedisUser,\n    redis_url=\"redis://localhost:6379\"\n)\n</code></pre>"},{"location":"database/#multi-model-support","title":"Multi-Model Support","text":"<p>All ODMs now support managing multiple document types in a single instance. This allows you to work with related models (e.g., <code>User</code> and <code>Address</code>) through a single ODM instance with attribute-based access.</p>"},{"location":"database/#usage-pattern","title":"Usage Pattern","text":"<pre><code># Instead of creating separate ODMs for each model:\nuser_db = MongoMindtraceODM(model_cls=User, ...)\naddress_db = MongoMindtraceODM(model_cls=Address, ...)\n\n# Use multi-model mode:\ndb = MongoMindtraceODM(\n    models={'user': User, 'address': Address},\n    db_uri=\"mongodb://localhost:27017\",\n    db_name=\"myapp\"\n)\n\n# Access models via attributes\nawait db.user.insert(user)\nawait db.address.insert(address)\nusers = await db.user.all()\naddresses = await db.address.all()\n</code></pre> <p>Benefits: - Shared Connection - All models share the same database connection - Unified Initialization - All models initialize together - Cleaner Code - Single ODM instance instead of multiple - Consistent API - Same operations work across all models</p> <p>Note: In multi-model mode, you must use attribute-based access (<code>db.user.insert()</code>). Direct methods (<code>db.insert()</code>) will raise a <code>ValueError</code> to prevent ambiguity.</p>"},{"location":"database/#available-odms","title":"Available ODMs","text":""},{"location":"database/#1-unifiedmindtraceodm-recommended","title":"1. UnifiedMindtraceODM (Recommended)","text":"<p>The flagship ODM that provides a unified interface for multiple databases:</p> <p>Key Features: - Single Interface: One API for all databases - Runtime Switching: Change databases without code changes - Automatic Model Generation: Converts unified models to database-specific formats - Flexible Configuration: Use one or multiple databases</p> <p>Configuration Options: <pre><code># Option 1: Single unified model\ndb = UnifiedMindtraceODM(\n    unified_model_cls=MyUnifiedDoc,\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"mydb\",\n    redis_url=\"redis://localhost:6379\",\n    preferred_backend=BackendType.MONGO\n)\n\n# Option 2: Multiple unified models (multi-model mode)\ndb = UnifiedMindtraceODM(\n    unified_models={'user': User, 'address': Address},\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"mydb\",\n    redis_url=\"redis://localhost:6379\",\n    preferred_backend=BackendType.MONGO\n)\n# Access via: db.user, db.address\n\n# Option 3: Separate models\ndb = UnifiedMindtraceODM(\n    mongo_model_cls=MyMongoDoc,\n    redis_model_cls=MyRedisDoc,\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"mydb\",\n    redis_url=\"redis://localhost:6379\",\n    preferred_backend=BackendType.REDIS\n)\n\n# Option 4: Single database\ndb = UnifiedMindtraceODM(\n    unified_model_cls=MyUnifiedDoc,\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"mydb\",\n    preferred_backend=BackendType.MONGO\n)\n</code></pre></p>"},{"location":"database/#2-mongomindtraceodm","title":"2. MongoMindtraceODM","text":"<p>Specialized MongoDB ODM using Beanie. Natively async, but supports sync interface too</p>"},{"location":"database/#single-model-mode","title":"Single Model Mode","text":"<pre><code>from mindtrace.database import MongoMindtraceODM, MindtraceDocument\n\nclass User(MindtraceDocument):\n    name: str\n    email: str\n\n    class Settings:\n        name = \"users\"\n        use_cache = False\n\ndb = MongoMindtraceODM(\n    model_cls=User,\n    db_uri=\"mongodb://localhost:27017\",\n    db_name=\"myapp\"\n)\n\n# Async operations (native)\nuser = await db.insert(User(name=\"Alice\", email=\"alice@example.com\"))\nuser.age = 31\nupdated_user = await db.update(user)\nall_users = await db.all()\n\n# Sync operations (wrapper methods - use from sync code)\nuser = db.insert_sync(User(name=\"Bob\", email=\"bob@example.com\"))\nuser.age = 32\nupdated_user = db.update_sync(user)\nall_users = db.all_sync()\n\n# Supports MongoDB-specific features\npipeline = [{\"$match\": {\"age\": {\"$gte\": 18}}}]\nresults = await db.aggregate(pipeline)\n</code></pre>"},{"location":"database/#multi-model-mode","title":"Multi-Model Mode","text":"<pre><code>from mindtrace.database import MongoMindtraceODM, MindtraceDocument\n\nclass Address(MindtraceDocument):\n    street: str\n    city: str\n\n    class Settings:\n        name = \"addresses\"\n        use_cache = False\n\nclass User(MindtraceDocument):\n    name: str\n    email: str\n\n    class Settings:\n        name = \"users\"\n        use_cache = False\n\n# Create ODM with multiple models\ndb = MongoMindtraceODM(\n    models={'user': User, 'address': Address},\n    db_uri=\"mongodb://localhost:27017\",\n    db_name=\"myapp\"\n)\n\n# Access models via attribute-based access\naddress = await db.address.insert(Address(street=\"123 Main St\", city=\"NYC\"))\nuser = await db.user.insert(User(name=\"Alice\", email=\"alice@example.com\"))\n\n# All operations work per model\nusers = await db.user.all()\naddresses = await db.address.all()\n</code></pre>"},{"location":"database/#working-with-linked-documents-fetch_links","title":"Working with Linked Documents (fetch_links)","text":"<p>MongoDB supports linking documents using Beanie's <code>Link</code> type. Use <code>fetch_links=True</code> to automatically fetch linked documents:</p> <pre><code>from mindtrace.database import Link, MongoMindtraceODM, MindtraceDocument\nfrom typing import Optional\n\nclass Address(MindtraceDocument):\n    street: str\n    city: str\n\n    class Settings:\n        name = \"addresses\"\n        use_cache = False\n\nclass User(MindtraceDocument):\n    name: str\n    email: str\n    address: Optional[Link[Address]] = None\n\n    class Settings:\n        name = \"users\"\n        use_cache = False\n\ndb = MongoMindtraceODM(\n    models={'user': User, 'address': Address},\n    db_uri=\"mongodb://localhost:27017\",\n    db_name=\"myapp\"\n)\n\n# Create linked documents\naddress = await db.address.insert(Address(street=\"123 Main St\", city=\"NYC\"))\nuser = await db.user.insert(User(name=\"Alice\", email=\"alice@example.com\", address=address))\n\n# Fetch with linked documents using fetch_links=True\nuser_with_address = await db.user.get(user.id, fetch_links=True)\nprint(f\"User: {user_with_address.name}, Address: {user_with_address.address.street}\")\n\n# Find with linked documents\nusers = await db.user.find(User.name == \"Alice\", fetch_links=True)\nfor u in users:\n    if u.address:\n        print(f\"{u.name} lives at {u.address.street}\")\n\n# Without fetch_links, address will be a Link object (not fetched)\nuser_without_links = await db.user.get(user.id)\n# user_without_links.address is a Link object, not the actual Address document\n</code></pre>"},{"location":"database/#3-redismindtraceodm","title":"3. RedisMindtraceODM","text":"<p>High-performance Redis ODM with JSON support. Natively sync, but supports async interface too</p>"},{"location":"database/#single-model-mode_1","title":"Single Model Mode","text":"<pre><code>from mindtrace.database import RedisMindtraceODM, MindtraceRedisDocument\nfrom redis_om import Field\n\nclass User(MindtraceRedisDocument):\n    name: str = Field(index=True)\n    email: str = Field(index=True)\n    age: int = Field(index=True)\n\n    class Meta:\n        global_key_prefix = \"myapp\"\n\ndb = RedisMindtraceODM(\n    model_cls=User,\n    redis_url=\"redis://localhost:6379\"\n)\n\n# Sync operations (native)\nuser = db.insert(User(name=\"Alice\", email=\"alice@example.com\"))\nuser.age = 31\nupdated_user = db.update(user)\nall_users = db.all()\n\n# Async operations (wrapper methods - use from async code)\nuser = await db.insert_async(User(name=\"Bob\", email=\"bob@example.com\"))\nuser.age = 32\nupdated_user = await db.update_async(user)\nall_users = await db.all_async()\n\n# Supports Redis-specific queries\nusers = db.find(User.age &gt;= 18)\n</code></pre>"},{"location":"database/#multi-model-mode_1","title":"Multi-Model Mode","text":"<pre><code>from mindtrace.database import RedisMindtraceODM, MindtraceRedisDocument\nfrom redis_om import Field\n\nclass Address(MindtraceRedisDocument):\n    street: str = Field(index=True)\n    city: str = Field(index=True)\n\n    class Meta:\n        global_key_prefix = \"myapp\"\n\nclass User(MindtraceRedisDocument):\n    name: str = Field(index=True)\n    email: str = Field(index=True)\n    address_id: Optional[str] = None\n\n    class Meta:\n        global_key_prefix = \"myapp\"\n\n# Create ODM with multiple models\ndb = RedisMindtraceODM(\n    models={'user': User, 'address': Address},\n    redis_url=\"redis://localhost:6379\"\n)\n\n# Access models via attribute-based access\naddress = db.address.insert(Address(street=\"123 Main St\", city=\"NYC\"))\nuser = db.user.insert(User(name=\"Alice\", email=\"alice@example.com\", address_id=address.id))\n\n# All operations work per model\nusers = db.user.all()\naddresses = await db.address.all_async()\n</code></pre>"},{"location":"database/#4-registrymindtraceodm","title":"4. RegistryMindtraceODM","text":"<p>Flexible ODM using the Mindtrace Registry system, supporting local storage, GCP, and other storage options:</p>"},{"location":"database/#single-model-mode_2","title":"Single Model Mode","text":"<pre><code>from mindtrace.database import RegistryMindtraceODM, DocumentNotFoundError\nfrom mindtrace.registry import Registry, Archiver\nfrom typing import Any, Type\nfrom pydantic import BaseModel\nfrom pathlib import Path\n\nclass User(BaseModel):\n    name: str\n    email: str\n\nclass UserArchiver(Archiver):\n    def save(self, user: User):\n        with open(Path(self.uri) / \"user.json\", \"w\") as f:\n            f.write(user.model_dump_json())\n\n    def load(self, data_type: Type[Any]) -&gt; User:\n        with open(Path(self.uri) / \"user.json\", \"r\") as f:\n            return User.model_validate_json(f.read())\n\nRegistry.register_default_materializer(User, UserArchiver)\n\ndb = RegistryMindtraceODM(model_cls=User)\n\nuser = User(name=\"John Doe\", email=\"john.doe@example.com\")\ninserted_user = db.insert(user)\n\n# Update the user\ninserted_user.name = \"John Smith\"\nupdated_user = db.update(inserted_user)\n\n# Retrieve by ID (raises DocumentNotFoundError if not found)\ntry:\n    user = db.get(inserted_user.id)\nexcept DocumentNotFoundError:\n    print(\"User not found\")\n</code></pre>"},{"location":"database/#multi-model-mode_2","title":"Multi-Model Mode","text":"<pre><code>from mindtrace.database import RegistryMindtraceODM\nfrom mindtrace.registry import Registry, Archiver\nfrom typing import Any, Type\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    email: str\n\nclass Address(BaseModel):\n    street: str\n    city: str\n\n# Register materializers for both models\nRegistry.register_default_materializer(User, UserArchiver)\nRegistry.register_default_materializer(Address, AddressArchiver)\n\n# Create ODM with multiple models\ndb = RegistryMindtraceODM(\n    models={'user': User, 'address': Address}\n)\n\n# Access models via attribute-based access\naddress = db.address.insert(Address(street=\"123 Main St\", city=\"NYC\"))\nuser = db.user.insert(User(name=\"John Doe\", email=\"john@example.com\"))\n\n# All operations work per model\nusers = db.user.all()\naddresses = db.address.all()\n</code></pre> <p>With GCP Storage:</p> <pre><code>from mindtrace.database import RegistryMindtraceODM\nfrom mindtrace.registry import Registry, GCPRegistryBackend, Archiver\nfrom typing import Any, Type\nfrom pydantic import BaseModel\nfrom pathlib import Path\n\nclass User(BaseModel):\n    name: str\n    email: str\n\nclass UserArchiver(Archiver):\n    def save(self, user: User):\n        with open(Path(self.uri) / \"user.json\", \"w\") as f:\n            f.write(user.model_dump_json())\n\n    def load(self, data_type: Type[Any]) -&gt; User:\n        with open(Path(self.uri) / \"user.json\", \"r\") as f:\n            return User.model_validate_json(f.read())\n\nRegistry.register_default_materializer(User, UserArchiver)\n\ngcp_registry_backend = GCPRegistryBackend(\n    uri=\"gs://my-bucket\",\n    project_id=\"my-project\",\n    bucket_name=\"my-bucket\",\n)\n\ndb = RegistryMindtraceODM(model_cls=User, backend=gcp_registry_backend)\n\nuser = User(name=\"John Doe\", email=\"john.doe@example.com\")\ninserted_user = db.insert(user)\n\n# Update the user\ninserted_user.name = \"John Smith\"\nupdated_user = db.update(inserted_user)\n\n# Retrieve by ID\nuser = db.get(inserted_user.id)\n</code></pre>"},{"location":"database/#api-reference","title":"API Reference","text":""},{"location":"database/#core-operations","title":"Core Operations","text":"<p>All ODMs support both sync and async interfaces for all operations. Choose the style that fits your codebase.</p>"},{"location":"database/#async-operations-recommended-for-async-code","title":"Async Operations (Recommended for async code)","text":"<pre><code># Insert a document\ninserted_doc = await db.insert_async(doc)\n\n# Get document by ID\ndoc = await db.get_async(\"doc_id\")\n\n# Get document with linked documents (MongoDB only)\ndoc_with_links = await db.get_async(\"doc_id\", fetch_links=True)\n\n# Update document\ndoc.name = \"Updated Name\"\nupdated_doc = await db.update_async(doc)\n\n# Delete document\nawait db.delete_async(\"doc_id\")\n\n# Get all documents\nall_docs = await db.all_async()\n\n# Find documents with filters\nresults = await db.find_async({\"name\": \"Alice\"})\n\n# Find documents with linked documents (MongoDB only)\nresults_with_links = await db.find_async({\"name\": \"Alice\"}, fetch_links=True)\n</code></pre>"},{"location":"database/#sync-operations-works-with-both-mongodb-and-redis","title":"Sync Operations (Works with both MongoDB and Redis)","text":"<pre><code># Insert a document\ninserted_doc = db.insert(doc)\n\n# Get document by ID\ndoc = db.get(\"doc_id\")\n\n# Update document\ndoc.name = \"Updated Name\"\nupdated_doc = db.update(doc)\n\n# Delete document\ndb.delete(\"doc_id\")\n\n# Get all documents\nall_docs = db.all()\n\n# Find documents with filters\nresults = db.find({\"name\": \"Alice\"})\n</code></pre> <p>Note:  - MongoDB: Sync methods use wrapper functions that run async code in an event loop - Redis: Async methods run sync operations in a thread pool to avoid blocking the event loop - Unified ODM: Automatically routes to the appropriate method based on the active database - Document IDs: All backends provide a consistent <code>id</code> attribute on returned documents (MongoDB uses <code>id</code>, Redis uses <code>pk</code> internally but exposes it as <code>id</code>)</p>"},{"location":"database/#syncasync-compatibility","title":"Sync/Async Compatibility","text":"<p>Both MongoDB and Redis ODMs support both interfaces:</p> Database Native Interface Wrapper Interface MongoDB Async (<code>insert</code>, <code>get</code>, etc.) Sync (<code>insert_sync</code>, <code>get_sync</code>, etc.) Redis Sync (<code>insert</code>, <code>get</code>, etc.) Async (<code>insert_async</code>, <code>get_async</code>, etc.) <p>This means you can: - Use sync code with MongoDB (via sync wrappers) - Use async code with Redis (via async wrappers) - Mix and match based on your needs</p>"},{"location":"database/#unifiedmindtraceodm-specific","title":"UnifiedMindtraceODM Specific","text":"<p>Additional methods for the unified ODM:</p> <pre><code># Database management\ndb.switch_backend(BackendType.REDIS)\ncurrent_type = db.get_current_backend_type()\nis_async = db.is_async()\n\n# Database availability\nhas_mongo = db.has_mongo_backend()\nhas_redis = db.has_redis_backend()\n\n# Direct access to underlying ODMs\nmongo_odm = db.get_mongo_backend()\nredis_odm = db.get_redis_backend()\n\n# Model access\nraw_model = db.get_raw_model()\nunified_model = db.get_unified_model()\n</code></pre>"},{"location":"database/#advanced-querying","title":"Advanced Querying","text":""},{"location":"database/#mongodb-through-unifiedmindtraceodm","title":"MongoDB (through UnifiedMindtraceODM)","text":"<pre><code>from mindtrace.database import Link\n\n# MongoDB-style queries\nusers = await db.find_async({\"age\": {\"$gte\": 18}})\nusers = await db.find_async({\"skills\": {\"$in\": [\"Python\", \"JavaScript\"]}})\n\n# Fetch linked documents using fetch_links=True\nuser = await db.get_async(user_id, fetch_links=True)\nif user.address:\n    print(f\"User lives at {user.address.street}\")\n\n# Find with linked documents\nusers = await db.find_async({\"name\": \"Alice\"}, fetch_links=True)\nfor u in users:\n    if u.address:\n        print(f\"{u.name} - {u.address.city}\")\n\n# Using Beanie expressions with links (get raw model first)\nUserMongo = db.get_raw_model()\nusers = await db.find_async(UserMongo.name == \"Alice\", fetch_links=True)\n\n# Aggregation pipelines (when using MongoDB)\nif db.get_current_backend_type() == BackendType.MONGO:\n    pipeline = [\n        {\"$match\": {\"age\": {\"$gte\": 18}}},\n        {\"$group\": {\"_id\": \"$department\", \"count\": {\"$sum\": 1}}}\n    ]\n    results = await db.get_mongo_backend().aggregate(pipeline)\n</code></pre>"},{"location":"database/#redis-through-unifiedmindtraceodm","title":"Redis (through UnifiedMindtraceODM)","text":"<pre><code># Switch to Redis for these queries\ndb.switch_backend(BackendType.REDIS)\n\n# Redis OM expressions\nModel = db.get_raw_model()\nusers = db.find(Model.age &gt;= 18)\nusers = db.find(Model.name == \"Alice\")\nusers = db.find(Model.skills &lt;&lt; \"Python\")  # Contains\n</code></pre>"},{"location":"database/#initialization-options","title":"Initialization Options","text":"<p>By default, ODMs auto-initialize on first operation. For more control, use constructor parameters:</p> <pre><code>from mindtrace.database import InitMode\n\ndb = UnifiedMindtraceODM(\n    unified_model_cls=User,\n    mongo_db_uri=\"mongodb://localhost:27017\",\n    mongo_db_name=\"myapp\",\n    redis_url=\"redis://localhost:6379\",\n    preferred_backend=BackendType.MONGO,\n    auto_init=True,              # Initialize at creation time\n    init_mode=InitMode.SYNC,     # Use sync initialization\n)\n</code></pre> <p>InitMode options: - <code>InitMode.SYNC</code> - Synchronous initialization (blocks until complete) - <code>InitMode.ASYNC</code> - Deferred initialization (completes on first async operation)</p> <p>Default behavior: - MongoDB defaults to <code>InitMode.ASYNC</code> - Redis defaults to <code>InitMode.SYNC</code></p>"},{"location":"database/#error-handling","title":"Error Handling","text":"<p>The module provides comprehensive error handling with consistent exceptions across all backends:</p> <pre><code>from mindtrace.database import DocumentNotFoundError, DuplicateInsertError\n\ntry:\n    user = await db.get_async(\"non_existent_id\")\nexcept DocumentNotFoundError as e:\n    print(f\"User not found: {e}\")\n\ntry:\n    await db.insert_async(duplicate_user)\nexcept DuplicateInsertError as e:\n    print(f\"User already exists: {e}\")\n\n# All backends raise DocumentNotFoundError (not KeyError) for consistency\ntry:\n    user = db.get(\"missing_id\")\nexcept DocumentNotFoundError:\n    print(\"Document not found\")\n\n# Multi-model mode errors\ntry:\n    db.insert(user)  # In multi-model mode, this raises ValueError\nexcept ValueError as e:\n    print(f\"Use db.model_name.insert() instead: {e}\")\n</code></pre> <pre><code>from mindtrace.database import DocumentNotFoundError, DuplicateInsertError\n\ntry:\n    user = await db.get_async(\"non_existent_id\")\nexcept DocumentNotFoundError as e:\n    print(f\"User not found: {e}\")\n\ntry:\n    await db.insert_async(duplicate_user)\nexcept DuplicateInsertError as e:\n    print(f\"User already exists: {e}\")\n</code></pre>"},{"location":"database/#testing","title":"Testing","text":"<p>The database module includes comprehensive test coverage with both unit and integration tests.</p>"},{"location":"database/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/mindtrace/database/          # Unit tests (no DB required)\n\u2502   \u251c\u2500\u2500 test_mongo_unit.py\n\u2502   \u251c\u2500\u2500 test_redis_unit.py\n\u2502   \u251c\u2500\u2500 test_registry_odm_backend.py\n\u2502   \u2514\u2500\u2500 test_unified_unit.py\n\u2514\u2500\u2500 integration/mindtrace/database/   # Integration tests (DB required)\n    \u251c\u2500\u2500 test_mongo.py\n    \u251c\u2500\u2500 test_redis_odm.py\n    \u251c\u2500\u2500 test_registry_odm.py\n    \u2514\u2500\u2500 test_unified.py\n</code></pre>"},{"location":"database/#running-tests","title":"Running Tests","text":""},{"location":"database/#quick-start-all-tests","title":"Quick Start - All Tests","text":"<pre><code>ds test: database\n</code></pre>"},{"location":"database/#unit-tests-only","title":"Unit Tests Only","text":"<pre><code>ds test: database --unit\n</code></pre>"},{"location":"database/#integration-tests-containers-managed-by-test-script","title":"Integration Tests (Containers managed by test script)","text":"<pre><code>ds test: database --integration\n</code></pre>"},{"location":"database/#targeted-testing","title":"Targeted Testing","text":"<pre><code># Test only unified backend\nds test: tests/integration/mindtrace/database/test_unified.py\n\n# Test only MongoDB\nds test: tests/integration/mindtrace/database/test_mongo.py\n\n# Test only Redis\nds test: tests/integration/mindtrace/database/test_redis_odm.py\n</code></pre>"},{"location":"database/#test-coverage","title":"Test Coverage","text":"<p>The test suite covers:</p> <ul> <li>CRUD Operations - Create, Read, Update, Delete</li> <li>Query Operations - Find, filter, search</li> <li>Error Handling - All exception scenarios</li> <li>Database Switching - Dynamic database changes</li> <li>Async/Sync Compatibility - Both programming styles</li> <li>Model Conversion - Unified to database-specific models</li> <li>Edge Cases - Duplicate keys, missing documents, invalid queries</li> </ul>"},{"location":"database/#examples","title":"Examples","text":""},{"location":"database/#complete-example-user-management-system","title":"Complete Example: User Management System","text":"<pre><code>import asyncio\nfrom mindtrace.database import (\n    UnifiedMindtraceODM,\n    UnifiedMindtraceDocument,\n    BackendType,\n    DocumentNotFoundError\n)\nfrom pydantic import Field\nfrom typing import List\n\nclass User(UnifiedMindtraceDocument):\n    name: str = Field(description=\"Full name\")\n    email: str = Field(description=\"Email address\")  \n    age: int = Field(ge=0, le=150, description=\"Age\")\n    department: str = Field(description=\"Department\")\n    skills: List[str] = Field(default_factory=list)\n\n    class Meta:\n        collection_name = \"employees\"\n        global_key_prefix = \"company\"\n        indexed_fields = [\"email\", \"department\", \"skills\"]\n        unique_fields = [\"email\"]\n\nasync def main():\n    # Setup with both MongoDB and Redis\n    db = UnifiedMindtraceODM(\n        unified_model_cls=User,\n        mongo_db_uri=\"mongodb://localhost:27017\",\n        mongo_db_name=\"company\",\n        redis_url=\"redis://localhost:6379\",\n        preferred_backend=BackendType.MONGO\n    )\n\n    # Create some users\n    users = [\n        User(\n            name=\"Alice Johnson\",\n            email=\"alice@company.com\",\n            age=30,\n            department=\"Engineering\",\n            skills=[\"Python\", \"MongoDB\", \"Docker\"]\n        ),\n        User(\n            name=\"Bob Smith\", \n            email=\"bob@company.com\",\n            age=25,\n            department=\"Engineering\",\n            skills=[\"JavaScript\", \"Redis\", \"React\"]\n        ),\n        User(\n            name=\"Carol Davis\",\n            email=\"carol@company.com\", \n            age=35,\n            department=\"Marketing\",\n            skills=[\"Analytics\", \"SQL\"]\n        )\n    ]\n\n    # Insert users\n    print(\"Creating users...\")\n    for user in users:\n        try:\n            inserted = await db.insert_async(user)\n            print(f\"Created: {inserted.name} (ID: {inserted.id})\")\n        except Exception as e:\n            print(f\"Failed to create {user.name}: {e}\")\n\n    # Find engineers\n    print(\"\\nFinding engineers...\")\n    engineers = await db.find_async({\"department\": \"Engineering\"})\n    for eng in engineers:\n        print(f\"{eng.name} - Skills: {', '.join(eng.skills)}\")\n\n    # Switch to Redis for fast lookups\n    print(\"\\nSwitching to Redis for fast operations...\")\n    db.switch_backend(BackendType.REDIS)\n\n    # Insert more users in Redis (both sync and async work)\n    redis_user = User(\n        name=\"Dave Wilson\",\n        email=\"dave@company.com\",\n        age=28,\n        department=\"DevOps\",\n        skills=[\"Kubernetes\", \"Redis\", \"Monitoring\"]\n    )\n\n    # Use sync interface (native for Redis)\n    redis_inserted = db.insert(redis_user)\n    print(f\"Redis user created (sync): {redis_inserted.name}\")\n\n    # Or use async interface (wrapper for Redis)\n    redis_user2 = User(\n        name=\"Eve Brown\",\n        email=\"eve@company.com\",\n        age=32,\n        department=\"DevOps\",\n        skills=[\"Docker\", \"CI/CD\"]\n    )\n    redis_inserted2 = await db.insert_async(redis_user2)\n    print(f\"Redis user created (async): {redis_inserted2.name}\")\n\n    # Demonstrate data isolation\n    print(f\"\\nMongoDB users: {len(await db.get_mongo_backend().all())}\")\n    print(f\"Redis users: {len(db.get_redis_backend().all())}\")\n\n    # Switch back to MongoDB\n    db.switch_backend(BackendType.MONGO)\n    print(f\"Back to MongoDB - Users: {len(await db.all_async())}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"database/#more-examples","title":"More Examples","text":"<p>Check out the <code>samples/database/</code> directory for additional examples:</p> <ul> <li><code>using_unified_backend.py</code> - Comprehensive unified ODM usage</li> <li>Advanced querying patterns</li> <li>Database switching strategies</li> <li>Error handling best practices</li> </ul>"},{"location":"database/#best-practices","title":"Best Practices","text":""},{"location":"database/#1-model-design","title":"1. Model Design","text":"<pre><code># Good: Clear, descriptive models\nclass Product(UnifiedMindtraceDocument):\n    name: str = Field(description=\"Product name\", min_length=1)\n    price: float = Field(ge=0, description=\"Price in USD\")\n    category: str = Field(description=\"Product category\")\n\n    class Meta:\n        collection_name = \"products\"\n        indexed_fields = [\"category\", \"name\"]\n        unique_fields = [\"name\"]\n\n# Avoid: Unclear models without validation\nclass Product(UnifiedMindtraceDocument):\n    n: str\n    p: float\n    c: str\n</code></pre>"},{"location":"database/#2-error-handling","title":"2. Error Handling","text":"<pre><code># Always handle database exceptions\ntry:\n    user = await db.get_async(user_id)\n    print(f\"Found user: {user.name}\")\nexcept DocumentNotFoundError:\n    print(\"User not found - creating new user\")\n    user = await db.insert_async(User(name=\"New User\", email=\"new@example.com\"))\nexcept Exception as e:\n    logger.error(f\"Database error: {e}\")\n    # Handle appropriately\n</code></pre>"},{"location":"database/#3-database-selection","title":"3. Database Selection","text":"<pre><code># Choose database based on use case\nif high_frequency_reads:\n    db.switch_backend(BackendType.REDIS)  # Fast reads\nelse:\n    db.switch_backend(BackendType.MONGO)  # Complex queries\n</code></pre>"},{"location":"database/#contributing","title":"Contributing","text":"<p>When adding new features:</p> <ol> <li>Add tests - Both unit and integration tests</li> <li>Update documentation - Keep README and docstrings current</li> <li>Follow patterns - Use existing code style and patterns</li> <li>Test thoroughly - Run the full test suite</li> </ol>"},{"location":"database/#requirements","title":"Requirements","text":"<ul> <li>MongoDB 4.4+ (for MongoMindtraceODM)</li> <li>Redis 6.0+ (for RedisMindtraceODM)</li> <li>Core dependencies: <code>pydantic</code>, <code>beanie</code>, <code>redis-om-python</code></li> </ul>"},{"location":"database/#need-help","title":"Need Help?","text":"<ul> <li>Check the <code>samples/database/</code> directory for working examples</li> <li>Look at the test files for usage patterns</li> <li>Review the docstrings in the source code for detailed API documentation</li> </ul> <p>The Mindtrace Database Module makes it easy to work with multiple databases through a single, powerful interface.</p>"},{"location":"database/#breaking-changes","title":"Breaking Changes","text":""},{"location":"database/#class-name-changes-v060","title":"Class Name Changes (v0.6.0)","text":"<p>All ODM class names have been simplified by removing the \"Backend\" suffix:</p> Old Name New Name <code>MindtraceODMBackend</code> <code>MindtraceODM</code> <code>MongoMindtraceODMBackend</code> <code>MongoMindtraceODM</code> <code>RedisMindtraceODMBackend</code> <code>RedisMindtraceODM</code> <code>RegistryMindtraceODMBackend</code> <code>RegistryMindtraceODM</code> <code>UnifiedMindtraceODMBackend</code> <code>UnifiedMindtraceODM</code> <p>File names also updated:</p> Old File New File <code>mindtrace_odm_backend.py</code> <code>mindtrace_odm.py</code> <code>mongo_odm_backend.py</code> <code>mongo_odm.py</code> <code>redis_odm_backend.py</code> <code>redis_odm.py</code> <code>registry_odm_backend.py</code> <code>registry_odm.py</code> <code>unified_odm_backend.py</code> <code>unified_odm.py</code> <p>Migration:</p> <pre><code># Old\nfrom mindtrace.database import MongoMindtraceODMBackend, UnifiedMindtraceODMBackend\ndb = MongoMindtraceODMBackend(model_cls=User, db_uri=\"...\", db_name=\"...\")\n\n# New\nfrom mindtrace.database import MongoMindtraceODM, UnifiedMindtraceODM\ndb = MongoMindtraceODM(model_cls=User, db_uri=\"...\", db_name=\"...\")\n</code></pre>"},{"location":"database/api/","title":"Database Package API Reference","text":""},{"location":"hardware/","title":"Hardware","text":""},{"location":"hardware/#mindtrace-hardware-component","title":"Mindtrace Hardware Component","text":"<p>The Mindtrace Hardware Component provides a unified, industrial-grade interface for managing 2D cameras, 3D stereo cameras, PLCs, sensors, and actuators. Built with a service-first architecture, it offers multiple interface levels from simple scripts to production automation systems.</p>"},{"location":"hardware/#overview","title":"\ud83c\udfaf Overview","text":"<p>Key Differentiators: - Service-Based Architecture: Modern REST APIs with MCP integration for all hardware components - Multi-Level Interfaces: From simple synchronous to industrial async with bandwidth management - 3D Vision Support: Stereo cameras for depth measurement, 3D inspection, and point cloud generation - Network Bandwidth Management: Critical for GigE cameras with intelligent concurrent capture limiting - Unified Configuration System: Single configuration for all hardware components - Production-Ready: Comprehensive exception handling, async operations, graceful degradation - Industrial Integration: Real-time PLC coordination with multiple addressing schemes - Vision-to-Physical Measurement: Homography-based pixel-to-world coordinate transformation - Extensible Design: Easy backend addition with consistent patterns</p>"},{"location":"hardware/#hardware-management-tools","title":"\ud83d\udee0\ufe0f Hardware Management Tools","text":""},{"location":"hardware/#cli-tools","title":"CLI Tools","text":"<p>The hardware system includes comprehensive command-line management tools for development, testing, and production deployment.</p> <p>Key Features: - Service lifecycle management with PID tracking - Health monitoring and status reporting - Network configuration and port management - Environment variable integration - Browser auto-launch for web interfaces</p> <p>Quick Start: <pre><code># Start camera services (API + web configurator)\nmindtrace-hw camera start\n\n# Start stereo camera service (API only)\nmindtrace-hw stereo start\n\n# Start PLC service (API only)\nmindtrace-hw plc start\n\n# Check service status with access URLs\nmindtrace-hw status\n\n# Stop all services gracefully\nmindtrace-hw stop\n</code></pre></p> <p>\u2192 See CLI Documentation for comprehensive usage examples, configuration options, and troubleshooting guides.</p> <p>SDK Setup Commands: <pre><code># Basler 2D cameras - Pylon Viewer &amp; IP Configurator (optional)\nmindtrace-camera-basler install       # Guided wizard for Pylon SDK tools\nmindtrace-camera-basler uninstall\n\n# GenICam cameras - CTI files (required for camera discovery)\nmindtrace-camera-genicam install      # Install Matrix Vision GenTL Producer\nmindtrace-camera-genicam verify       # Verify CTI installation\nmindtrace-camera-genicam uninstall\n\n# Stereo 3D cameras - Supplementary Package (required for 3D vision)\nmindtrace-stereo-basler install       # Guided wizard for stereo libraries\nmindtrace-stereo-basler uninstall\n</code></pre></p>"},{"location":"hardware/#camera-configurator-app","title":"Camera Configurator App","text":"<p>A standalone Reflex web application providing intuitive camera management with real-time streaming capabilities.</p> <p>Key Features: - Multi-backend camera discovery (Basler, GenICam, OpenCV) - Real-time MJPEG streaming with dynamic quality/FPS control - Interactive parameter configuration with range validation - Configuration import/export as JSON files - Live camera status monitoring - Responsive modern UI with state-driven updates</p> <p>Access via CLI: <pre><code># Launch both API and configurator app\nmindtrace-hw camera start\n# Opens browser automatically to http://localhost:3000\n\n# API-only mode for headless operation\nmindtrace-hw camera start --api-only\n</code></pre></p> <p>\u2192 See App Documentation for detailed features, API integration, configuration management, and troubleshooting.</p>"},{"location":"hardware/#hardware-component-architecture","title":"\ud83c\udfd7\ufe0f HARDWARE COMPONENT ARCHITECTURE","text":""},{"location":"hardware/#directory-structure","title":"Directory Structure","text":"<pre><code>mindtrace/hardware/\n\u2514\u2500\u2500 mindtrace/hardware/\n    \u251c\u2500\u2500 __init__.py           # Lazy imports: CameraManager, PLCManager\n    \u251c\u2500\u2500 api/                  # Service layer\n    \u2502   \u251c\u2500\u2500 cameras/          # CameraManagerService + client\n    \u2502   \u2502   \u251c\u2500\u2500 service.py         # REST endpoints + MCP tools\n    \u2502   \u2502   \u251c\u2500\u2500 launcher.py        # Service launcher and startup\n    \u2502   \u2502   \u251c\u2500\u2500 connection_manager.py # Python client\n    \u2502   \u2502   \u251c\u2500\u2500 models/            # Request/response models\n    \u2502   \u2502   \u2514\u2500\u2500 schemas/           # TaskSchema definitions\n    \u2502   \u251c\u2500\u2500 stereo_cameras/   # StereoCameraService + client\n    \u2502   \u2502   \u251c\u2500\u2500 service.py         # REST endpoints + MCP tools\n    \u2502   \u2502   \u251c\u2500\u2500 launcher.py        # Service launcher and startup\n    \u2502   \u2502   \u251c\u2500\u2500 connection_manager.py # Python client\n    \u2502   \u2502   \u251c\u2500\u2500 models/            # Request/response models\n    \u2502   \u2502   \u2514\u2500\u2500 schemas/           # TaskSchema definitions\n    \u2502   \u2514\u2500\u2500 plcs/             # PLCManagerService + client\n    \u2502       \u251c\u2500\u2500 service.py         # REST endpoints + MCP tools\n    \u2502       \u251c\u2500\u2500 launcher.py        # Service launcher and startup\n    \u2502       \u251c\u2500\u2500 connection_manager.py # Python client\n    \u2502       \u251c\u2500\u2500 models/            # Request/response models\n    \u2502       \u2514\u2500\u2500 schemas/           # TaskSchema definitions\n    \u251c\u2500\u2500 apps/                 # Web applications\n    \u2502   \u2514\u2500\u2500 camera_configurator/   # Reflex-based camera management app\n    \u2502       \u251c\u2500\u2500 camera_configurator/\n    \u2502       \u2502   \u251c\u2500\u2500 components/    # UI components (cards, modals, layouts)\n    \u2502       \u2502   \u251c\u2500\u2500 pages/         # Application pages\n    \u2502       \u2502   \u251c\u2500\u2500 services/      # API client integration\n    \u2502       \u2502   \u251c\u2500\u2500 state/         # Reactive state management\n    \u2502       \u2502   \u2514\u2500\u2500 styles/        # Theme and styling\n    \u2502       \u251c\u2500\u2500 rxconfig.py        # Reflex configuration\n    \u2502       \u2514\u2500\u2500 uploaded_files/    # Configuration file uploads\n    \u251c\u2500\u2500 cli/                  # Command-line interface\n    \u2502   \u251c\u2500\u2500 __main__.py       # CLI entry point\n    \u2502   \u251c\u2500\u2500 commands/         # Command implementations\n    \u2502   \u2502   \u251c\u2500\u2500 camera.py          # Camera service management + testing\n    \u2502   \u2502   \u251c\u2500\u2500 stereo.py          # Stereo camera service management\n    \u2502   \u2502   \u251c\u2500\u2500 plc.py             # PLC service management\n    \u2502   \u2502   \u2514\u2500\u2500 status.py          # Global status commands\n    \u2502   \u251c\u2500\u2500 core/             # Core CLI functionality\n    \u2502   \u2502   \u251c\u2500\u2500 process_manager.py # Service lifecycle with PID tracking\n    \u2502   \u2502   \u2514\u2500\u2500 logger.py          # Structured CLI logging\n    \u2502   \u2514\u2500\u2500 utils/            # CLI utilities\n    \u2502       \u251c\u2500\u2500 display.py         # Terminal formatting\n    \u2502       \u2514\u2500\u2500 network.py         # Port checking and health\n    \u251c\u2500\u2500 core/\n    \u2502   \u251c\u2500\u2500 config.py         # Unified hardware configuration\n    \u2502   \u2514\u2500\u2500 exceptions.py     # Hardware exception hierarchy\n    \u251c\u2500\u2500 cameras/\n    \u2502   \u251c\u2500\u2500 core/            # Core camera interfaces\n    \u2502   \u2502   \u251c\u2500\u2500 camera.py         # Synchronous interface\n    \u2502   \u2502   \u251c\u2500\u2500 async_camera.py   # Asynchronous interface\n    \u2502   \u2502   \u251c\u2500\u2500 camera_manager.py # Sync multi-camera manager\n    \u2502   \u2502   \u2514\u2500\u2500 async_camera_manager.py # Async + bandwidth mgmt\n    \u2502   \u251c\u2500\u2500 backends/        # Camera implementations\n    \u2502   \u2502   \u251c\u2500\u2500 basler/      # Basler + mock\n    \u2502   \u2502   \u251c\u2500\u2500 genicam/     # GenICam + mock\n    \u2502   \u2502   \u2514\u2500\u2500 opencv/      # OpenCV implementation\n    \u2502   \u251c\u2500\u2500 homography/      # Planar measurement system\n    \u2502   \u2502   \u251c\u2500\u2500 data.py           # CalibrationData, MeasuredBox models\n    \u2502   \u2502   \u251c\u2500\u2500 calibrator.py     # HomographyCalibrator (checkerboard/manual)\n    \u2502   \u2502   \u2514\u2500\u2500 measurer.py       # HomographyMeasurer (bbox/distance)\n    \u2502   \u2514\u2500\u2500 setup/           # Camera setup utilities\n    \u2502       \u251c\u2500\u2500 setup_cameras.py   # Interactive camera setup\n    \u2502       \u251c\u2500\u2500 setup_basler.py    # Basler SDK setup\n    \u2502       \u2514\u2500\u2500 setup_genicam.py   # GenICam CTI setup\n    \u251c\u2500\u2500 stereo_cameras/      # Stereo camera system (3D vision)\n    \u2502   \u251c\u2500\u2500 core/            # Core stereo interfaces\n    \u2502   \u2502   \u251c\u2500\u2500 stereo_camera.py   # Async stereo camera interface\n    \u2502   \u2502   \u2514\u2500\u2500 stereo_manager.py  # Multi-stereo camera manager\n    \u2502   \u251c\u2500\u2500 backends/        # Stereo camera implementations\n    \u2502   \u2502   \u2514\u2500\u2500 basler/      # Basler stereo ace cameras\n    \u2502   \u2514\u2500\u2500 setup/           # Stereo camera setup utilities\n    \u2502       \u2514\u2500\u2500 setup_basler.py    # Basler stereo ace SDK setup\n    \u251c\u2500\u2500 plcs/\n    \u2502   \u251c\u2500\u2500 core/\n    \u2502   \u2502   \u2514\u2500\u2500 plc_manager.py    # PLC management interface\n    \u2502   \u2514\u2500\u2500 backends/\n    \u2502       \u2514\u2500\u2500 allen_bradley/    # LogixDriver, SLCDriver, CIPDriver\n    \u251c\u2500\u2500 sensors/             # Sensor management (extensible)\n    \u2514\u2500\u2500 tests/unit/          # Comprehensive test suite\n</code></pre>"},{"location":"hardware/#installation","title":"Installation","text":"<pre><code># Clone and install with camera support\ngit clone https://github.com/Mindtrace/mindtrace.git\ncd mindtrace\nuv sync --extra cameras-all\n\n# For stereo cameras (3D/depth)\nuv sync --extra stereo-all\n</code></pre>"},{"location":"hardware/#sdk-requirements-by-camera-type","title":"SDK Requirements by Camera Type","text":"Camera Type Python Package External SDK Why? Basler 2D <code>pypylon</code> Optional pypylon is self-contained for camera operations. Install Pylon SDK only if you need the Viewer or IP Configurator tools for diagnostics. GenICam <code>harvesters</code> Required Harvesters needs GenTL Producer (.cti files) to discover and communicate with cameras. The Matrix Vision SDK provides this. Stereo ace <code>pypylon</code> Required 3D vision requires the Basler Stereo ace Supplementary Package for rectification, disparity, and point cloud libraries. <p>SDK Setup (when needed): <pre><code># Basler 2D: Only if you need Pylon Viewer / IP Configurator\nmindtrace-camera-basler install\n\n# GenICam: Required for camera discovery\nmindtrace-camera-genicam install\n\n# Stereo ace: Required for 3D vision capabilities\nmindtrace-stereo-basler install\n</code></pre></p> <p>Each setup command launches a guided wizard that opens your browser to the vendor's official download page, where you accept the EULA and download the package. The wizard then handles installation from your downloaded file.</p>"},{"location":"hardware/#camera-system","title":"\ud83d\udcf7 CAMERA SYSTEM","text":"<p>The camera system provides four interface levels, each optimized for different use cases from prototyping to industrial automation.</p>"},{"location":"hardware/#interface-hierarchy","title":"Interface Hierarchy","text":"Interface Async Multi-Camera Bandwidth Mgmt Service API Use Case Camera \u274c \u274c \u274c \u274c Simple scripts, prototyping AsyncCamera \u2705 \u274c \u274c \u274c Performance-critical single camera CameraManager \u274c \u2705 \u274c \u274c Multi-camera sync applications AsyncCameraManager \u2705 \u2705 \u2705 \u274c Industrial automation systems CameraManagerService \u2705 \u2705 \u2705 \u2705 Service-based integration"},{"location":"hardware/#core-usage-patterns","title":"Core Usage Patterns","text":""},{"location":"hardware/#simple-camera-prototyping","title":"Simple Camera (Prototyping)","text":"<pre><code>from mindtrace.hardware.cameras.core.camera import Camera\n\n# Direct camera usage - no async needed\ncamera = Camera(name=\"OpenCV:opencv_camera_0\")\nimage = camera.capture()\ncamera.configure(exposure=15000, gain=2.0)\ncamera.close()\n</code></pre>"},{"location":"hardware/#async-camera-manager-industrial","title":"Async Camera Manager (Industrial)","text":"<pre><code>import asyncio\nfrom mindtrace.hardware import CameraManager\n\nasync def industrial_capture():\n    # Network bandwidth management critical for GigE cameras\n    async with CameraManager(max_concurrent_captures=2) as manager:\n        cameras = manager.discover()\n        await manager.open(cameras[0])\n        camera_proxy = await manager.open(cameras[0])\n\n        # Bandwidth-managed capture\n        image = await camera_proxy.capture()\n        await camera_proxy.configure(exposure=15000, gain=2.0)\n\nasyncio.run(industrial_capture())\n</code></pre>"},{"location":"hardware/#service-architecture","title":"Service Architecture","text":"<p>The CameraManagerService provides enterprise-grade camera management with REST API and MCP integration.</p>"},{"location":"hardware/#launch-service","title":"Launch Service","text":"<pre><code>from mindtrace.hardware.api import CameraManagerService\n\n# Launch with REST API + MCP\nCameraManagerService.launch(\n    port=8001,\n    include_mocks=True,\n    block=True\n)\n</code></pre>"},{"location":"hardware/#programmatic-client","title":"Programmatic Client","text":"<pre><code>from mindtrace.hardware.api import CameraManagerConnectionManager\nfrom urllib3.util.url import parse_url\n\nasync def service_example():\n    client = CameraManagerConnectionManager(url=parse_url(\"http://localhost:8001\"))\n\n    cameras = await client.discover_cameras()\n    await client.open_camera(cameras[0], test_connection=True)\n\n    result = await client.capture_image(\n        camera=cameras[0],\n        save_path=\"/tmp/image.jpg\"\n    )\n</code></pre>"},{"location":"hardware/#key-service-endpoints","title":"Key Service Endpoints","text":"Category Essential Endpoints Description Discovery <code>discover_backends</code>, <code>discover_cameras</code> Backend and camera discovery Lifecycle <code>open_camera</code>, <code>close_camera</code>, <code>get_active_cameras</code> Camera management Capture <code>capture_image</code>, <code>capture_hdr_image</code>, <code>capture_images_batch</code> Image acquisition Configuration <code>configure_camera</code>, <code>get_camera_capabilities</code> Camera settings System <code>get_system_diagnostics</code>, <code>get_bandwidth_settings</code> Monitoring"},{"location":"hardware/#mcp-integration","title":"MCP Integration","text":"<p>16 essential camera operations are automatically exposed as MCP tools:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mindtrace_cameras\": {\n      \"url\": \"http://localhost:8001/mcp-server/mcp/\"\n    }\n  }\n}\n</code></pre>"},{"location":"hardware/#supported-camera-backends","title":"Supported Camera Backends","text":"Backend SDK Features Use Case Basler pypylon High-performance industrial, GigE, multicast streaming Production automation GenICam harvesters GenICam-compliant cameras, Keyence VJ, network cameras Industrial inspection OpenCV opencv-python USB cameras, webcams, IP cameras Development, testing Mock Built-in Configurable test patterns Testing, CI/CD"},{"location":"hardware/#genicam-backend","title":"GenICam Backend","text":"<p>The GenICam backend provides support for GenICam-compliant industrial cameras through the Harvesters library with Matrix Vision GenTL Producer integration.</p> <p>Supported Cameras: - Keyence VJ series cameras - Basler cameras via GenICam protocol - Any GenICam-compliant network cameras</p> <p>Key Features: - GenTL Producer interface via Harvesters - Matrix Vision mvIMPACT Acquire SDK integration - Network camera discovery and configuration - ROI controls and white balance management - Hardware trigger and continuous capture modes - Vendor-specific parameter handling</p> <p>Installation: <pre><code># Install with GenICam support\nuv sync --extra cameras-genicam\n\n# Setup GenICam CTI files (required - Matrix Vision SDK)\n# This is necessary because Harvesters requires GenTL Producer files\n# to discover and communicate with GenICam-compliant cameras\nmindtrace-camera-genicam install\n\n# Verify installation\nmindtrace-camera-genicam verify\n</code></pre></p> <p>Usage: <pre><code>from mindtrace.hardware.cameras.backends.genicam import GenICamCameraBackend\n\n# Discover GenICam cameras\ncameras = GenICamCameraBackend.get_available_cameras()\n\n# Initialize with image quality enhancement\ncamera = GenICamCameraBackend(\"device_serial\", img_quality_enhancement=True)\nsuccess, cam_obj, remote_obj = await camera.initialize()\n\nif success:\n    await camera.set_exposure(50000)\n    await camera.set_triggermode(\"continuous\")\n    image = await camera.capture()\n    await camera.close()\n</code></pre></p> <p>Requirements: - Harvesters library (<code>harvesters&gt;=1.4.3</code>) - GenICam Python bindings (<code>genicam&gt;=1.5.0</code>) - Matrix Vision mvIMPACT Acquire SDK - GenTL Producer (.cti file) - automatically detected or configurable via <code>GENICAM_CTI_PATH</code> - Network interface configuration for GigE cameras</p> <p>CTI Path Detection: The GenICam backend automatically detects the CTI file location using this priority order: 1. <code>GENICAM_CTI_PATH</code> environment variable (if set) 2. Platform-specific default paths:    - Linux x86_64: <code>/opt/ImpactAcquire/lib/x86_64/mvGenTLProducer.cti</code>    - Linux ARM64: <code>/opt/ImpactAcquire/lib/arm64/mvGenTLProducer.cti</code>    - Windows x64: <code>C:\\Program Files\\MATRIX VISION\\mvIMPACT Acquire\\bin\\win64\\mvGenTLProducer.cti</code>    - macOS: <code>/Applications/ImpactAcquire/lib/mvGenTLProducer.cti</code> 3. Alternative common paths in <code>/usr/lib</code>, <code>/usr/local/lib</code>, and user home directory</p>"},{"location":"hardware/#basler-backend-features","title":"Basler Backend Features","text":"<p>Note: The <code>pypylon</code> package is fully self-contained for camera operations. No external SDK installation is required to capture images, configure cameras, or use the Basler backend. The optional Pylon SDK (<code>mindtrace-camera-basler install</code>) provides GUI tools like Pylon Viewer and IP Configurator for camera diagnostics and network configuration.</p> <p>Multicast Streaming: - IP-based camera discovery for targeted multicast setup - Standard and IP-targeted initialization paths - <code>configure_streaming()</code> method for GigE Vision multicast configuration - Multicast group and port configuration via environment variables - Broadcasting to specific multicast groups with bandwidth management</p> <p>ExposureTime Parameter Support: - Automatic fallback between ExposureTime and ExposureTimeAbs parameters - Compatible across different Basler camera models - Supports multicast timing and initialization</p> <p>Multicast Configuration: <pre><code># Multicast settings\nexport MINDTRACE_HW_CAMERA_BASLER_MULTICAST_GROUP=\"239.192.1.1\"\nexport MINDTRACE_HW_CAMERA_BASLER_MULTICAST_PORT=\"3956\"\nexport MINDTRACE_HW_CAMERA_BASLER_ENABLE_MULTICAST=\"true\"\n</code></pre></p>"},{"location":"hardware/#homography-measurement-system","title":"Homography Measurement System","text":"<p>The homography module provides planar measurement capabilities for converting pixel-space detections to real-world metric dimensions.</p> <p>Core Capabilities: - \u2705 Automatic checkerboard calibration with sub-pixel accuracy - \u2705 Manual point correspondence calibration for custom targets - \u2705 Bounding box dimension measurement (width, height, area) - \u2705 Point-to-point distance measurement - \u2705 Unified batch measurement (boxes and distances in one request) - \u2705 Multi-unit support (mm, cm, m, in, ft) with automatic conversion - \u2705 RANSAC-based robust estimation with outlier rejection</p>"},{"location":"hardware/#quick-start","title":"Quick Start","text":"<pre><code>from mindtrace.hardware import HomographyCalibrator, HomographyMeasurer\n\n# Calibrate using checkerboard\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),    # Inner corners\n    square_size=25.0,        # mm per square\n    world_unit=\"mm\"\n)\ncalibration.save(\"camera_calibration.json\")\n\n# Measure object dimensions\nmeasurer = HomographyMeasurer(calibration)\nmeasured = measurer.measure_bounding_box(detection_bbox, target_unit=\"cm\")\nprint(f\"Size: {measured.width_world:.2f} \u00d7 {measured.height_world:.2f} cm\")\n\n# Measure distance between two points\ndistance, unit = measurer.measure_distance(\n    point1=(100, 150),\n    point2=(300, 400),\n    target_unit=\"mm\"\n)\n</code></pre>"},{"location":"hardware/#service-integration","title":"Service Integration","text":"<p>The Camera Manager Service provides REST API endpoints for automated measurement workflows:</p> <pre><code># Calibrate from checkerboard\ncurl -X POST http://localhost:8002/cameras/homography/calibrate/checkerboard \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"image_path\": \"/path/to/checkerboard.png\", \"square_size\": 25.0}'\n\n# Unified batch measurement (boxes and distances)\ncurl -X POST http://localhost:8002/cameras/homography/measure/batch \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"calibration_path\": \"/path/to/calibration.json\",\n    \"bounding_boxes\": [{\"x\": 100, \"y\": 150, \"width\": 200, \"height\": 150}],\n    \"point_pairs\": [[[50, 50], [250, 50]], [[100, 200], [300, 400]]],\n    \"target_unit\": \"mm\"\n  }'\n</code></pre> <p>Typical Workflow: 1. Place calibration checkerboard in camera view 2. Calibrate: <code>POST /cameras/homography/calibrate/checkerboard</code> 3. Detect objects with vision model (YOLO, etc.) 4. Batch measure: <code>POST /cameras/homography/measure/batch</code></p> <p>\u2192 See Homography Documentation for calibration methods, use cases, performance optimization, and troubleshooting.</p>"},{"location":"hardware/#stereo-camera-system","title":"\ud83d\udcd0 STEREO CAMERA SYSTEM","text":"<p>The stereo camera system provides 3D vision and depth measurement capabilities using Basler stereo ace cameras for industrial 3D inspection, measurement, and automation applications.</p>"},{"location":"hardware/#overview_1","title":"Overview","text":"<p>Stereo cameras enable precise 3D measurements, depth mapping, and volume calculations for applications such as: - Bin picking and robotic guidance - 3D object inspection and quality control - Volume and dimension measurement - Obstacle detection and navigation - Pick and place automation</p>"},{"location":"hardware/#interface-hierarchy_1","title":"Interface Hierarchy","text":"Interface Async Multi-Camera Service API Use Case StereoCamera \u2705 \u274c \u274c Single stereo camera applications StereoCameraManager \u2705 \u2705 \u274c Multi-stereo camera systems StereoCameraService \u2705 \u2705 \u2705 Service-based integration"},{"location":"hardware/#core-usage-patterns_1","title":"Core Usage Patterns","text":""},{"location":"hardware/#basic-stereo-camera-usage","title":"Basic Stereo Camera Usage","text":"<pre><code>import asyncio\nfrom mindtrace.hardware.stereo_cameras import StereoCamera\n\nasync def capture_3d():\n    camera = StereoCamera(name=\"Basler:stereo_camera_0\")\n\n    try:\n        await camera.initialize()\n        await camera.configure(exposure=10000, trigger_mode=\"software\")\n\n        # Capture rectified stereo pair\n        rectified = await camera.capture_rectified()\n        print(f\"Left: {rectified.left_image.shape}\")\n        print(f\"Right: {rectified.right_image.shape}\")\n\n        # Capture 3D point cloud\n        point_cloud = await camera.capture_point_cloud()\n        print(f\"Point cloud: {point_cloud.points.shape}\")\n        print(f\"Depth range: {point_cloud.range_min} - {point_cloud.range_max} mm\")\n\n    finally:\n        await camera.close()\n\nasyncio.run(capture_3d())\n</code></pre>"},{"location":"hardware/#multi-camera-stereo-manager","title":"Multi-Camera Stereo Manager","text":"<pre><code>from mindtrace.hardware.stereo_cameras import StereoCameraManager\n\nasync def multi_stereo():\n    async with StereoCameraManager() as manager:\n        cameras = await manager.discover()\n\n        # Open multiple stereo cameras\n        cam1 = await manager.open(cameras[0])\n        cam2 = await manager.open(cameras[1])\n\n        # Synchronized capture from multiple stereo rigs\n        results = await manager.capture_batch([\n            (cam1, {\"exposure\": 10000}),\n            (cam2, {\"exposure\": 15000})\n        ])\n</code></pre>"},{"location":"hardware/#service-architecture_1","title":"Service Architecture","text":"<p>The StereoCameraService provides REST API and MCP integration for stereo camera management.</p>"},{"location":"hardware/#launch-service_1","title":"Launch Service","text":"<pre><code># Via CLI (recommended)\nmindtrace-hw stereo start\n\n# Programmatically\nfrom mindtrace.hardware.api.stereo_cameras import StereoCameraService\n\nStereoCameraService.launch(\n    host=\"localhost\",\n    port=8004,\n    block=True\n)\n</code></pre>"},{"location":"hardware/#programmatic-client_1","title":"Programmatic Client","text":"<pre><code>from mindtrace.hardware.api.stereo_cameras import StereoCameraConnectionManager\n\nasync def service_example():\n    client = StereoCameraConnectionManager(\"http://localhost:8004\")\n\n    # Discover and open stereo cameras\n    cameras = await client.discover_cameras()\n    await client.open_camera(cameras[0])\n\n    # Capture 3D data\n    point_cloud = await client.capture_point_cloud(\n        camera=cameras[0],\n        save_path=\"/tmp/scan.ply\"\n    )\n\n    # Measure 3D dimensions\n    measurements = await client.measure_3d_bounding_box(\n        camera=cameras[0],\n        bbox={\"x\": 100, \"y\": 150, \"width\": 200, \"height\": 150}\n    )\n</code></pre>"},{"location":"hardware/#cli-integration","title":"CLI Integration","text":"<p>The stereo camera service is fully integrated into the hardware CLI:</p> <pre><code># Start stereo camera API service\nmindtrace-hw stereo start\n\n# Custom configuration\nmindtrace-hw stereo start --api-host 0.0.0.0 --api-port 8005\n\n# Open API documentation in browser\nmindtrace-hw stereo start --open-docs\n\n# Check service status\nmindtrace-hw stereo status\n\n# Stop service\nmindtrace-hw stereo stop\n\n# View logs\nmindtrace-hw stereo logs\n</code></pre>"},{"location":"hardware/#key-service-endpoints_1","title":"Key Service Endpoints","text":"Category Essential Endpoints Description Discovery <code>discover_cameras</code>, <code>get_camera_info</code> Camera discovery and capabilities Lifecycle <code>open_camera</code>, <code>close_camera</code>, <code>get_active_cameras</code> Camera management 3D Capture <code>capture_point_cloud</code>, <code>capture_rectified</code>, <code>capture_depth_map</code> 3D data acquisition Measurement <code>measure_3d_box</code>, <code>measure_distance</code>, <code>measure_volume</code> 3D measurements Configuration <code>configure_camera</code>, <code>calibrate_stereo</code> Camera settings and calibration"},{"location":"hardware/#api-access","title":"API Access","text":"<pre><code># API Documentation\nhttp://localhost:8004/docs          # Swagger UI\nhttp://localhost:8004/redoc         # ReDoc\n\n# Example API Call\ncurl -X POST http://localhost:8004/cameras/capture/point-cloud \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"camera_name\": \"stereo_camera_0\", \"save_path\": \"/tmp/scan.ply\"}'\n</code></pre>"},{"location":"hardware/#supported-features","title":"Supported Features","text":""},{"location":"hardware/#basler-stereo-ace-backend","title":"Basler Stereo ace Backend","text":"<p>Key Capabilities: - \u2705 Rectified stereo pair capture (left/right images) - \u2705 3D point cloud generation with confidence mapping - \u2705 Depth map computation with range validation - \u2705 Factory calibration data with distortion correction - \u2705 Software and hardware trigger support - \u2705 Configurable ROI and scan parameters - \u2705 Multiple output formats (PLY, PCD, NumPy)</p> <p>Camera Models: - Basler stereo ace a2A1920-160um (1920x1200, 160 fps) - Basler stereo ace a2A1920-51um (1920x1200, 51 fps) - Basler stereo ace a2A2590-60um (2590x1942, 60 fps)</p> <p>Installation: <pre><code># Install with stereo camera support\nuv sync --extra stereo-all\n\n# Setup Basler Stereo ace Supplementary Package (required - Linux only)\n# This provides the 3D vision libraries for rectification, disparity\n# computation, and point cloud generation that pypylon alone doesn't include\nmindtrace-stereo-basler install\n\n# Verify installation\npython -c \"from pypylon import pylon; print('Stereo SDK ready')\"\n</code></pre></p>"},{"location":"hardware/#configuration","title":"Configuration","text":""},{"location":"hardware/#service-configuration","title":"Service Configuration","text":"<pre><code># Environment variables\nexport STEREO_CAMERA_API_HOST=\"localhost\"\nexport STEREO_CAMERA_API_PORT=\"8004\"\nexport STEREO_CAMERA_API_URL=\"http://localhost:8004\"\n\n# Core settings\nexport MINDTRACE_HW_STEREO_TIMEOUT_MS=\"10000\"\nexport MINDTRACE_HW_STEREO_DEFAULT_EXPOSURE=\"10000\"\n</code></pre>"},{"location":"hardware/#stereo-camera-settings","title":"Stereo Camera Settings","text":"<pre><code>from mindtrace.hardware.core.config import get_hardware_config\n\nconfig = get_hardware_config()\nstereo_settings = config.get_config().stereo_cameras\n\n# Capture settings\nstereo_settings.timeout_ms = 10000\nstereo_settings.default_exposure = 10000\nstereo_settings.trigger_mode = \"software\"\n\n# 3D processing\nstereo_settings.confidence_threshold = 0.5\nstereo_settings.depth_range_min = 100.0  # mm\nstereo_settings.depth_range_max = 2000.0  # mm\n</code></pre>"},{"location":"hardware/#plc-system","title":"\ud83c\udfed PLC SYSTEM","text":"<p>The PLC system provides comprehensive industrial automation support with async operations and multiple driver types for different PLC families.</p>"},{"location":"hardware/#interface-hierarchy_2","title":"Interface Hierarchy","text":"Interface Async Multi-PLC Batch Ops Service API Use Case PLCManager \u2705 \u2705 \u2705 \u274c Multi-PLC automation systems PLCManagerService \u2705 \u2705 \u2705 \u2705 Service-based integration"},{"location":"hardware/#core-interface","title":"Core Interface","text":"<pre><code>import asyncio\nfrom mindtrace.hardware import PLCManager\n\nasync def plc_automation():\n    manager = PLCManager()\n\n    # Register PLC with appropriate driver\n    await manager.register_plc(\"ProductionPLC\", \"192.168.1.100\", plc_type=\"logix\")\n    await manager.connect_plc(\"ProductionPLC\")\n\n    # Read/write operations\n    values = await manager.read_tags(\"ProductionPLC\", [\"Motor1_Speed\", \"Conveyor_Status\"])\n    await manager.write_tag(\"ProductionPLC\", \"Pump1_Command\", True)\n\n    await manager.cleanup()\n</code></pre>"},{"location":"hardware/#allen-bradley-driver-types","title":"Allen Bradley Driver Types","text":"Driver Target PLCs Addressing Key Features LogixDriver ControlLogix, CompactLogix Tag-based (<code>Motor1_Speed</code>) Tag discovery, data type detection SLCDriver SLC500, MicroLogix Data files (<code>N7:0</code>, <code>B3:1</code>) Timer/Counter support, I/O files CIPDriver PowerFlex, I/O Modules CIP objects (<code>Parameter:10</code>) Drive parameters, assembly objects"},{"location":"hardware/#tag-addressing-examples","title":"Tag Addressing Examples","text":"<pre><code># Logix-style (ControlLogix/CompactLogix)\nlogix_tags = [\"Production_Ready\", \"Part_Count\", \"Motor1_Speed\"]\n\n# SLC-style (SLC500/MicroLogix) \nslc_tags = [\"N7:0\", \"B3:1\", \"T4:0.ACC\"]  # Integer, Binary, Timer\n\n# CIP-style (Drives/I/O Modules)\ncip_tags = [\"Parameter:10\", \"Parameter:11\"]\n</code></pre>"},{"location":"hardware/#batch-operations","title":"Batch Operations","text":"<pre><code># Multi-PLC coordination\nbatch_data = [\n    (\"ProductionPLC\", [\"Production_Ready\", \"Part_Count\"]),      # Logix\n    (\"PackagingPLC\", [\"N7:0\", \"B3:0\"]),                       # SLC  \n    (\"QualityPLC\", [\"Parameter:10\", \"Parameter:11\"])           # CIP\n]\n\nresults = await manager.read_tags_batch(batch_data)\n# Returns: {'ProductionPLC': {...}, 'PackagingPLC': {...}, 'QualityPLC': {...}}\n</code></pre>"},{"location":"hardware/#service-architecture_2","title":"Service Architecture","text":"<p>The PLCManagerService provides enterprise-grade PLC management with REST API and MCP integration.</p>"},{"location":"hardware/#launch-service_2","title":"Launch Service","text":"<pre><code>from mindtrace.hardware.api import PLCManagerService\n\n# Launch with REST API + MCP\nPLCManagerService.launch(\n    port=8003,\n    block=True\n)\n</code></pre>"},{"location":"hardware/#programmatic-client_2","title":"Programmatic Client","text":"<pre><code>from mindtrace.hardware.api import PLCManagerConnectionManager\n\nasync def service_example():\n    client = PLCManagerConnectionManager(\"http://localhost:8003\")\n\n    # Connect to PLC\n    await client.connect_plc(\n        plc_name=\"RTU_LUBE_SYSTEM\",\n        backend=\"AllenBradley\",\n        ip_address=\"192.168.160.3\",\n        plc_type=\"logix\"\n    )\n\n    # Read tags\n    values = await client.read_tags(\n        plc=\"RTU_LUBE_SYSTEM\",\n        tags=[\"Robot_Status\", \"Robot_Position_X\"]\n    )\n\n    # Write tags\n    await client.write_tags(\n        plc=\"RTU_LUBE_SYSTEM\",\n        tags=[(\"Robot_Command\", 1), (\"Target_X\", 150.0)]\n    )\n</code></pre>"},{"location":"hardware/#key-service-endpoints_2","title":"Key Service Endpoints","text":"Category Essential Endpoints Description Discovery <code>discover_backends</code>, <code>discover_plcs</code> Backend and PLC discovery Lifecycle <code>connect_plc</code>, <code>disconnect_plc</code>, <code>get_active_plcs</code> PLC management Tag Operations <code>tag_read</code>, <code>tag_write</code>, <code>tag_list</code> Tag read/write operations System <code>get_plc_status</code>, <code>get_system_diagnostics</code> Monitoring"},{"location":"hardware/#mcp-integration_1","title":"MCP Integration","text":"<p>16 essential PLC operations are automatically exposed as MCP tools:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mindtrace_plcs\": {\n      \"url\": \"http://localhost:8003/mcp-server/mcp/\"\n    }\n  }\n}\n</code></pre>"},{"location":"hardware/#configuration_1","title":"Configuration","text":"<pre><code>plc_settings = config.get_config().plcs\n\n# Connection management\nplc_settings.connection_timeout = 10.0\nplc_settings.read_timeout = 5.0\nplc_settings.write_timeout = 5.0\nplc_settings.max_concurrent_connections = 10\n</code></pre>"},{"location":"hardware/#system-integration","title":"\ud83d\udd27 SYSTEM INTEGRATION","text":""},{"location":"hardware/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>HardwareError\n\u251c\u2500\u2500 HardwareOperationError\n\u251c\u2500\u2500 HardwareTimeoutError\n\u2514\u2500\u2500 SDKNotAvailableError\n\nCameraError (extends HardwareError)\n\u251c\u2500\u2500 CameraNotFoundError\n\u251c\u2500\u2500 CameraCaptureError\n\u251c\u2500\u2500 CameraConfigurationError\n\u2514\u2500\u2500 CameraConnectionError\n\nPLCError (extends HardwareError)\n\u251c\u2500\u2500 PLCConnectionError\n\u251c\u2500\u2500 PLCCommunicationError\n\u2514\u2500\u2500 PLCTagError\n    \u251c\u2500\u2500 PLCTagNotFoundError\n    \u251c\u2500\u2500 PLCTagReadError\n    \u2514\u2500\u2500 PLCTagWriteError\n</code></pre>"},{"location":"hardware/#configuration-management","title":"Configuration Management","text":""},{"location":"hardware/#environment-variables","title":"Environment Variables","text":"<pre><code># Network bandwidth (critical for GigE)\nexport MINDTRACE_HW_CAMERA_MAX_CONCURRENT_CAPTURES=\"2\"\n\n# Camera settings\nexport MINDTRACE_HW_CAMERA_DEFAULT_EXPOSURE=\"1000.0\"\nexport MINDTRACE_HW_CAMERA_TIMEOUT_MS=\"5000\"\n\n# PLC settings  \nexport MINDTRACE_HW_PLC_CONNECTION_TIMEOUT=\"10.0\"\nexport MINDTRACE_HW_PLC_READ_TIMEOUT=\"5.0\"\n\n# Backend control\nexport MINDTRACE_HW_CAMERA_BASLER_ENABLED=\"true\"\nexport MINDTRACE_HW_CAMERA_GENICAM_ENABLED=\"true\"\nexport MINDTRACE_HW_PLC_ALLEN_BRADLEY_ENABLED=\"true\"\n\n# Basler multicast settings\nexport MINDTRACE_HW_CAMERA_BASLER_MULTICAST_GROUP=\"239.192.1.1\"\nexport MINDTRACE_HW_CAMERA_BASLER_MULTICAST_PORT=\"3956\"\nexport MINDTRACE_HW_CAMERA_BASLER_ENABLE_MULTICAST=\"true\"\n\n# GenICam settings (optional - auto-detected if not set)\nexport GENICAM_CTI_PATH=\"/opt/ImpactAcquire/lib/x86_64/mvGenTLProducer.cti\"\nexport MINDTRACE_HW_CAMERA_GENICAM_IMAGE_QUALITY_ENHANCEMENT=\"true\"\n</code></pre>"},{"location":"hardware/#configuration-file","title":"Configuration File","text":"<pre><code>{\n  \"cameras\": {\n    \"max_concurrent_captures\": 2,\n    \"trigger_mode\": \"continuous\",\n    \"exposure_time\": 1000.0,\n    \"timeout_ms\": 5000\n  },\n  \"plcs\": {\n    \"connection_timeout\": 10.0,\n    \"read_timeout\": 5.0,\n    \"max_concurrent_connections\": 10\n  },\n  \"backends\": {\n    \"basler_enabled\": true,\n    \"genicam_enabled\": true,\n    \"opencv_enabled\": true,\n    \"allen_bradley_enabled\": true,\n    \"mock_enabled\": false\n  },\n  \"basler\": {\n    \"multicast_group\": \"239.192.1.1\",\n    \"multicast_port\": 3956,\n    \"enable_multicast\": true\n  },\n  \"genicam\": {\n    \"cti_path\": \"/opt/ImpactAcquire/lib/x86_64/mvGenTLProducer.cti\",\n    \"image_quality_enhancement\": true,\n    \"timeout_ms\": 5000,\n    \"buffer_count\": 10\n  }\n}\n</code></pre>"},{"location":"hardware/#testing","title":"Testing","text":""},{"location":"hardware/#unit-tests","title":"Unit Tests","text":"<pre><code># All hardware unit tests\npytest mindtrace/hardware/tests/unit/\n\n# Specific component tests\npytest mindtrace/hardware/tests/unit/cameras/\npytest mindtrace/hardware/tests/unit/plcs/\n</code></pre>"},{"location":"hardware/#integration-tests","title":"Integration Tests","text":"<pre><code># Hardware integration tests (SDK integration without physical hardware)\npytest tests/integration/mindtrace/hardware/\n\n# Basler pypylon SDK integration (Docker-based)\npytest tests/integration/mindtrace/hardware/cameras/backends/basler/test_basler_pypylon_integration.py\n\n# Hardware backend integration tests\npytest tests/integration/mindtrace/hardware/cameras/backends/basler/test_basler_hardware_integration.py\n</code></pre>"},{"location":"hardware/#docker-pylon-runtime","title":"Docker Pylon Runtime","text":"<p>Run Basler Pylon SDK integration tests using Docker without installing pypylon locally:</p> <pre><code># Build and run pypylon runtime service\ndocker build -f /home/yasser/mindtrace/tests/docker/pypylon-runtime.Dockerfile -t pypylon-runtime .\n\n# The Docker container provides:\n# - Complete Basler Pylon SDK (8.1.0)\n# - pypylon Python binding\n# - Service mode for integration testing\n# - Health checks for SDK verification\n</code></pre> <p>Docker Features: - Full SDK Integration: Real pypylon SDK without hardware dependencies - Service Mode: Proxy system for integration testing - Health Checks: Automatic SDK verification (<code>python3 -c \"from pypylon import pylon\"</code>) - Volume Support: <code>/tmp/pypylon</code> for service communication - Environment Ready: <code>PYPYLON_AVAILABLE=true</code>, <code>PYTHONPATH=/workspace</code></p>"},{"location":"hardware/#mock-testing","title":"Mock Testing","text":"<pre><code># Enable mocks for development\nexport MINDTRACE_HW_CAMERA_MOCK_ENABLED=true\nexport MINDTRACE_HW_CAMERA_MOCK_COUNT=25\nexport MINDTRACE_HW_PLC_MOCK_ENABLED=true\n</code></pre>"},{"location":"hardware/#industrial-automation-example","title":"Industrial Automation Example","text":"<pre><code>import asyncio\nfrom mindtrace.hardware import CameraManager, PLCManager\n\nasync def industrial_system():\n    \"\"\"Complete industrial automation with cameras and PLCs.\"\"\"\n\n    # Initialize with bandwidth management\n    async with CameraManager(max_concurrent_captures=2) as camera_manager:\n        plc_manager = PLCManager()\n\n        try:\n            # Setup cameras\n            cameras = camera_manager.discover()\n            await camera_manager.open(cameras[0])\n            inspection_camera = await camera_manager.open(cameras[0])\n\n            # Setup PLCs with different drivers\n            await plc_manager.register_plc(\"ProductionPLC\", \"192.168.1.100\", plc_type=\"logix\")\n            await plc_manager.register_plc(\"PackagingPLC\", \"192.168.1.101\", plc_type=\"slc\") \n            await plc_manager.connect_all_plcs()\n\n            # Production cycle\n            for cycle in range(10):\n                # Check PLC status across different addressing schemes\n                status_batch = [\n                    (\"ProductionPLC\", [\"Production_Ready\", \"Part_Count\"]),\n                    (\"PackagingPLC\", [\"N7:0\", \"B3:0\"])  # Integer file, Binary file\n                ]\n\n                status_results = await plc_manager.read_tags_batch(status_batch)\n                production_ready = status_results[\"ProductionPLC\"][\"Production_Ready\"]\n                packaging_ready = status_results[\"PackagingPLC\"][\"B3:0\"]\n\n                if production_ready and packaging_ready:\n                    # Coordinated operations\n                    print(f\"\ud83d\udd04 Production cycle {cycle + 1} starting\")\n\n                    # Start production sequence\n                    await plc_manager.write_tags_batch([\n                        (\"ProductionPLC\", [(\"Start_Production\", True)]),\n                        (\"PackagingPLC\", [(\"B3:1\", True)])  # Start packaging\n                    ])\n\n                    # Wait for part detection\n                    part_detected = await plc_manager.read_tag(\"ProductionPLC\", \"PartDetector_Sensor\")\n                    if part_detected:\n                        # Capture inspection image (bandwidth managed)\n                        image = await inspection_camera.capture(f\"/tmp/inspection_{cycle:03d}.jpg\")\n                        print(f\"\ud83d\udcf8 Captured inspection image: {image.shape}\")\n\n                    # Update counters\n                    current_count = await plc_manager.read_tag(\"ProductionPLC\", \"Part_Count\")\n                    await plc_manager.write_tag(\"ProductionPLC\", \"Part_Count\", current_count + 1)\n\n                    print(f\"\u2705 Cycle {cycle + 1} completed\")\n\n                await asyncio.sleep(2)\n\n        finally:\n            await plc_manager.cleanup()\n\n# Run industrial automation\nasyncio.run(industrial_system())\n</code></pre>"},{"location":"hardware/#adding-new-hardware-components","title":"Adding New Hardware Components","text":"<ol> <li>Create component directory: <code>mindtrace/hardware/[component]/</code></li> <li>Follow established patterns: Core interface + backends + mock implementation  </li> <li>Add configuration: Update <code>core/config.py</code></li> <li>Add exceptions: Update <code>core/exceptions.py</code></li> <li>Create tests: Add to <code>tests/unit/[component]/</code></li> <li>Optional service layer: Follow CameraManagerService pattern</li> <li>Update documentation: Add usage examples to README</li> </ol>"},{"location":"hardware/#license","title":"\ud83d\udcc4 License","text":"<p>This component is part of the Mindtrace project. See the main project LICENSE file for details.</p>"},{"location":"hardware/api/","title":"Hardware Package API Reference","text":"<p>Mindtrace Hardware Module</p> <p>A comprehensive hardware abstraction layer providing unified access to cameras, PLCs, sensors, and other industrial hardware components with lazy imports to prevent cross-contamination between different backends.</p> Key Features <ul> <li>Lazy import system to avoid loading all backends at startup</li> <li>Unified interface for different hardware types</li> <li>Async-first design for optimal performance</li> <li>Thread-safe operations across all components</li> <li>Comprehensive error handling and logging</li> <li>Configuration management system</li> <li>Mock backends for testing and development</li> </ul> Hardware Components <ul> <li>CameraManager: Unified camera management (Basler, OpenCV)</li> <li>PLCManager: Unified PLC management (Allen-Bradley, Siemens, Modbus)</li> <li>SensorManager: Sensor data acquisition and monitoring (MQTT, HTTP, Serial)</li> <li>SensorManagerService: Service wrapper for SensorManager with MCP endpoints</li> <li>ActuatorManager: Actuator control and positioning (Future)</li> </ul> Design Philosophy <p>This module uses lazy imports to prevent SWIG warnings from pycomm3 appearing in camera tests, and to avoid loading heavy SDKs unless they are actually needed. Each manager is only imported when accessed.</p> Usage Configuration <p>All hardware components use the unified configuration system: - Environment variables with MINDTRACE_HW_ prefix - JSON configuration files - Programmatic configuration via dataclasses - Hierarchical configuration inheritance</p> Thread Safety <p>All hardware managers are thread-safe and can be used concurrently from multiple threads without interference.</p>"},{"location":"hardware/api/#mindtrace.hardware--import-managers-only-when-needed","title":"Import managers only when needed","text":"<p>from mindtrace.hardware import CameraManager, PLCManager, SensorManager from mindtrace.hardware.api.sensors import SensorManagerService</p>"},{"location":"hardware/api/#mindtrace.hardware--camera-operations","title":"Camera operations","text":"<p>async with CameraManager() as camera_manager:     cameras = camera_manager.discover()     camera = await camera_manager.open(cameras[0])     image = await camera.capture()</p>"},{"location":"hardware/api/#mindtrace.hardware--plc-operations","title":"PLC operations","text":"<p>async with PLCManager() as plc_manager:     await plc_manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")     await plc_manager.connect_plc(\"PLC1\")     values = await plc_manager.read_tag(\"PLC1\", [\"Tag1\", \"Tag2\"])</p>"},{"location":"hardware/api/#mindtrace.hardware--sensor-operations-direct-manager","title":"Sensor operations (direct manager)","text":"<p>async with SensorManager() as sensor_manager:     await sensor_manager.connect_sensor(\"temp1\", \"mqtt\", config, \"sensors/temp\")     data = await sensor_manager.read_sensor_data(\"temp1\")</p>"},{"location":"hardware/api/#mindtrace.hardware--sensor-operations-service-with-mcp-endpoints","title":"Sensor operations (service with MCP endpoints)","text":"<p>service = SensorManagerService() response = await service.connect_sensor(connection_request)</p>"},{"location":"hardware/api/#mindtrace.hardware.api","title":"api","text":"<p>Hardware API modules.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager","title":"CameraManagerConnectionManager","text":"<pre><code>CameraManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for CameraManagerService.</p> <p>Provides strongly-typed methods for all camera management operations, making it easy to use the service programmatically from other applications.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get","title":"get  <code>async</code>","text":"<pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.post","title":"post  <code>async</code>","text":"<pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.discover_backends","title":"discover_backends  <code>async</code>","text":"<pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available camera backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_backend_info","title":"get_backend_info  <code>async</code>","text":"<pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.discover_cameras","title":"discover_cameras  <code>async</code>","text":"<pre><code>discover_cameras(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available cameras from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of camera names in format 'Backend:device_name'</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.open_camera","title":"open_camera  <code>async</code>","text":"<pre><code>open_camera(camera: str, test_connection: bool = True) -&gt; bool\n</code></pre> <p>Open a single camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name in format 'Backend:device_name'</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.open_cameras_batch","title":"open_cameras_batch  <code>async</code>","text":"<pre><code>open_cameras_batch(\n    cameras: List[str], test_connection: bool = True\n) -&gt; Dict[str, Any]\n</code></pre> <p>Open multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.close_camera","title":"close_camera  <code>async</code>","text":"<pre><code>close_camera(camera: str) -&gt; bool\n</code></pre> <p>Close a specific camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to close</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.close_cameras_batch","title":"close_cameras_batch  <code>async</code>","text":"<pre><code>close_cameras_batch(cameras: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Close multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names to close</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.close_all_cameras","title":"close_all_cameras  <code>async</code>","text":"<pre><code>close_all_cameras() -&gt; bool\n</code></pre> <p>Close all active cameras.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_active_cameras","title":"get_active_cameras  <code>async</code>","text":"<pre><code>get_active_cameras() -&gt; List[str]\n</code></pre> <p>Get list of currently active cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active camera names</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_camera_status","title":"get_camera_status  <code>async</code>","text":"<pre><code>get_camera_status(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera status information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera status information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_camera_info","title":"get_camera_info  <code>async</code>","text":"<pre><code>get_camera_info(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed camera information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_camera_capabilities","title":"get_camera_capabilities  <code>async</code>","text":"<pre><code>get_camera_capabilities(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera capabilities information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera capabilities</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_system_diagnostics","title":"get_system_diagnostics  <code>async</code>","text":"<pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.configure_camera","title":"configure_camera  <code>async</code>","text":"<pre><code>configure_camera(camera: str, properties: Dict[str, Any]) -&gt; bool\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to configure</p> required <code>properties</code> <code>Dict[str, Any]</code> <p>Configuration properties</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.configure_cameras_batch","title":"configure_cameras_batch  <code>async</code>","text":"<pre><code>configure_cameras_batch(\n    configurations: Dict[str, Dict[str, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Configure multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>configurations</code> <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping camera names to their configurations</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_camera_configuration","title":"get_camera_configuration  <code>async</code>","text":"<pre><code>get_camera_configuration(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get current camera configuration.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Current camera configuration</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.import_camera_config","title":"import_camera_config  <code>async</code>","text":"<pre><code>import_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Import camera configuration from file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Import operation result</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.export_camera_config","title":"export_camera_config  <code>async</code>","text":"<pre><code>export_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Export camera configuration to file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Export operation result</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.capture_image","title":"capture_image  <code>async</code>","text":"<pre><code>capture_image(\n    camera: str, save_path: Optional[str] = None, output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture a single image.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path</code> <code>Optional[str]</code> <p>Optional path to save image</p> <code>None</code> <code>output_format</code> <code>str</code> <p>Output format for returned image (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Capture result</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.capture_images_batch","title":"capture_images_batch  <code>async</code>","text":"<pre><code>capture_images_batch(\n    cameras: List[str], output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch capture results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.capture_hdr_image","title":"capture_hdr_image  <code>async</code>","text":"<pre><code>capture_hdr_image(\n    camera: str,\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR image sequence.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>HDR capture result</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.capture_hdr_images_batch","title":"capture_hdr_images_batch  <code>async</code>","text":"<pre><code>capture_hdr_images_batch(\n    cameras: List[str],\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch HDR capture results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_bandwidth_settings","title":"get_bandwidth_settings  <code>async</code>","text":"<pre><code>get_bandwidth_settings() -&gt; Dict[str, Any]\n</code></pre> <p>Get current bandwidth settings.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Bandwidth settings</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.set_bandwidth_limit","title":"set_bandwidth_limit  <code>async</code>","text":"<pre><code>set_bandwidth_limit(max_concurrent_captures: int) -&gt; bool\n</code></pre> <p>Set maximum concurrent capture limit.</p> <p>Parameters:</p> Name Type Description Default <code>max_concurrent_captures</code> <code>int</code> <p>Maximum concurrent captures</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerConnectionManager.get_network_diagnostics","title":"get_network_diagnostics  <code>async</code>","text":"<pre><code>get_network_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get network diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Network diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService","title":"CameraManagerService","text":"<pre><code>CameraManagerService(include_mocks: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Camera Management Service.</p> <p>Provides comprehensive camera management functionality through a Service-based architecture with MCP tool integration and async camera operations.</p> <p>Initialize CameraManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>include_mocks</code> <code>bool</code> <p>Include mock cameras in discovery</p> <code>False</code> <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.shutdown_cleanup","title":"shutdown_cleanup  <code>async</code>","text":"<pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup camera manager on shutdown.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.discover_backends","title":"discover_backends  <code>async</code>","text":"<pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available camera backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_backend_info","title":"get_backend_info  <code>async</code>","text":"<pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.discover_cameras","title":"discover_cameras  <code>async</code>","text":"<pre><code>discover_cameras(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available cameras from all or specific backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.open_camera","title":"open_camera  <code>async</code>","text":"<pre><code>open_camera(request: CameraOpenRequest) -&gt; BoolResponse\n</code></pre> <p>Open a single camera with exposure validation.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.open_cameras_batch","title":"open_cameras_batch  <code>async</code>","text":"<pre><code>open_cameras_batch(request: CameraOpenBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Open multiple cameras in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.close_camera","title":"close_camera  <code>async</code>","text":"<pre><code>close_camera(request: CameraCloseRequest) -&gt; BoolResponse\n</code></pre> <p>Close a specific camera.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.close_cameras_batch","title":"close_cameras_batch  <code>async</code>","text":"<pre><code>close_cameras_batch(request: CameraCloseBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Close multiple cameras in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.close_all_cameras","title":"close_all_cameras  <code>async</code>","text":"<pre><code>close_all_cameras() -&gt; BoolResponse\n</code></pre> <p>Close all active cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_active_cameras","title":"get_active_cameras  <code>async</code>","text":"<pre><code>get_active_cameras() -&gt; ActiveCamerasResponse\n</code></pre> <p>Get list of currently active cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_camera_status","title":"get_camera_status  <code>async</code>","text":"<pre><code>get_camera_status(request: CameraQueryRequest) -&gt; CameraStatusResponse\n</code></pre> <p>Get camera status information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_camera_info","title":"get_camera_info  <code>async</code>","text":"<pre><code>get_camera_info(request: CameraQueryRequest) -&gt; CameraInfoResponse\n</code></pre> <p>Get detailed camera information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_camera_capabilities","title":"get_camera_capabilities  <code>async</code>","text":"<pre><code>get_camera_capabilities(\n    request: CameraQueryRequest,\n) -&gt; CameraCapabilitiesResponse\n</code></pre> <p>Get camera capabilities information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.configure_camera","title":"configure_camera  <code>async</code>","text":"<pre><code>configure_camera(request: CameraConfigureRequest) -&gt; BoolResponse\n</code></pre> <p>Configure camera parameters.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.configure_cameras_batch","title":"configure_cameras_batch  <code>async</code>","text":"<pre><code>configure_cameras_batch(\n    request: CameraConfigureBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Configure multiple cameras in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_camera_configuration","title":"get_camera_configuration  <code>async</code>","text":"<pre><code>get_camera_configuration(\n    request: CameraQueryRequest,\n) -&gt; CameraConfigurationResponse\n</code></pre> <p>Get current camera configuration.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.import_camera_config","title":"import_camera_config  <code>async</code>","text":"<pre><code>import_camera_config(request: ConfigFileImportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Import camera configuration from file.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.export_camera_config","title":"export_camera_config  <code>async</code>","text":"<pre><code>export_camera_config(request: ConfigFileExportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Export camera configuration to file.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.capture_image","title":"capture_image  <code>async</code>","text":"<pre><code>capture_image(request: CaptureImageRequest) -&gt; CaptureResponse\n</code></pre> <p>Capture a single image with timeout protection.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.capture_images_batch","title":"capture_images_batch  <code>async</code>","text":"<pre><code>capture_images_batch(request: CaptureBatchRequest) -&gt; BatchCaptureResponse\n</code></pre> <p>Capture images from multiple cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.capture_hdr_image","title":"capture_hdr_image  <code>async</code>","text":"<pre><code>capture_hdr_image(request: CaptureHDRRequest) -&gt; HDRCaptureResponse\n</code></pre> <p>Capture HDR image sequence.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.capture_hdr_images_batch","title":"capture_hdr_images_batch  <code>async</code>","text":"<pre><code>capture_hdr_images_batch(\n    request: CaptureHDRBatchRequest,\n) -&gt; BatchHDRCaptureResponse\n</code></pre> <p>Capture HDR images from multiple cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_network_diagnostics","title":"get_network_diagnostics  <code>async</code>","text":"<pre><code>get_network_diagnostics() -&gt; NetworkDiagnosticsResponse\n</code></pre> <p>Get network diagnostics information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_performance_settings","title":"get_performance_settings  <code>async</code>","text":"<pre><code>get_performance_settings(\n    request: CameraPerformanceSettingsRequest = None,\n) -&gt; CameraPerformanceSettingsResponse\n</code></pre> <p>Get current camera performance settings.</p> <p>Returns global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.set_performance_settings","title":"set_performance_settings  <code>async</code>","text":"<pre><code>set_performance_settings(\n    request: CameraPerformanceSettingsRequest,\n) -&gt; BoolResponse\n</code></pre> <p>Update camera performance settings.</p> <p>Updates global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.start_stream","title":"start_stream  <code>async</code>","text":"<pre><code>start_stream(request: StreamStartRequest) -&gt; StreamInfoResponse\n</code></pre> <p>Start camera stream with resilient state management.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.stop_stream","title":"stop_stream  <code>async</code>","text":"<pre><code>stop_stream(request: StreamStopRequest) -&gt; BoolResponse\n</code></pre> <p>Stop camera stream with resilient state management.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_stream_status","title":"get_stream_status  <code>async</code>","text":"<pre><code>get_stream_status(request: StreamStatusRequest) -&gt; StreamStatusResponse\n</code></pre> <p>Get camera stream status with resilient state management.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_active_streams","title":"get_active_streams  <code>async</code>","text":"<pre><code>get_active_streams() -&gt; ActiveStreamsResponse\n</code></pre> <p>Get list of cameras with active streams.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.stop_all_streams","title":"stop_all_streams  <code>async</code>","text":"<pre><code>stop_all_streams() -&gt; BoolResponse\n</code></pre> <p>Stop all active camera streams.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.serve_camera_stream","title":"serve_camera_stream  <code>async</code>","text":"<pre><code>serve_camera_stream(camera_name: str)\n</code></pre> <p>Serve MJPEG video stream for a specific camera.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.calibrate_homography_checkerboard","title":"calibrate_homography_checkerboard  <code>async</code>","text":"<pre><code>calibrate_homography_checkerboard(\n    request: HomographyCalibrateCheckerboardRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography using checkerboard pattern detection.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.calibrate_homography_correspondences","title":"calibrate_homography_correspondences  <code>async</code>","text":"<pre><code>calibrate_homography_correspondences(\n    request: HomographyCalibrateCorrespondencesRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from known point correspondences.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.calibrate_homography_multi_view","title":"calibrate_homography_multi_view  <code>async</code>","text":"<pre><code>calibrate_homography_multi_view(\n    request: HomographyCalibrateMultiViewRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from multiple checkerboard positions on the same plane.</p> <p>Ideal for calibrating long surfaces (metallic bars, conveyor belts) using a standard checkerboard moved to multiple positions.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.measure_homography_box","title":"measure_homography_box  <code>async</code>","text":"<pre><code>measure_homography_box(\n    request: HomographyMeasureBoundingBoxRequest,\n) -&gt; HomographyMeasurementResponse\n</code></pre> <p>Measure bounding box dimensions using homography calibration.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.measure_homography_batch","title":"measure_homography_batch  <code>async</code>","text":"<pre><code>measure_homography_batch(\n    request: HomographyMeasureBatchRequest,\n) -&gt; HomographyBatchMeasurementResponse\n</code></pre> <p>Unified batch measurement for bounding boxes and/or point-pair distances.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.measure_homography_distance","title":"measure_homography_distance  <code>async</code>","text":"<pre><code>measure_homography_distance(\n    request: HomographyMeasureDistanceRequest,\n) -&gt; HomographyDistanceResponse\n</code></pre> <p>Measure distance between two points using homography calibration.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.health_check","title":"health_check  <code>async</code>","text":"<pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.CameraManagerService.get_system_diagnostics","title":"get_system_diagnostics  <code>async</code>","text":"<pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager","title":"PLCManagerConnectionManager","text":"<pre><code>PLCManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for PLCManagerService.</p> <p>Provides strongly-typed methods for all PLC management operations, making it easy to use the service programmatically from other applications.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get","title":"get  <code>async</code>","text":"<pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.post","title":"post  <code>async</code>","text":"<pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.discover_backends","title":"discover_backends  <code>async</code>","text":"<pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available PLC backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_backend_info","title":"get_backend_info  <code>async</code>","text":"<pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.discover_plcs","title":"discover_plcs  <code>async</code>","text":"<pre><code>discover_plcs(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available PLCs from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.connect_plc","title":"connect_plc  <code>async</code>","text":"<pre><code>connect_plc(\n    plc_name: str,\n    backend: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n) -&gt; bool\n</code></pre> <p>Connect to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>backend</code> <code>str</code> <p>Backend type (AllenBradley, Siemens, Modbus)</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>Specific PLC type (logix, slc, cip, auto)</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.connect_plcs_batch","title":"connect_plcs_batch  <code>async</code>","text":"<pre><code>connect_plcs_batch(plcs: List[PLCConnectRequest]) -&gt; Dict[str, Any]\n</code></pre> <p>Connect to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[PLCConnectRequest]</code> <p>List of PLC connection requests</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.disconnect_plc","title":"disconnect_plc  <code>async</code>","text":"<pre><code>disconnect_plc(plc: str) -&gt; bool\n</code></pre> <p>Disconnect from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to disconnect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.disconnect_plcs_batch","title":"disconnect_plcs_batch  <code>async</code>","text":"<pre><code>disconnect_plcs_batch(plcs: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[str]</code> <p>List of PLC names to disconnect</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.disconnect_all_plcs","title":"disconnect_all_plcs  <code>async</code>","text":"<pre><code>disconnect_all_plcs() -&gt; bool\n</code></pre> <p>Disconnect from all active PLCs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_active_plcs","title":"get_active_plcs  <code>async</code>","text":"<pre><code>get_active_plcs() -&gt; List[str]\n</code></pre> <p>Get list of currently active PLCs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active PLC names</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.read_tags","title":"read_tags  <code>async</code>","text":"<pre><code>read_tags(plc: str, tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tag values from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.write_tags","title":"write_tags  <code>async</code>","text":"<pre><code>write_tags(\n    plc: str, tags: Union[Tuple[str, Any], List[Tuple[str, Any]]]\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tag values to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.read_tags_batch","title":"read_tags_batch  <code>async</code>","text":"<pre><code>read_tags_batch(\n    requests: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[str, List[str]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their tag read results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.write_tags_batch","title":"write_tags_batch  <code>async</code>","text":"<pre><code>write_tags_batch(\n    requests: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; Dict[str, Dict[str, bool]]\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, bool]]</code> <p>Dictionary mapping PLC names to their tag write results</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.list_tags","title":"list_tags  <code>async</code>","text":"<pre><code>list_tags(plc: str) -&gt; List[str]\n</code></pre> <p>List all available tags on a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_tag_info","title":"get_tag_info  <code>async</code>","text":"<pre><code>get_tag_info(plc: str, tag: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tag</code> <code>str</code> <p>Tag name</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Tag information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_plc_status","title":"get_plc_status  <code>async</code>","text":"<pre><code>get_plc_status(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get PLC status information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC status information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_plc_info","title":"get_plc_info  <code>async</code>","text":"<pre><code>get_plc_info(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed PLC information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerConnectionManager.get_system_diagnostics","title":"get_system_diagnostics  <code>async</code>","text":"<pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService","title":"PLCManagerService","text":"<pre><code>PLCManagerService(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>PLC Management Service.</p> <p>Provides comprehensive PLC management functionality through a Service-based architecture with MCP tool integration and async PLC operations.</p> <p>Initialize PLCManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.shutdown_cleanup","title":"shutdown_cleanup  <code>async</code>","text":"<pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup PLC manager on shutdown.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.discover_backends","title":"discover_backends  <code>async</code>","text":"<pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available PLC backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_backend_info","title":"get_backend_info  <code>async</code>","text":"<pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.discover_plcs","title":"discover_plcs  <code>async</code>","text":"<pre><code>discover_plcs(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available PLCs from all or specific backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.connect_plc","title":"connect_plc  <code>async</code>","text":"<pre><code>connect_plc(request: PLCConnectRequest) -&gt; BoolResponse\n</code></pre> <p>Connect to a PLC.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.connect_plcs_batch","title":"connect_plcs_batch  <code>async</code>","text":"<pre><code>connect_plcs_batch(request: PLCConnectBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Connect to multiple PLCs in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.disconnect_plc","title":"disconnect_plc  <code>async</code>","text":"<pre><code>disconnect_plc(request: PLCDisconnectRequest) -&gt; BoolResponse\n</code></pre> <p>Disconnect from a PLC.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.disconnect_plcs_batch","title":"disconnect_plcs_batch  <code>async</code>","text":"<pre><code>disconnect_plcs_batch(\n    request: PLCDisconnectBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.disconnect_all_plcs","title":"disconnect_all_plcs  <code>async</code>","text":"<pre><code>disconnect_all_plcs() -&gt; BoolResponse\n</code></pre> <p>Disconnect from all active PLCs.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_active_plcs","title":"get_active_plcs  <code>async</code>","text":"<pre><code>get_active_plcs() -&gt; ActivePLCsResponse\n</code></pre> <p>Get list of currently active PLCs.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.read_tags","title":"read_tags  <code>async</code>","text":"<pre><code>read_tags(request: TagReadRequest) -&gt; TagReadResponse\n</code></pre> <p>Read tag values from a PLC.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.write_tags","title":"write_tags  <code>async</code>","text":"<pre><code>write_tags(request: TagWriteRequest) -&gt; TagWriteResponse\n</code></pre> <p>Write tag values to a PLC.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.read_tags_batch","title":"read_tags_batch  <code>async</code>","text":"<pre><code>read_tags_batch(request: TagBatchReadRequest) -&gt; BatchTagReadResponse\n</code></pre> <p>Read tags from multiple PLCs in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.write_tags_batch","title":"write_tags_batch  <code>async</code>","text":"<pre><code>write_tags_batch(request: TagBatchWriteRequest) -&gt; BatchTagWriteResponse\n</code></pre> <p>Write tags to multiple PLCs in batch.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.list_tags","title":"list_tags  <code>async</code>","text":"<pre><code>list_tags(request: PLCQueryRequest) -&gt; TagListResponse\n</code></pre> <p>List all available tags on a PLC.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_tag_info","title":"get_tag_info  <code>async</code>","text":"<pre><code>get_tag_info(request: TagInfoRequest) -&gt; TagInfoResponse\n</code></pre> <p>Get detailed information about a specific tag.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_plc_status","title":"get_plc_status  <code>async</code>","text":"<pre><code>get_plc_status(request: PLCQueryRequest) -&gt; PLCStatusResponse\n</code></pre> <p>Get PLC status information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_plc_info","title":"get_plc_info  <code>async</code>","text":"<pre><code>get_plc_info(request: PLCQueryRequest) -&gt; PLCInfoResponse\n</code></pre> <p>Get detailed PLC information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.get_system_diagnostics","title":"get_system_diagnostics  <code>async</code>","text":"<pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.PLCManagerService.health_check","title":"health_check  <code>async</code>","text":"<pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager","title":"SensorConnectionManager","text":"<pre><code>SensorConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Strongly-typed connection manager for sensor service operations.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.connect_sensor","title":"connect_sensor  <code>async</code>","text":"<pre><code>connect_sensor(\n    sensor_id: str, backend_type: str, config: Dict[str, Any], address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>backend_type</code> <code>str</code> <p>Backend type (mqtt, http, serial)</p> required <code>config</code> <code>Dict[str, Any]</code> <p>Backend-specific configuration</p> required <code>address</code> <code>str</code> <p>Sensor address (topic, endpoint, or port)</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.disconnect_sensor","title":"disconnect_sensor  <code>async</code>","text":"<pre><code>disconnect_sensor(sensor_id: str) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.read_sensor_data","title":"read_sensor_data  <code>async</code>","text":"<pre><code>read_sensor_data(\n    sensor_id: str, timeout: Optional[float] = None\n) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>timeout</code> <code>Optional[float]</code> <p>Optional read timeout in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.get_sensor_status","title":"get_sensor_status  <code>async</code>","text":"<pre><code>get_sensor_status(sensor_id: str) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.list_sensors","title":"list_sensors  <code>async</code>","text":"<pre><code>list_sensors(include_status: bool = False) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>include_status</code> <code>bool</code> <p>Whether to include connection status for each sensor</p> <code>False</code> <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.connect_mqtt_sensor","title":"connect_mqtt_sensor  <code>async</code>","text":"<pre><code>connect_mqtt_sensor(\n    sensor_id: str, broker_url: str, identifier: str, address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an MQTT sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>str</code> <p>Client identifier for MQTT connection</p> required <code>address</code> <code>str</code> <p>MQTT topic to subscribe to</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.connect_http_sensor","title":"connect_http_sensor  <code>async</code>","text":"<pre><code>connect_http_sensor(\n    sensor_id: str,\n    base_url: str,\n    address: str,\n    headers: Optional[Dict[str, str]] = None,\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an HTTP sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests</p> required <code>address</code> <code>str</code> <p>Endpoint path for sensor data</p> required <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorConnectionManager.connect_serial_sensor","title":"connect_serial_sensor  <code>async</code>","text":"<pre><code>connect_serial_sensor(\n    sensor_id: str, port: str, baudrate: int = 9600, timeout: float = 1.0\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a serial sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>port</code> <code>str</code> <p>Serial port (e.g., \"/dev/ttyUSB0\" or \"COM1\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baud rate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Serial read timeout</p> <code>1.0</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService","title":"SensorManagerService","text":"<pre><code>SensorManagerService(manager: Optional[SensorManager] = None, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Service wrapper for SensorManager with MCP endpoint registration.</p> <p>Initialize the sensor manager service.</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>Optional[SensorManager]</code> <p>Optional SensorManager instance. If None, creates a new one.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the Service base class</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.manager","title":"manager  <code>property</code>","text":"<pre><code>manager: SensorManager\n</code></pre> <p>Get the underlying SensorManager instance.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.connect_sensor","title":"connect_sensor  <code>async</code>","text":"<pre><code>connect_sensor(request: SensorConnectionRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorConnectionRequest</code> <p>Connection request with sensor configuration</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.disconnect_sensor","title":"disconnect_sensor  <code>async</code>","text":"<pre><code>disconnect_sensor(request: SensorStatusRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.read_sensor_data","title":"read_sensor_data  <code>async</code>","text":"<pre><code>read_sensor_data(request: SensorDataRequest) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorDataRequest</code> <p>Request specifying sensor and read parameters</p> required <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.get_sensor_status","title":"get_sensor_status  <code>async</code>","text":"<pre><code>get_sensor_status(request: SensorStatusRequest) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p>"},{"location":"hardware/api/#mindtrace.hardware.api.SensorManagerService.list_sensors","title":"list_sensors  <code>async</code>","text":"<pre><code>list_sensors(request: SensorListRequest) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorListRequest</code> <p>Request with listing options</p> required <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras","title":"cameras","text":"<p>CameraManagerService - Service-based camera management API.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.CameraManagerConnectionManager","title":"CameraManagerConnectionManager","text":"<pre><code>CameraManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for CameraManagerService.</p> <p>Provides strongly-typed methods for all camera management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available camera backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p> discover_cameras <code>async</code> <pre><code>discover_cameras(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available cameras from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of camera names in format 'Backend:device_name'</p> open_camera <code>async</code> <pre><code>open_camera(camera: str, test_connection: bool = True) -&gt; bool\n</code></pre> <p>Open a single camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name in format 'Backend:device_name'</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(\n    cameras: List[str], test_connection: bool = True\n) -&gt; Dict[str, Any]\n</code></pre> <p>Open multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> close_camera <code>async</code> <pre><code>close_camera(camera: str) -&gt; bool\n</code></pre> <p>Close a specific camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to close</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(cameras: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Close multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names to close</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; bool\n</code></pre> <p>Close all active cameras.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; List[str]\n</code></pre> <p>Get list of currently active cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active camera names</p> get_camera_status <code>async</code> <pre><code>get_camera_status(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera status information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera status information</p> get_camera_info <code>async</code> <pre><code>get_camera_info(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed camera information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera information</p> get_camera_capabilities <code>async</code> <pre><code>get_camera_capabilities(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera capabilities information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera capabilities</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p> configure_camera <code>async</code> <pre><code>configure_camera(camera: str, properties: Dict[str, Any]) -&gt; bool\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to configure</p> required <code>properties</code> <code>Dict[str, Any]</code> <p>Configuration properties</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    configurations: Dict[str, Dict[str, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Configure multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>configurations</code> <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping camera names to their configurations</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get current camera configuration.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Current camera configuration</p> import_camera_config <code>async</code> <pre><code>import_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Import camera configuration from file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Import operation result</p> export_camera_config <code>async</code> <pre><code>export_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Export camera configuration to file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Export operation result</p> capture_image <code>async</code> <pre><code>capture_image(\n    camera: str, save_path: Optional[str] = None, output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture a single image.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path</code> <code>Optional[str]</code> <p>Optional path to save image</p> <code>None</code> <code>output_format</code> <code>str</code> <p>Output format for returned image (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Capture result</p> capture_images_batch <code>async</code> <pre><code>capture_images_batch(\n    cameras: List[str], output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch capture results</p> capture_hdr_image <code>async</code> <pre><code>capture_hdr_image(\n    camera: str,\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR image sequence.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>HDR capture result</p> capture_hdr_images_batch <code>async</code> <pre><code>capture_hdr_images_batch(\n    cameras: List[str],\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch HDR capture results</p> get_bandwidth_settings <code>async</code> <pre><code>get_bandwidth_settings() -&gt; Dict[str, Any]\n</code></pre> <p>Get current bandwidth settings.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Bandwidth settings</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(max_concurrent_captures: int) -&gt; bool\n</code></pre> <p>Set maximum concurrent capture limit.</p> <p>Parameters:</p> Name Type Description Default <code>max_concurrent_captures</code> <code>int</code> <p>Maximum concurrent captures</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_network_diagnostics <code>async</code> <pre><code>get_network_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get network diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Network diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.CameraManagerService","title":"CameraManagerService","text":"<pre><code>CameraManagerService(include_mocks: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Camera Management Service.</p> <p>Provides comprehensive camera management functionality through a Service-based architecture with MCP tool integration and async camera operations.</p> <p>Initialize CameraManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>include_mocks</code> <code>bool</code> <p>Include mock cameras in discovery</p> <code>False</code> <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup camera manager on shutdown.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available camera backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p> discover_cameras <code>async</code> <pre><code>discover_cameras(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available cameras from all or specific backends.</p> open_camera <code>async</code> <pre><code>open_camera(request: CameraOpenRequest) -&gt; BoolResponse\n</code></pre> <p>Open a single camera with exposure validation.</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(request: CameraOpenBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Open multiple cameras in batch.</p> close_camera <code>async</code> <pre><code>close_camera(request: CameraCloseRequest) -&gt; BoolResponse\n</code></pre> <p>Close a specific camera.</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(request: CameraCloseBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Close multiple cameras in batch.</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; BoolResponse\n</code></pre> <p>Close all active cameras.</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; ActiveCamerasResponse\n</code></pre> <p>Get list of currently active cameras.</p> get_camera_status <code>async</code> <pre><code>get_camera_status(request: CameraQueryRequest) -&gt; CameraStatusResponse\n</code></pre> <p>Get camera status information.</p> get_camera_info <code>async</code> <pre><code>get_camera_info(request: CameraQueryRequest) -&gt; CameraInfoResponse\n</code></pre> <p>Get detailed camera information.</p> get_camera_capabilities <code>async</code> <pre><code>get_camera_capabilities(\n    request: CameraQueryRequest,\n) -&gt; CameraCapabilitiesResponse\n</code></pre> <p>Get camera capabilities information.</p> configure_camera <code>async</code> <pre><code>configure_camera(request: CameraConfigureRequest) -&gt; BoolResponse\n</code></pre> <p>Configure camera parameters.</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    request: CameraConfigureBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Configure multiple cameras in batch.</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(\n    request: CameraQueryRequest,\n) -&gt; CameraConfigurationResponse\n</code></pre> <p>Get current camera configuration.</p> import_camera_config <code>async</code> <pre><code>import_camera_config(request: ConfigFileImportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Import camera configuration from file.</p> export_camera_config <code>async</code> <pre><code>export_camera_config(request: ConfigFileExportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Export camera configuration to file.</p> capture_image <code>async</code> <pre><code>capture_image(request: CaptureImageRequest) -&gt; CaptureResponse\n</code></pre> <p>Capture a single image with timeout protection.</p> capture_images_batch <code>async</code> <pre><code>capture_images_batch(request: CaptureBatchRequest) -&gt; BatchCaptureResponse\n</code></pre> <p>Capture images from multiple cameras.</p> capture_hdr_image <code>async</code> <pre><code>capture_hdr_image(request: CaptureHDRRequest) -&gt; HDRCaptureResponse\n</code></pre> <p>Capture HDR image sequence.</p> capture_hdr_images_batch <code>async</code> <pre><code>capture_hdr_images_batch(\n    request: CaptureHDRBatchRequest,\n) -&gt; BatchHDRCaptureResponse\n</code></pre> <p>Capture HDR images from multiple cameras.</p> get_network_diagnostics <code>async</code> <pre><code>get_network_diagnostics() -&gt; NetworkDiagnosticsResponse\n</code></pre> <p>Get network diagnostics information.</p> get_performance_settings <code>async</code> <pre><code>get_performance_settings(\n    request: CameraPerformanceSettingsRequest = None,\n) -&gt; CameraPerformanceSettingsResponse\n</code></pre> <p>Get current camera performance settings.</p> <p>Returns global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p> set_performance_settings <code>async</code> <pre><code>set_performance_settings(\n    request: CameraPerformanceSettingsRequest,\n) -&gt; BoolResponse\n</code></pre> <p>Update camera performance settings.</p> <p>Updates global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p> start_stream <code>async</code> <pre><code>start_stream(request: StreamStartRequest) -&gt; StreamInfoResponse\n</code></pre> <p>Start camera stream with resilient state management.</p> stop_stream <code>async</code> <pre><code>stop_stream(request: StreamStopRequest) -&gt; BoolResponse\n</code></pre> <p>Stop camera stream with resilient state management.</p> get_stream_status <code>async</code> <pre><code>get_stream_status(request: StreamStatusRequest) -&gt; StreamStatusResponse\n</code></pre> <p>Get camera stream status with resilient state management.</p> get_active_streams <code>async</code> <pre><code>get_active_streams() -&gt; ActiveStreamsResponse\n</code></pre> <p>Get list of cameras with active streams.</p> stop_all_streams <code>async</code> <pre><code>stop_all_streams() -&gt; BoolResponse\n</code></pre> <p>Stop all active camera streams.</p> serve_camera_stream <code>async</code> <pre><code>serve_camera_stream(camera_name: str)\n</code></pre> <p>Serve MJPEG video stream for a specific camera.</p> calibrate_homography_checkerboard <code>async</code> <pre><code>calibrate_homography_checkerboard(\n    request: HomographyCalibrateCheckerboardRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography using checkerboard pattern detection.</p> calibrate_homography_correspondences <code>async</code> <pre><code>calibrate_homography_correspondences(\n    request: HomographyCalibrateCorrespondencesRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from known point correspondences.</p> calibrate_homography_multi_view <code>async</code> <pre><code>calibrate_homography_multi_view(\n    request: HomographyCalibrateMultiViewRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from multiple checkerboard positions on the same plane.</p> <p>Ideal for calibrating long surfaces (metallic bars, conveyor belts) using a standard checkerboard moved to multiple positions.</p> measure_homography_box <code>async</code> <pre><code>measure_homography_box(\n    request: HomographyMeasureBoundingBoxRequest,\n) -&gt; HomographyMeasurementResponse\n</code></pre> <p>Measure bounding box dimensions using homography calibration.</p> measure_homography_batch <code>async</code> <pre><code>measure_homography_batch(\n    request: HomographyMeasureBatchRequest,\n) -&gt; HomographyBatchMeasurementResponse\n</code></pre> <p>Unified batch measurement for bounding boxes and/or point-pair distances.</p> measure_homography_distance <code>async</code> <pre><code>measure_homography_distance(\n    request: HomographyMeasureDistanceRequest,\n) -&gt; HomographyDistanceResponse\n</code></pre> <p>Measure distance between two points using homography calibration.</p> health_check <code>async</code> <pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.connection_manager","title":"connection_manager","text":"<p>Connection Manager for CameraManagerService.</p> <p>Provides a strongly-typed client interface for programmatic access to camera management operations.</p> CameraManagerConnectionManager <pre><code>CameraManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for CameraManagerService.</p> <p>Provides strongly-typed methods for all camera management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available camera backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p> discover_cameras <code>async</code> <pre><code>discover_cameras(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available cameras from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of camera names in format 'Backend:device_name'</p> open_camera <code>async</code> <pre><code>open_camera(camera: str, test_connection: bool = True) -&gt; bool\n</code></pre> <p>Open a single camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name in format 'Backend:device_name'</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(\n    cameras: List[str], test_connection: bool = True\n) -&gt; Dict[str, Any]\n</code></pre> <p>Open multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>test_connection</code> <code>bool</code> <p>Test connection after opening</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> close_camera <code>async</code> <pre><code>close_camera(camera: str) -&gt; bool\n</code></pre> <p>Close a specific camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to close</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(cameras: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Close multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names to close</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; bool\n</code></pre> <p>Close all active cameras.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; List[str]\n</code></pre> <p>Get list of currently active cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active camera names</p> get_camera_status <code>async</code> <pre><code>get_camera_status(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera status information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera status information</p> get_camera_info <code>async</code> <pre><code>get_camera_info(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed camera information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera information</p> get_camera_capabilities <code>async</code> <pre><code>get_camera_capabilities(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get camera capabilities information.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Camera capabilities</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p> configure_camera <code>async</code> <pre><code>configure_camera(camera: str, properties: Dict[str, Any]) -&gt; bool\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to configure</p> required <code>properties</code> <code>Dict[str, Any]</code> <p>Configuration properties</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    configurations: Dict[str, Dict[str, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Configure multiple cameras in batch.</p> <p>Parameters:</p> Name Type Description Default <code>configurations</code> <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping camera names to their configurations</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get current camera configuration.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Current camera configuration</p> import_camera_config <code>async</code> <pre><code>import_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Import camera configuration from file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Import operation result</p> export_camera_config <code>async</code> <pre><code>export_camera_config(camera: str, config_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Export camera configuration to file.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Export operation result</p> capture_image <code>async</code> <pre><code>capture_image(\n    camera: str, save_path: Optional[str] = None, output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture a single image.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path</code> <code>Optional[str]</code> <p>Optional path to save image</p> <code>None</code> <code>output_format</code> <code>str</code> <p>Output format for returned image (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Capture result</p> capture_images_batch <code>async</code> <pre><code>capture_images_batch(\n    cameras: List[str], output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch capture results</p> capture_hdr_image <code>async</code> <pre><code>capture_hdr_image(\n    camera: str,\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR image sequence.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>str</code> <p>Camera name</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>HDR capture result</p> capture_hdr_images_batch <code>async</code> <pre><code>capture_hdr_images_batch(\n    cameras: List[str],\n    save_path_pattern: Optional[str] = None,\n    exposure_levels: int = 3,\n    exposure_multiplier: float = 2.0,\n    return_images: bool = True,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture HDR images from multiple cameras.</p> <p>Parameters:</p> Name Type Description Default <code>cameras</code> <code>List[str]</code> <p>List of camera names</p> required <code>save_path_pattern</code> <code>Optional[str]</code> <p>Path pattern with {exposure} placeholder</p> <code>None</code> <code>exposure_levels</code> <code>int</code> <p>Number of exposure levels</p> <code>3</code> <code>exposure_multiplier</code> <code>float</code> <p>Multiplier between exposures</p> <code>2.0</code> <code>return_images</code> <code>bool</code> <p>Return captured images</p> <code>True</code> <code>output_format</code> <code>str</code> <p>Output format for returned images (\"numpy\" or \"pil\")</p> <code>'pil'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch HDR capture results</p> get_bandwidth_settings <code>async</code> <pre><code>get_bandwidth_settings() -&gt; Dict[str, Any]\n</code></pre> <p>Get current bandwidth settings.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Bandwidth settings</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(max_concurrent_captures: int) -&gt; bool\n</code></pre> <p>Set maximum concurrent capture limit.</p> <p>Parameters:</p> Name Type Description Default <code>max_concurrent_captures</code> <code>int</code> <p>Maximum concurrent captures</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_network_diagnostics <code>async</code> <pre><code>get_network_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get network diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Network diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.launcher","title":"launcher","text":"<p>Camera API service launcher.</p> main <pre><code>main()\n</code></pre> <p>Main launcher function.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.models","title":"models","text":"<p>Models for CameraManagerService API.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> BandwidthLimitCameraRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting camera bandwidth limit.</p> BandwidthLimitRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting bandwidth limit.</p> CameraCloseBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera closing.</p> CameraCloseRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for closing a camera.</p> CameraConfigureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera configuration.</p> validate_configurations <code>classmethod</code> <pre><code>validate_configurations(\n    v: Union[Dict[str, Dict[str, Any]], List[Dict[str, Any]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Convert list format to dict format.</p> CameraConfigureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for camera configuration.</p> CameraOpenBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera opening.</p> CameraOpenRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for opening a camera.</p> CameraPerformanceSettingsRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for updating camera performance settings.</p> <p>Global settings (always applicable): - timeout_ms, retrieve_retry_count, max_concurrent_captures</p> <p>Per-camera GigE settings (requires camera field, only for GigE cameras): - packet_size, inter_packet_delay, bandwidth_limit_mbps</p> CameraQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for camera query operations.</p> CaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch image capture.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureHDRBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch HDR image capture.</p> validate_exposure_levels <code>classmethod</code> <pre><code>validate_exposure_levels(v: Union[int, List[float]]) -&gt; Union[int, List[float]]\n</code></pre> <p>Validate exposure levels.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureHDRRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for HDR image capture.</p> validate_exposure_levels <code>classmethod</code> <pre><code>validate_exposure_levels(v: Union[int, List[float]]) -&gt; Union[int, List[float]]\n</code></pre> <p>Validate exposure levels.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureImageRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for single image capture.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> ConfigFileExportRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for configuration file export.</p> ConfigFileImportRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for configuration file import.</p> ExposureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for exposure setting.</p> GainRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for gain setting.</p> HomographyCalibrateCheckerboardRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for checkerboard-based homography calibration.</p> HomographyCalibrateCorrespondencesRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for manual point correspondence calibration.</p> validate_points <code>classmethod</code> <pre><code>validate_points(v: List[List[float]]) -&gt; List[List[float]]\n</code></pre> <p>Validate point arrays.</p> HomographyCalibrateMultiViewRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for multi-view checkerboard calibration.</p> <p>Note: Checkerboard parameters (board_size, square_size, world_unit) are configured in HomographySettings (see config.py), not passed per-request.</p> validate_positions <code>classmethod</code> <pre><code>validate_positions(v: List[Dict[str, float]]) -&gt; List[Dict[str, float]]\n</code></pre> <p>Validate position format.</p> validate_lengths_match <pre><code>validate_lengths_match()\n</code></pre> <p>Ensure number of images matches number of positions.</p> HomographyMeasureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Unified request model for batch measurements (bounding boxes and/or point-pair distances).</p> validate_boxes <code>classmethod</code> <pre><code>validate_boxes(\n    v: Optional[List[Dict[str, int]]],\n) -&gt; Optional[List[Dict[str, int]]]\n</code></pre> <p>Validate bounding boxes.</p> validate_point_pairs <code>classmethod</code> <pre><code>validate_point_pairs(\n    v: Optional[List[List[List[float]]]],\n) -&gt; Optional[List[List[List[float]]]]\n</code></pre> <p>Validate point pairs.</p> validate_at_least_one <pre><code>validate_at_least_one()\n</code></pre> <p>Ensure at least one measurement type is provided.</p> HomographyMeasureBoundingBoxRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for measuring a single bounding box.</p> HomographyMeasureDistanceRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for measuring distance between two points.</p> ImageEnhancementRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for image enhancement setting.</p> InterPacketDelayRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting inter-packet delay.</p> PacketSizeRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting camera packet size.</p> PixelFormatRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for pixel format setting.</p> ROIRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for ROI (Region of Interest) setting.</p> StreamStartRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for starting camera stream.</p> StreamStatusRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for getting stream status.</p> StreamStopRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stopping camera stream.</p> TriggerModeRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for trigger mode setting.</p> WhiteBalanceRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for white balance setting.</p> ActiveCamerasResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active cameras list.</p> ActiveStreamsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active streams list.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Backend information model.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BandwidthSettings <p>               Bases: <code>BaseModel</code></p> <p>Bandwidth settings model.</p> BandwidthSettingsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for bandwidth settings.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BatchCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch capture operations.</p> BatchHDRCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch HDR capture.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Batch operation result model.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> CameraCapabilities <p>               Bases: <code>BaseModel</code></p> <p>Camera capabilities model.</p> CameraCapabilitiesResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera capabilities.</p> CameraConfiguration <p>               Bases: <code>BaseModel</code></p> <p>Camera configuration model.</p> CameraConfigurationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera configuration.</p> CameraInfo <p>               Bases: <code>BaseModel</code></p> <p>Camera information model.</p> CameraInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera information.</p> CameraPerformanceSettings <p>               Bases: <code>BaseModel</code></p> <p>Camera performance and retry settings model.</p> <p>Global settings: - timeout_ms, retrieve_retry_count, max_concurrent_captures</p> <p>Per-camera GigE settings (None if not applicable or not queried): - packet_size, inter_packet_delay, bandwidth_limit_mbps</p> CameraPerformanceSettingsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera performance settings.</p> CameraStatus <p>               Bases: <code>BaseModel</code></p> <p>Camera status model.</p> CameraStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera status.</p> CaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for single image capture.</p> CaptureResult <p>               Bases: <code>BaseModel</code></p> <p>Capture result model.</p> ConfigFileOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Configuration file operation result.</p> ConfigFileResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for configuration file operations.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> ErrorDetail <p>               Bases: <code>BaseModel</code></p> <p>Error detail model.</p> ErrorResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for error conditions.</p> FloatResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for float values.</p> HDRCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for HDR capture.</p> HDRCaptureResult <p>               Bases: <code>BaseModel</code></p> <p>HDR capture result model.</p> HomographyBatchMeasurementData <p>               Bases: <code>BaseModel</code></p> <p>Batch measurement data containing both box and distance measurements.</p> HomographyBatchMeasurementResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for unified batch homography measurements.</p> HomographyCalibrationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for homography calibration.</p> HomographyCalibrationResult <p>               Bases: <code>BaseModel</code></p> <p>Homography calibration result model.</p> HomographyDistanceResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for distance measurement.</p> HomographyDistanceResult <p>               Bases: <code>BaseModel</code></p> <p>Homography distance measurement result model.</p> HomographyMeasurementResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for single homography measurement.</p> HomographyMeasurementResult <p>               Bases: <code>BaseModel</code></p> <p>Homography measurement result model.</p> IntResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for integer values.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> NetworkDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>Network diagnostics model.</p> NetworkDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for network diagnostics.</p> ParameterRange <p>               Bases: <code>BaseModel</code></p> <p>Parameter range model.</p> RangeResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for parameter ranges.</p> StreamInfo <p>               Bases: <code>BaseModel</code></p> <p>Stream information model.</p> StreamInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stream information.</p> StreamStatus <p>               Bases: <code>BaseModel</code></p> <p>Stream status model.</p> StreamStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stream status.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p> requests <p>Request models for CameraManagerService.</p> <p>Contains all Pydantic models for API requests, ensuring proper input validation and documentation for all camera operations.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> CameraOpenRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for opening a camera.</p> CameraOpenBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera opening.</p> CameraCloseRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for closing a camera.</p> CameraCloseBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera closing.</p> CameraConfigureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for camera configuration.</p> CameraConfigureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch camera configuration.</p> validate_configurations <code>classmethod</code> <pre><code>validate_configurations(\n    v: Union[Dict[str, Dict[str, Any]], List[Dict[str, Any]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Convert list format to dict format.</p> CameraQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for camera query operations.</p> ConfigFileImportRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for configuration file import.</p> ConfigFileExportRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for configuration file export.</p> CaptureImageRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for single image capture.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch image capture.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureHDRRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for HDR image capture.</p> validate_exposure_levels <code>classmethod</code> <pre><code>validate_exposure_levels(v: Union[int, List[float]]) -&gt; Union[int, List[float]]\n</code></pre> <p>Validate exposure levels.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> CaptureHDRBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch HDR image capture.</p> validate_exposure_levels <code>classmethod</code> <pre><code>validate_exposure_levels(v: Union[int, List[float]]) -&gt; Union[int, List[float]]\n</code></pre> <p>Validate exposure levels.</p> validate_output_format <code>classmethod</code> <pre><code>validate_output_format(v: str) -&gt; str\n</code></pre> <p>Validate output format is supported.</p> BandwidthLimitRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting bandwidth limit.</p> CameraPerformanceSettingsRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for updating camera performance settings.</p> <p>Global settings (always applicable): - timeout_ms, retrieve_retry_count, max_concurrent_captures</p> <p>Per-camera GigE settings (requires camera field, only for GigE cameras): - packet_size, inter_packet_delay, bandwidth_limit_mbps</p> ExposureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for exposure setting.</p> GainRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for gain setting.</p> ROIRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for ROI (Region of Interest) setting.</p> TriggerModeRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for trigger mode setting.</p> PixelFormatRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for pixel format setting.</p> WhiteBalanceRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for white balance setting.</p> ImageEnhancementRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for image enhancement setting.</p> BandwidthLimitCameraRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting camera bandwidth limit.</p> PacketSizeRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting camera packet size.</p> InterPacketDelayRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for setting inter-packet delay.</p> StreamStartRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for starting camera stream.</p> StreamStopRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stopping camera stream.</p> StreamStatusRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for getting stream status.</p> HomographyCalibrateCheckerboardRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for checkerboard-based homography calibration.</p> HomographyCalibrateCorrespondencesRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for manual point correspondence calibration.</p> validate_points <code>classmethod</code> <pre><code>validate_points(v: List[List[float]]) -&gt; List[List[float]]\n</code></pre> <p>Validate point arrays.</p> HomographyMeasureBoundingBoxRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for measuring a single bounding box.</p> HomographyMeasureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Unified request model for batch measurements (bounding boxes and/or point-pair distances).</p> validate_boxes <code>classmethod</code> <pre><code>validate_boxes(\n    v: Optional[List[Dict[str, int]]],\n) -&gt; Optional[List[Dict[str, int]]]\n</code></pre> <p>Validate bounding boxes.</p> validate_point_pairs <code>classmethod</code> <pre><code>validate_point_pairs(\n    v: Optional[List[List[List[float]]]],\n) -&gt; Optional[List[List[List[float]]]]\n</code></pre> <p>Validate point pairs.</p> validate_at_least_one <pre><code>validate_at_least_one()\n</code></pre> <p>Ensure at least one measurement type is provided.</p> HomographyMeasureDistanceRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for measuring distance between two points.</p> HomographyCalibrateMultiViewRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for multi-view checkerboard calibration.</p> <p>Note: Checkerboard parameters (board_size, square_size, world_unit) are configured in HomographySettings (see config.py), not passed per-request.</p> validate_positions <code>classmethod</code> <pre><code>validate_positions(v: List[Dict[str, float]]) -&gt; List[Dict[str, float]]\n</code></pre> <p>Validate position format.</p> validate_lengths_match <pre><code>validate_lengths_match()\n</code></pre> <p>Ensure number of images matches number of positions.</p> responses <p>Response models for CameraManagerService.</p> <p>Contains all Pydantic models for API responses, ensuring consistent response formatting across all camera management endpoints.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> IntResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for integer values.</p> FloatResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for float values.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Backend information model.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> CameraInfo <p>               Bases: <code>BaseModel</code></p> <p>Camera information model.</p> CameraStatus <p>               Bases: <code>BaseModel</code></p> <p>Camera status model.</p> CameraCapabilities <p>               Bases: <code>BaseModel</code></p> <p>Camera capabilities model.</p> CameraConfiguration <p>               Bases: <code>BaseModel</code></p> <p>Camera configuration model.</p> CameraInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera information.</p> CameraStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera status.</p> CameraCapabilitiesResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera capabilities.</p> CameraConfigurationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera configuration.</p> ActiveCamerasResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active cameras list.</p> CaptureResult <p>               Bases: <code>BaseModel</code></p> <p>Capture result model.</p> CaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for single image capture.</p> BatchCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch capture operations.</p> HDRCaptureResult <p>               Bases: <code>BaseModel</code></p> <p>HDR capture result model.</p> HDRCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for HDR capture.</p> BatchHDRCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch HDR capture.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p> BandwidthSettings <p>               Bases: <code>BaseModel</code></p> <p>Bandwidth settings model.</p> BandwidthSettingsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for bandwidth settings.</p> CameraPerformanceSettings <p>               Bases: <code>BaseModel</code></p> <p>Camera performance and retry settings model.</p> <p>Global settings: - timeout_ms, retrieve_retry_count, max_concurrent_captures</p> <p>Per-camera GigE settings (None if not applicable or not queried): - packet_size, inter_packet_delay, bandwidth_limit_mbps</p> CameraPerformanceSettingsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for camera performance settings.</p> NetworkDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>Network diagnostics model.</p> NetworkDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for network diagnostics.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Batch operation result model.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> ErrorDetail <p>               Bases: <code>BaseModel</code></p> <p>Error detail model.</p> ErrorResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for error conditions.</p> ParameterRange <p>               Bases: <code>BaseModel</code></p> <p>Parameter range model.</p> RangeResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for parameter ranges.</p> ConfigFileOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Configuration file operation result.</p> ConfigFileResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for configuration file operations.</p> StreamInfo <p>               Bases: <code>BaseModel</code></p> <p>Stream information model.</p> StreamStatus <p>               Bases: <code>BaseModel</code></p> <p>Stream status model.</p> StreamInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stream information.</p> StreamStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stream status.</p> ActiveStreamsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active streams list.</p> HomographyCalibrationResult <p>               Bases: <code>BaseModel</code></p> <p>Homography calibration result model.</p> HomographyCalibrationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for homography calibration.</p> HomographyMeasurementResult <p>               Bases: <code>BaseModel</code></p> <p>Homography measurement result model.</p> HomographyMeasurementResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for single homography measurement.</p> HomographyDistanceResult <p>               Bases: <code>BaseModel</code></p> <p>Homography distance measurement result model.</p> HomographyDistanceResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for distance measurement.</p> HomographyBatchMeasurementData <p>               Bases: <code>BaseModel</code></p> <p>Batch measurement data containing both box and distance measurements.</p> HomographyBatchMeasurementResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for unified batch homography measurements.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.schemas","title":"schemas","text":"<p>TaskSchemas for CameraManagerService endpoints.</p> backend_schemas <p>Backend and Discovery TaskSchemas.</p> capture_schemas <p>Image Capture TaskSchemas.</p> config_schemas <p>Camera Configuration TaskSchemas.</p> homography_schemas <p>Homography Calibration &amp; Measurement TaskSchemas.</p> info_schemas <p>Camera Status and Information TaskSchemas.</p> lifecycle_schemas <p>Camera Lifecycle TaskSchemas.</p> network_schemas <p>Network and Performance TaskSchemas.</p> stream_schemas <p>Streaming TaskSchemas.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.cameras.service","title":"service","text":"<p>CameraManagerService - Service-based API for camera management.</p> <p>This service wraps AsyncCameraManager functionality in a Service-based architecture with comprehensive MCP tool integration and typed client access.</p> CameraManagerService <pre><code>CameraManagerService(include_mocks: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Camera Management Service.</p> <p>Provides comprehensive camera management functionality through a Service-based architecture with MCP tool integration and async camera operations.</p> <p>Initialize CameraManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>include_mocks</code> <code>bool</code> <p>Include mock cameras in discovery</p> <code>False</code> <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup camera manager on shutdown.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available camera backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p> discover_cameras <code>async</code> <pre><code>discover_cameras(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available cameras from all or specific backends.</p> open_camera <code>async</code> <pre><code>open_camera(request: CameraOpenRequest) -&gt; BoolResponse\n</code></pre> <p>Open a single camera with exposure validation.</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(request: CameraOpenBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Open multiple cameras in batch.</p> close_camera <code>async</code> <pre><code>close_camera(request: CameraCloseRequest) -&gt; BoolResponse\n</code></pre> <p>Close a specific camera.</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(request: CameraCloseBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Close multiple cameras in batch.</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; BoolResponse\n</code></pre> <p>Close all active cameras.</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; ActiveCamerasResponse\n</code></pre> <p>Get list of currently active cameras.</p> get_camera_status <code>async</code> <pre><code>get_camera_status(request: CameraQueryRequest) -&gt; CameraStatusResponse\n</code></pre> <p>Get camera status information.</p> get_camera_info <code>async</code> <pre><code>get_camera_info(request: CameraQueryRequest) -&gt; CameraInfoResponse\n</code></pre> <p>Get detailed camera information.</p> get_camera_capabilities <code>async</code> <pre><code>get_camera_capabilities(\n    request: CameraQueryRequest,\n) -&gt; CameraCapabilitiesResponse\n</code></pre> <p>Get camera capabilities information.</p> configure_camera <code>async</code> <pre><code>configure_camera(request: CameraConfigureRequest) -&gt; BoolResponse\n</code></pre> <p>Configure camera parameters.</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    request: CameraConfigureBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Configure multiple cameras in batch.</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(\n    request: CameraQueryRequest,\n) -&gt; CameraConfigurationResponse\n</code></pre> <p>Get current camera configuration.</p> import_camera_config <code>async</code> <pre><code>import_camera_config(request: ConfigFileImportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Import camera configuration from file.</p> export_camera_config <code>async</code> <pre><code>export_camera_config(request: ConfigFileExportRequest) -&gt; ConfigFileResponse\n</code></pre> <p>Export camera configuration to file.</p> capture_image <code>async</code> <pre><code>capture_image(request: CaptureImageRequest) -&gt; CaptureResponse\n</code></pre> <p>Capture a single image with timeout protection.</p> capture_images_batch <code>async</code> <pre><code>capture_images_batch(request: CaptureBatchRequest) -&gt; BatchCaptureResponse\n</code></pre> <p>Capture images from multiple cameras.</p> capture_hdr_image <code>async</code> <pre><code>capture_hdr_image(request: CaptureHDRRequest) -&gt; HDRCaptureResponse\n</code></pre> <p>Capture HDR image sequence.</p> capture_hdr_images_batch <code>async</code> <pre><code>capture_hdr_images_batch(\n    request: CaptureHDRBatchRequest,\n) -&gt; BatchHDRCaptureResponse\n</code></pre> <p>Capture HDR images from multiple cameras.</p> get_network_diagnostics <code>async</code> <pre><code>get_network_diagnostics() -&gt; NetworkDiagnosticsResponse\n</code></pre> <p>Get network diagnostics information.</p> get_performance_settings <code>async</code> <pre><code>get_performance_settings(\n    request: CameraPerformanceSettingsRequest = None,\n) -&gt; CameraPerformanceSettingsResponse\n</code></pre> <p>Get current camera performance settings.</p> <p>Returns global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p> set_performance_settings <code>async</code> <pre><code>set_performance_settings(\n    request: CameraPerformanceSettingsRequest,\n) -&gt; BoolResponse\n</code></pre> <p>Update camera performance settings.</p> <p>Updates global settings (timeout, retries, concurrent captures) and optionally per-camera GigE settings (packet_size, inter_packet_delay, bandwidth_limit) if camera is specified.</p> start_stream <code>async</code> <pre><code>start_stream(request: StreamStartRequest) -&gt; StreamInfoResponse\n</code></pre> <p>Start camera stream with resilient state management.</p> stop_stream <code>async</code> <pre><code>stop_stream(request: StreamStopRequest) -&gt; BoolResponse\n</code></pre> <p>Stop camera stream with resilient state management.</p> get_stream_status <code>async</code> <pre><code>get_stream_status(request: StreamStatusRequest) -&gt; StreamStatusResponse\n</code></pre> <p>Get camera stream status with resilient state management.</p> get_active_streams <code>async</code> <pre><code>get_active_streams() -&gt; ActiveStreamsResponse\n</code></pre> <p>Get list of cameras with active streams.</p> stop_all_streams <code>async</code> <pre><code>stop_all_streams() -&gt; BoolResponse\n</code></pre> <p>Stop all active camera streams.</p> serve_camera_stream <code>async</code> <pre><code>serve_camera_stream(camera_name: str)\n</code></pre> <p>Serve MJPEG video stream for a specific camera.</p> calibrate_homography_checkerboard <code>async</code> <pre><code>calibrate_homography_checkerboard(\n    request: HomographyCalibrateCheckerboardRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography using checkerboard pattern detection.</p> calibrate_homography_correspondences <code>async</code> <pre><code>calibrate_homography_correspondences(\n    request: HomographyCalibrateCorrespondencesRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from known point correspondences.</p> calibrate_homography_multi_view <code>async</code> <pre><code>calibrate_homography_multi_view(\n    request: HomographyCalibrateMultiViewRequest,\n) -&gt; HomographyCalibrationResponse\n</code></pre> <p>Calibrate homography from multiple checkerboard positions on the same plane.</p> <p>Ideal for calibrating long surfaces (metallic bars, conveyor belts) using a standard checkerboard moved to multiple positions.</p> measure_homography_box <code>async</code> <pre><code>measure_homography_box(\n    request: HomographyMeasureBoundingBoxRequest,\n) -&gt; HomographyMeasurementResponse\n</code></pre> <p>Measure bounding box dimensions using homography calibration.</p> measure_homography_batch <code>async</code> <pre><code>measure_homography_batch(\n    request: HomographyMeasureBatchRequest,\n) -&gt; HomographyBatchMeasurementResponse\n</code></pre> <p>Unified batch measurement for bounding boxes and/or point-pair distances.</p> measure_homography_distance <code>async</code> <pre><code>measure_homography_distance(\n    request: HomographyMeasureDistanceRequest,\n) -&gt; HomographyDistanceResponse\n</code></pre> <p>Measure distance between two points using homography calibration.</p> health_check <code>async</code> <pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs","title":"plcs","text":"<p>PLC API Service - REST API for PLC management and control.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.PLCManagerConnectionManager","title":"PLCManagerConnectionManager","text":"<pre><code>PLCManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for PLCManagerService.</p> <p>Provides strongly-typed methods for all PLC management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available PLC backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p> discover_plcs <code>async</code> <pre><code>discover_plcs(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available PLCs from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers</p> connect_plc <code>async</code> <pre><code>connect_plc(\n    plc_name: str,\n    backend: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n) -&gt; bool\n</code></pre> <p>Connect to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>backend</code> <code>str</code> <p>Backend type (AllenBradley, Siemens, Modbus)</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>Specific PLC type (logix, slc, cip, auto)</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> connect_plcs_batch <code>async</code> <pre><code>connect_plcs_batch(plcs: List[PLCConnectRequest]) -&gt; Dict[str, Any]\n</code></pre> <p>Connect to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[PLCConnectRequest]</code> <p>List of PLC connection requests</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> disconnect_plc <code>async</code> <pre><code>disconnect_plc(plc: str) -&gt; bool\n</code></pre> <p>Disconnect from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to disconnect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> disconnect_plcs_batch <code>async</code> <pre><code>disconnect_plcs_batch(plcs: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[str]</code> <p>List of PLC names to disconnect</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> disconnect_all_plcs <code>async</code> <pre><code>disconnect_all_plcs() -&gt; bool\n</code></pre> <p>Disconnect from all active PLCs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_active_plcs <code>async</code> <pre><code>get_active_plcs() -&gt; List[str]\n</code></pre> <p>Get list of currently active PLCs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active PLC names</p> read_tags <code>async</code> <pre><code>read_tags(plc: str, tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tag values from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tags <code>async</code> <pre><code>write_tags(\n    plc: str, tags: Union[Tuple[str, Any], List[Tuple[str, Any]]]\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tag values to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> read_tags_batch <code>async</code> <pre><code>read_tags_batch(\n    requests: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[str, List[str]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their tag read results</p> write_tags_batch <code>async</code> <pre><code>write_tags_batch(\n    requests: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; Dict[str, Dict[str, bool]]\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, bool]]</code> <p>Dictionary mapping PLC names to their tag write results</p> list_tags <code>async</code> <pre><code>list_tags(plc: str) -&gt; List[str]\n</code></pre> <p>List all available tags on a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(plc: str, tag: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tag</code> <code>str</code> <p>Tag name</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Tag information</p> get_plc_status <code>async</code> <pre><code>get_plc_status(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get PLC status information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC status information</p> get_plc_info <code>async</code> <pre><code>get_plc_info(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed PLC information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC information</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.PLCManagerService","title":"PLCManagerService","text":"<pre><code>PLCManagerService(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>PLC Management Service.</p> <p>Provides comprehensive PLC management functionality through a Service-based architecture with MCP tool integration and async PLC operations.</p> <p>Initialize PLCManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup PLC manager on shutdown.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available PLC backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p> discover_plcs <code>async</code> <pre><code>discover_plcs(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available PLCs from all or specific backends.</p> connect_plc <code>async</code> <pre><code>connect_plc(request: PLCConnectRequest) -&gt; BoolResponse\n</code></pre> <p>Connect to a PLC.</p> connect_plcs_batch <code>async</code> <pre><code>connect_plcs_batch(request: PLCConnectBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Connect to multiple PLCs in batch.</p> disconnect_plc <code>async</code> <pre><code>disconnect_plc(request: PLCDisconnectRequest) -&gt; BoolResponse\n</code></pre> <p>Disconnect from a PLC.</p> disconnect_plcs_batch <code>async</code> <pre><code>disconnect_plcs_batch(\n    request: PLCDisconnectBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p> disconnect_all_plcs <code>async</code> <pre><code>disconnect_all_plcs() -&gt; BoolResponse\n</code></pre> <p>Disconnect from all active PLCs.</p> get_active_plcs <code>async</code> <pre><code>get_active_plcs() -&gt; ActivePLCsResponse\n</code></pre> <p>Get list of currently active PLCs.</p> read_tags <code>async</code> <pre><code>read_tags(request: TagReadRequest) -&gt; TagReadResponse\n</code></pre> <p>Read tag values from a PLC.</p> write_tags <code>async</code> <pre><code>write_tags(request: TagWriteRequest) -&gt; TagWriteResponse\n</code></pre> <p>Write tag values to a PLC.</p> read_tags_batch <code>async</code> <pre><code>read_tags_batch(request: TagBatchReadRequest) -&gt; BatchTagReadResponse\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> write_tags_batch <code>async</code> <pre><code>write_tags_batch(request: TagBatchWriteRequest) -&gt; BatchTagWriteResponse\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> list_tags <code>async</code> <pre><code>list_tags(request: PLCQueryRequest) -&gt; TagListResponse\n</code></pre> <p>List all available tags on a PLC.</p> get_tag_info <code>async</code> <pre><code>get_tag_info(request: TagInfoRequest) -&gt; TagInfoResponse\n</code></pre> <p>Get detailed information about a specific tag.</p> get_plc_status <code>async</code> <pre><code>get_plc_status(request: PLCQueryRequest) -&gt; PLCStatusResponse\n</code></pre> <p>Get PLC status information.</p> get_plc_info <code>async</code> <pre><code>get_plc_info(request: PLCQueryRequest) -&gt; PLCInfoResponse\n</code></pre> <p>Get detailed PLC information.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p> health_check <code>async</code> <pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.connection_manager","title":"connection_manager","text":"<p>Connection Manager for PLCManagerService.</p> <p>Provides a strongly-typed client interface for programmatic access to PLC management operations.</p> PLCManagerConnectionManager <pre><code>PLCManagerConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for PLCManagerService.</p> <p>Provides strongly-typed methods for all PLC management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available PLC backends.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available backend names</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping backend names to their information</p> discover_plcs <code>async</code> <pre><code>discover_plcs(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available PLCs from all or specific backends.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Optional[str]</code> <p>Optional backend name to filter by</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers</p> connect_plc <code>async</code> <pre><code>connect_plc(\n    plc_name: str,\n    backend: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n) -&gt; bool\n</code></pre> <p>Connect to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>backend</code> <code>str</code> <p>Backend type (AllenBradley, Siemens, Modbus)</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>Specific PLC type (logix, slc, cip, auto)</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> connect_plcs_batch <code>async</code> <pre><code>connect_plcs_batch(plcs: List[PLCConnectRequest]) -&gt; Dict[str, Any]\n</code></pre> <p>Connect to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[PLCConnectRequest]</code> <p>List of PLC connection requests</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> disconnect_plc <code>async</code> <pre><code>disconnect_plc(plc: str) -&gt; bool\n</code></pre> <p>Disconnect from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to disconnect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> disconnect_plcs_batch <code>async</code> <pre><code>disconnect_plcs_batch(plcs: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>plcs</code> <code>List[str]</code> <p>List of PLC names to disconnect</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Batch operation results</p> disconnect_all_plcs <code>async</code> <pre><code>disconnect_all_plcs() -&gt; bool\n</code></pre> <p>Disconnect from all active PLCs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful</p> get_active_plcs <code>async</code> <pre><code>get_active_plcs() -&gt; List[str]\n</code></pre> <p>Get list of currently active PLCs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of active PLC names</p> read_tags <code>async</code> <pre><code>read_tags(plc: str, tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tag values from a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tags <code>async</code> <pre><code>write_tags(\n    plc: str, tags: Union[Tuple[str, Any], List[Tuple[str, Any]]]\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tag values to a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> read_tags_batch <code>async</code> <pre><code>read_tags_batch(\n    requests: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[str, List[str]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their tag read results</p> write_tags_batch <code>async</code> <pre><code>write_tags_batch(\n    requests: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; Dict[str, Dict[str, bool]]\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, bool]]</code> <p>Dictionary mapping PLC names to their tag write results</p> list_tags <code>async</code> <pre><code>list_tags(plc: str) -&gt; List[str]\n</code></pre> <p>List all available tags on a PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(plc: str, tag: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name</p> required <code>tag</code> <code>str</code> <p>Tag name</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Tag information</p> get_plc_status <code>async</code> <pre><code>get_plc_status(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get PLC status information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC status information</p> get_plc_info <code>async</code> <pre><code>get_plc_info(plc: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed PLC information.</p> <p>Parameters:</p> Name Type Description Default <code>plc</code> <code>str</code> <p>PLC name to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>PLC information</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics information.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>System diagnostics data</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.launcher","title":"launcher","text":"<p>PLC API service launcher.</p> main <pre><code>main()\n</code></pre> <p>Main launcher function.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.models","title":"models","text":"<p>PLC API models - Request and Response models.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> PLCConnectBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch PLC connection.</p> PLCConnectRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for connecting to a PLC.</p> PLCDisconnectBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch PLC disconnection.</p> PLCDisconnectRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for disconnecting from a PLC.</p> PLCQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for PLC query operations.</p> TagBatchReadRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch tag reading from multiple PLCs.</p> validate_requests <code>classmethod</code> <pre><code>validate_requests(\n    v: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; List[Tuple[str, Union[str, List[str]]]]\n</code></pre> <p>Validate batch read requests.</p> TagBatchWriteRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch tag writing to multiple PLCs.</p> validate_requests <code>classmethod</code> <pre><code>validate_requests(\n    v: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]\n</code></pre> <p>Validate batch write requests.</p> TagInfoRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for getting tag information.</p> TagReadRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for reading tags from a PLC.</p> validate_tags <code>classmethod</code> <pre><code>validate_tags(v: Union[str, List[str]]) -&gt; Union[str, List[str]]\n</code></pre> <p>Ensure tags is not empty.</p> TagWriteRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for writing tags to a PLC.</p> validate_tags <code>classmethod</code> <pre><code>validate_tags(\n    v: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Union[Tuple[str, Any], List[Tuple[str, Any]]]\n</code></pre> <p>Ensure tags is properly formatted.</p> ActivePLCsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active PLCs listing.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Backend information model.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Batch operation result model.</p> BatchTagReadResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch tag read operations.</p> BatchTagWriteResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch tag write operations.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> FloatResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for float values.</p> IntResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for integer values.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> PLCInfo <p>               Bases: <code>BaseModel</code></p> <p>PLC information model.</p> PLCInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for PLC information.</p> PLCStatus <p>               Bases: <code>BaseModel</code></p> <p>PLC status model.</p> PLCStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for PLC status.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p> TagInfo <p>               Bases: <code>BaseModel</code></p> <p>Tag information model.</p> TagInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag information.</p> TagListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag list operations.</p> TagReadResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag read operations.</p> TagWriteResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag write operations.</p> requests <p>Request models for PLCManagerService.</p> <p>Contains all Pydantic models for API requests, ensuring proper input validation and documentation for all PLC operations.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> PLCConnectRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for connecting to a PLC.</p> PLCConnectBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch PLC connection.</p> PLCDisconnectRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for disconnecting from a PLC.</p> PLCDisconnectBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch PLC disconnection.</p> PLCQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for PLC query operations.</p> TagReadRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for reading tags from a PLC.</p> validate_tags <code>classmethod</code> <pre><code>validate_tags(v: Union[str, List[str]]) -&gt; Union[str, List[str]]\n</code></pre> <p>Ensure tags is not empty.</p> TagWriteRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for writing tags to a PLC.</p> validate_tags <code>classmethod</code> <pre><code>validate_tags(\n    v: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Union[Tuple[str, Any], List[Tuple[str, Any]]]\n</code></pre> <p>Ensure tags is properly formatted.</p> TagBatchReadRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch tag reading from multiple PLCs.</p> validate_requests <code>classmethod</code> <pre><code>validate_requests(\n    v: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; List[Tuple[str, Union[str, List[str]]]]\n</code></pre> <p>Validate batch read requests.</p> TagBatchWriteRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch tag writing to multiple PLCs.</p> validate_requests <code>classmethod</code> <pre><code>validate_requests(\n    v: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]\n</code></pre> <p>Validate batch write requests.</p> TagInfoRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for getting tag information.</p> responses <p>Response models for PLCManagerService.</p> <p>Contains all Pydantic models for API responses, ensuring consistent response formatting across all PLC management endpoints.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> IntResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for integer values.</p> FloatResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for float values.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Backend information model.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> PLCInfo <p>               Bases: <code>BaseModel</code></p> <p>PLC information model.</p> PLCStatus <p>               Bases: <code>BaseModel</code></p> <p>PLC status model.</p> PLCInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for PLC information.</p> PLCStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for PLC status.</p> ActivePLCsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for active PLCs listing.</p> TagReadResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag read operations.</p> TagWriteResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag write operations.</p> TagListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag list operations.</p> TagInfo <p>               Bases: <code>BaseModel</code></p> <p>Tag information model.</p> TagInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for tag information.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Batch operation result model.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> BatchTagReadResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch tag read operations.</p> BatchTagWriteResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch tag write operations.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.schemas","title":"schemas","text":"<p>TaskSchemas for PLCManagerService endpoints.</p> backend_schemas <p>Backend and Discovery TaskSchemas.</p> lifecycle_schemas <p>PLC Lifecycle TaskSchemas.</p> status_schemas <p>Status &amp; Information TaskSchemas.</p> tag_schemas <p>Tag Operations TaskSchemas.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.plcs.service","title":"service","text":"<p>PLCManagerService - Service-based API for PLC management.</p> <p>This service wraps PLCManager functionality in a Service-based architecture with comprehensive MCP tool integration and typed client access.</p> PLCManagerService <pre><code>PLCManagerService(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>PLC Management Service.</p> <p>Provides comprehensive PLC management functionality through a Service-based architecture with MCP tool integration and async PLC operations.</p> <p>Initialize PLCManagerService.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional Service initialization parameters</p> <code>{}</code> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup PLC manager on shutdown.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; BackendsResponse\n</code></pre> <p>Discover available PLC backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; BackendInfoResponse\n</code></pre> <p>Get detailed information about all backends.</p> discover_plcs <code>async</code> <pre><code>discover_plcs(request: BackendFilterRequest) -&gt; ListResponse\n</code></pre> <p>Discover available PLCs from all or specific backends.</p> connect_plc <code>async</code> <pre><code>connect_plc(request: PLCConnectRequest) -&gt; BoolResponse\n</code></pre> <p>Connect to a PLC.</p> connect_plcs_batch <code>async</code> <pre><code>connect_plcs_batch(request: PLCConnectBatchRequest) -&gt; BatchOperationResponse\n</code></pre> <p>Connect to multiple PLCs in batch.</p> disconnect_plc <code>async</code> <pre><code>disconnect_plc(request: PLCDisconnectRequest) -&gt; BoolResponse\n</code></pre> <p>Disconnect from a PLC.</p> disconnect_plcs_batch <code>async</code> <pre><code>disconnect_plcs_batch(\n    request: PLCDisconnectBatchRequest,\n) -&gt; BatchOperationResponse\n</code></pre> <p>Disconnect from multiple PLCs in batch.</p> disconnect_all_plcs <code>async</code> <pre><code>disconnect_all_plcs() -&gt; BoolResponse\n</code></pre> <p>Disconnect from all active PLCs.</p> get_active_plcs <code>async</code> <pre><code>get_active_plcs() -&gt; ActivePLCsResponse\n</code></pre> <p>Get list of currently active PLCs.</p> read_tags <code>async</code> <pre><code>read_tags(request: TagReadRequest) -&gt; TagReadResponse\n</code></pre> <p>Read tag values from a PLC.</p> write_tags <code>async</code> <pre><code>write_tags(request: TagWriteRequest) -&gt; TagWriteResponse\n</code></pre> <p>Write tag values to a PLC.</p> read_tags_batch <code>async</code> <pre><code>read_tags_batch(request: TagBatchReadRequest) -&gt; BatchTagReadResponse\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> write_tags_batch <code>async</code> <pre><code>write_tags_batch(request: TagBatchWriteRequest) -&gt; BatchTagWriteResponse\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> list_tags <code>async</code> <pre><code>list_tags(request: PLCQueryRequest) -&gt; TagListResponse\n</code></pre> <p>List all available tags on a PLC.</p> get_tag_info <code>async</code> <pre><code>get_tag_info(request: TagInfoRequest) -&gt; TagInfoResponse\n</code></pre> <p>Get detailed information about a specific tag.</p> get_plc_status <code>async</code> <pre><code>get_plc_status(request: PLCQueryRequest) -&gt; PLCStatusResponse\n</code></pre> <p>Get PLC status information.</p> get_plc_info <code>async</code> <pre><code>get_plc_info(request: PLCQueryRequest) -&gt; PLCInfoResponse\n</code></pre> <p>Get detailed PLC information.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; SystemDiagnosticsResponse\n</code></pre> <p>Get system diagnostics information.</p> health_check <code>async</code> <pre><code>health_check() -&gt; dict\n</code></pre> <p>Health check endpoint for container healthcheck.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors","title":"sensors","text":"<p>Sensor API module providing service and connection management.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.SensorConnectionManager","title":"SensorConnectionManager","text":"<pre><code>SensorConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Strongly-typed connection manager for sensor service operations.</p> connect_sensor <code>async</code> <pre><code>connect_sensor(\n    sensor_id: str, backend_type: str, config: Dict[str, Any], address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>backend_type</code> <code>str</code> <p>Backend type (mqtt, http, serial)</p> required <code>config</code> <code>Dict[str, Any]</code> <p>Backend-specific configuration</p> required <code>address</code> <code>str</code> <p>Sensor address (topic, endpoint, or port)</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> disconnect_sensor <code>async</code> <pre><code>disconnect_sensor(sensor_id: str) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p> read_sensor_data <code>async</code> <pre><code>read_sensor_data(\n    sensor_id: str, timeout: Optional[float] = None\n) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>timeout</code> <code>Optional[float]</code> <p>Optional read timeout in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p> get_sensor_status <code>async</code> <pre><code>get_sensor_status(sensor_id: str) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p> list_sensors <code>async</code> <pre><code>list_sensors(include_status: bool = False) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>include_status</code> <code>bool</code> <p>Whether to include connection status for each sensor</p> <code>False</code> <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p> connect_mqtt_sensor <code>async</code> <pre><code>connect_mqtt_sensor(\n    sensor_id: str, broker_url: str, identifier: str, address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an MQTT sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>str</code> <p>Client identifier for MQTT connection</p> required <code>address</code> <code>str</code> <p>MQTT topic to subscribe to</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> connect_http_sensor <code>async</code> <pre><code>connect_http_sensor(\n    sensor_id: str,\n    base_url: str,\n    address: str,\n    headers: Optional[Dict[str, str]] = None,\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an HTTP sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests</p> required <code>address</code> <code>str</code> <p>Endpoint path for sensor data</p> required <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> connect_serial_sensor <code>async</code> <pre><code>connect_serial_sensor(\n    sensor_id: str, port: str, baudrate: int = 9600, timeout: float = 1.0\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a serial sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>port</code> <code>str</code> <p>Serial port (e.g., \"/dev/ttyUSB0\" or \"COM1\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baud rate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Serial read timeout</p> <code>1.0</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.SensorManagerService","title":"SensorManagerService","text":"<pre><code>SensorManagerService(manager: Optional[SensorManager] = None, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Service wrapper for SensorManager with MCP endpoint registration.</p> <p>Initialize the sensor manager service.</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>Optional[SensorManager]</code> <p>Optional SensorManager instance. If None, creates a new one.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the Service base class</p> <code>{}</code> manager <code>property</code> <pre><code>manager: SensorManager\n</code></pre> <p>Get the underlying SensorManager instance.</p> connect_sensor <code>async</code> <pre><code>connect_sensor(request: SensorConnectionRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorConnectionRequest</code> <p>Connection request with sensor configuration</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> disconnect_sensor <code>async</code> <pre><code>disconnect_sensor(request: SensorStatusRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p> read_sensor_data <code>async</code> <pre><code>read_sensor_data(request: SensorDataRequest) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorDataRequest</code> <p>Request specifying sensor and read parameters</p> required <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p> get_sensor_status <code>async</code> <pre><code>get_sensor_status(request: SensorStatusRequest) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p> list_sensors <code>async</code> <pre><code>list_sensors(request: SensorListRequest) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorListRequest</code> <p>Request with listing options</p> required <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.connection_manager","title":"connection_manager","text":"<p>Connection manager for typed sensor service client access.</p> SensorConnectionManager <pre><code>SensorConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Strongly-typed connection manager for sensor service operations.</p> connect_sensor <code>async</code> <pre><code>connect_sensor(\n    sensor_id: str, backend_type: str, config: Dict[str, Any], address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>backend_type</code> <code>str</code> <p>Backend type (mqtt, http, serial)</p> required <code>config</code> <code>Dict[str, Any]</code> <p>Backend-specific configuration</p> required <code>address</code> <code>str</code> <p>Sensor address (topic, endpoint, or port)</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> disconnect_sensor <code>async</code> <pre><code>disconnect_sensor(sensor_id: str) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p> read_sensor_data <code>async</code> <pre><code>read_sensor_data(\n    sensor_id: str, timeout: Optional[float] = None\n) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>timeout</code> <code>Optional[float]</code> <p>Optional read timeout in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p> get_sensor_status <code>async</code> <pre><code>get_sensor_status(sensor_id: str) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p> list_sensors <code>async</code> <pre><code>list_sensors(include_status: bool = False) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>include_status</code> <code>bool</code> <p>Whether to include connection status for each sensor</p> <code>False</code> <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p> connect_mqtt_sensor <code>async</code> <pre><code>connect_mqtt_sensor(\n    sensor_id: str, broker_url: str, identifier: str, address: str\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an MQTT sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>str</code> <p>Client identifier for MQTT connection</p> required <code>address</code> <code>str</code> <p>MQTT topic to subscribe to</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> connect_http_sensor <code>async</code> <pre><code>connect_http_sensor(\n    sensor_id: str,\n    base_url: str,\n    address: str,\n    headers: Optional[Dict[str, str]] = None,\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to an HTTP sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests</p> required <code>address</code> <code>str</code> <p>Endpoint path for sensor data</p> required <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers</p> <code>None</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> connect_serial_sensor <code>async</code> <pre><code>connect_serial_sensor(\n    sensor_id: str, port: str, baudrate: int = 9600, timeout: float = 1.0\n) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a serial sensor with simplified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>port</code> <code>str</code> <p>Serial port (e.g., \"/dev/ttyUSB0\" or \"COM1\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baud rate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Serial read timeout</p> <code>1.0</code> <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.models","title":"models","text":"<p>Sensor API models for request/response data structures.</p> SensorConnectionRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to connect to a sensor.</p> SensorDataRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to read data from a connected sensor.</p> SensorListRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to list all sensors.</p> SensorStatusRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to get status of a sensor.</p> SensorConnectionResponse <p>               Bases: <code>BaseModel</code></p> <p>Response from sensor connection operation.</p> SensorConnectionStatus <p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Status of sensor connection.</p> SensorDataResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing sensor data.</p> SensorInfo <p>               Bases: <code>BaseModel</code></p> <p>Information about a sensor.</p> SensorListResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing list of sensors.</p> SensorStatusResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing sensor status information.</p> requests <p>Request models for sensor operations.</p> SensorConnectionRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to connect to a sensor.</p> SensorDataRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to read data from a connected sensor.</p> SensorStatusRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to get status of a sensor.</p> SensorListRequest <p>               Bases: <code>BaseModel</code></p> <p>Request to list all sensors.</p> responses <p>Response models for sensor operations.</p> SensorConnectionStatus <p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Status of sensor connection.</p> SensorInfo <p>               Bases: <code>BaseModel</code></p> <p>Information about a sensor.</p> SensorConnectionResponse <p>               Bases: <code>BaseModel</code></p> <p>Response from sensor connection operation.</p> SensorDataResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing sensor data.</p> SensorStatusResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing sensor status information.</p> SensorListResponse <p>               Bases: <code>BaseModel</code></p> <p>Response containing list of sensors.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.schemas","title":"schemas","text":"<p>Sensor task schemas for service operations.</p> SensorDataSchemas <p>Task schemas for sensor data access.</p> SensorLifecycleSchemas <p>Task schemas for sensor lifecycle management.</p> data <p>Task schemas for sensor data operations.</p> SensorDataSchemas <p>Task schemas for sensor data access.</p> lifecycle <p>Task schemas for sensor lifecycle operations.</p> SensorLifecycleSchemas <p>Task schemas for sensor lifecycle management.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.sensors.service","title":"service","text":"<p>Sensor Manager Service providing MCP endpoints for sensor operations.</p> SensorManagerService <pre><code>SensorManagerService(manager: Optional[SensorManager] = None, **kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Service wrapper for SensorManager with MCP endpoint registration.</p> <p>Initialize the sensor manager service.</p> <p>Parameters:</p> Name Type Description Default <code>manager</code> <code>Optional[SensorManager]</code> <p>Optional SensorManager instance. If None, creates a new one.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the Service base class</p> <code>{}</code> manager <code>property</code> <pre><code>manager: SensorManager\n</code></pre> <p>Get the underlying SensorManager instance.</p> connect_sensor <code>async</code> <pre><code>connect_sensor(request: SensorConnectionRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Connect to a sensor with specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorConnectionRequest</code> <p>Connection request with sensor configuration</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of connection</p> disconnect_sensor <code>async</code> <pre><code>disconnect_sensor(request: SensorStatusRequest) -&gt; SensorConnectionResponse\n</code></pre> <p>Disconnect from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id to disconnect</p> required <p>Returns:</p> Type Description <code>SensorConnectionResponse</code> <p>Response indicating success/failure of disconnection</p> read_sensor_data <code>async</code> <pre><code>read_sensor_data(request: SensorDataRequest) -&gt; SensorDataResponse\n</code></pre> <p>Read data from a connected sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorDataRequest</code> <p>Request specifying sensor and read parameters</p> required <p>Returns:</p> Type Description <code>SensorDataResponse</code> <p>Response containing sensor data or error information</p> get_sensor_status <code>async</code> <pre><code>get_sensor_status(request: SensorStatusRequest) -&gt; SensorStatusResponse\n</code></pre> <p>Get status information for a sensor.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorStatusRequest</code> <p>Request containing sensor_id</p> required <p>Returns:</p> Type Description <code>SensorStatusResponse</code> <p>Response containing sensor status information</p> list_sensors <code>async</code> <pre><code>list_sensors(request: SensorListRequest) -&gt; SensorListResponse\n</code></pre> <p>List all registered sensors.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SensorListRequest</code> <p>Request with listing options</p> required <p>Returns:</p> Type Description <code>SensorListResponse</code> <p>Response containing list of sensors</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras","title":"stereo_cameras","text":"<p>StereoCameraService - Service-based stereo camera management API.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.StereoCameraConnectionManager","title":"StereoCameraConnectionManager","text":"<pre><code>StereoCameraConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for StereoCameraService.</p> <p>Provides strongly-typed methods for all stereo camera management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available stereo camera backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> discover_cameras <code>async</code> <pre><code>discover_cameras(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available stereo cameras.</p> open_camera <code>async</code> <pre><code>open_camera(camera: str, test_connection: bool = True) -&gt; bool\n</code></pre> <p>Open a stereo camera.</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(\n    cameras: List[str], test_connection: bool = True\n) -&gt; Dict[str, Any]\n</code></pre> <p>Open multiple stereo cameras.</p> close_camera <code>async</code> <pre><code>close_camera(camera: str) -&gt; bool\n</code></pre> <p>Close a stereo camera.</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(cameras: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Close multiple stereo cameras.</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; bool\n</code></pre> <p>Close all active stereo cameras.</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; List[str]\n</code></pre> <p>Get list of currently active stereo cameras.</p> get_camera_status <code>async</code> <pre><code>get_camera_status(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get stereo camera status.</p> get_camera_info <code>async</code> <pre><code>get_camera_info(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed stereo camera information.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics.</p> configure_camera <code>async</code> <pre><code>configure_camera(camera: str, properties: Dict[str, Any]) -&gt; bool\n</code></pre> <p>Configure stereo camera parameters.</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    configurations: Dict[str, Dict[str, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Configure multiple stereo cameras.</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get current stereo camera configuration.</p> capture_stereo_pair <code>async</code> <pre><code>capture_stereo_pair(\n    camera: str,\n    save_intensity_path: Optional[str] = None,\n    save_disparity_path: Optional[str] = None,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture stereo data (intensity + disparity).</p> capture_stereo_batch <code>async</code> <pre><code>capture_stereo_batch(\n    captures: List[Dict[str, Any]], output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture stereo data from multiple cameras.</p> capture_point_cloud <code>async</code> <pre><code>capture_point_cloud(\n    camera: str,\n    save_path: Optional[str] = None,\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n    output_format: str = \"numpy\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture and generate 3D point cloud.</p> capture_point_cloud_batch <code>async</code> <pre><code>capture_point_cloud_batch(\n    captures: List[Dict[str, Any]], output_format: str = \"numpy\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture point clouds from multiple cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.StereoCameraService","title":"StereoCameraService","text":"<pre><code>StereoCameraService(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Stereo Camera Management Service.</p> <p>Provides comprehensive REST API and MCP tools for managing stereo cameras with multi-component capture capabilities (intensity, disparity, point clouds).</p> <p>Supported Operations: - Backend discovery and information - Camera lifecycle management (open, close, status) - Multi-component capture (intensity + disparity) - Point cloud generation with optional color - Camera configuration (depth range, illumination, binning, quality, exposure, gain) - Batch operations for multiple cameras - System diagnostics and monitoring</p> <p>Initialize StereoCameraService.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to Service base class</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.connection_manager","title":"connection_manager","text":"<p>Connection Manager for StereoCameraService.</p> <p>Provides a strongly-typed client interface for programmatic access to stereo camera management operations.</p> StereoCameraConnectionManager <pre><code>StereoCameraConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConnectionManager</code></p> <p>Connection Manager for StereoCameraService.</p> <p>Provides strongly-typed methods for all stereo camera management operations, making it easy to use the service programmatically from other applications.</p> get <code>async</code> <pre><code>get(endpoint: str, http_timeout: float = 60.0) -&gt; Dict[str, Any]\n</code></pre> <p>Make GET request to service endpoint.</p> post <code>async</code> <pre><code>post(\n    endpoint: str, data: Dict[str, Any] = None, http_timeout: float = 60.0\n) -&gt; Dict[str, Any]\n</code></pre> <p>Make POST request to service endpoint.</p> discover_backends <code>async</code> <pre><code>discover_backends() -&gt; List[str]\n</code></pre> <p>Discover available stereo camera backends.</p> get_backend_info <code>async</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about all backends.</p> discover_cameras <code>async</code> <pre><code>discover_cameras(backend: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Discover available stereo cameras.</p> open_camera <code>async</code> <pre><code>open_camera(camera: str, test_connection: bool = True) -&gt; bool\n</code></pre> <p>Open a stereo camera.</p> open_cameras_batch <code>async</code> <pre><code>open_cameras_batch(\n    cameras: List[str], test_connection: bool = True\n) -&gt; Dict[str, Any]\n</code></pre> <p>Open multiple stereo cameras.</p> close_camera <code>async</code> <pre><code>close_camera(camera: str) -&gt; bool\n</code></pre> <p>Close a stereo camera.</p> close_cameras_batch <code>async</code> <pre><code>close_cameras_batch(cameras: List[str]) -&gt; Dict[str, Any]\n</code></pre> <p>Close multiple stereo cameras.</p> close_all_cameras <code>async</code> <pre><code>close_all_cameras() -&gt; bool\n</code></pre> <p>Close all active stereo cameras.</p> get_active_cameras <code>async</code> <pre><code>get_active_cameras() -&gt; List[str]\n</code></pre> <p>Get list of currently active stereo cameras.</p> get_camera_status <code>async</code> <pre><code>get_camera_status(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get stereo camera status.</p> get_camera_info <code>async</code> <pre><code>get_camera_info(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed stereo camera information.</p> get_system_diagnostics <code>async</code> <pre><code>get_system_diagnostics() -&gt; Dict[str, Any]\n</code></pre> <p>Get system diagnostics.</p> configure_camera <code>async</code> <pre><code>configure_camera(camera: str, properties: Dict[str, Any]) -&gt; bool\n</code></pre> <p>Configure stereo camera parameters.</p> configure_cameras_batch <code>async</code> <pre><code>configure_cameras_batch(\n    configurations: Dict[str, Dict[str, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Configure multiple stereo cameras.</p> get_camera_configuration <code>async</code> <pre><code>get_camera_configuration(camera: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get current stereo camera configuration.</p> capture_stereo_pair <code>async</code> <pre><code>capture_stereo_pair(\n    camera: str,\n    save_intensity_path: Optional[str] = None,\n    save_disparity_path: Optional[str] = None,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n    output_format: str = \"pil\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture stereo data (intensity + disparity).</p> capture_stereo_batch <code>async</code> <pre><code>capture_stereo_batch(\n    captures: List[Dict[str, Any]], output_format: str = \"pil\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture stereo data from multiple cameras.</p> capture_point_cloud <code>async</code> <pre><code>capture_point_cloud(\n    camera: str,\n    save_path: Optional[str] = None,\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n    output_format: str = \"numpy\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture and generate 3D point cloud.</p> capture_point_cloud_batch <code>async</code> <pre><code>capture_point_cloud_batch(\n    captures: List[Dict[str, Any]], output_format: str = \"numpy\"\n) -&gt; Dict[str, Any]\n</code></pre> <p>Capture point clouds from multiple cameras.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.launcher","title":"launcher","text":"<p>Stereo Camera API service launcher.</p> main <pre><code>main()\n</code></pre> <p>Main launcher function.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.models","title":"models","text":"<p>Models for StereoCameraService API.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> PointCloudCaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch point cloud capture.</p> PointCloudCaptureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for point cloud capture.</p> StereoCameraCloseBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera closing.</p> StereoCameraCloseRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for closing a stereo camera.</p> StereoCameraConfigureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera configuration.</p> StereoCameraConfigureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo camera configuration.</p> StereoCameraOpenBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera opening.</p> StereoCameraOpenRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for opening a stereo camera.</p> StereoCameraQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo camera queries.</p> StereoCaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo capture.</p> StereoCaptureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo capture.</p> ActiveStereoCamerasResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for listing active stereo cameras.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera backend information model.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Individual batch operation result.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> PointCloudBatchResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch point cloud capture.</p> PointCloudBatchResult <p>               Bases: <code>BaseModel</code></p> <p>Batch point cloud capture result model.</p> PointCloudResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for point cloud capture.</p> PointCloudResult <p>               Bases: <code>BaseModel</code></p> <p>Point cloud capture result model.</p> StereoCameraConfiguration <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera configuration model.</p> StereoCameraConfigurationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera configuration.</p> StereoCameraInfo <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera information model.</p> StereoCameraInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera information.</p> StereoCameraStatus <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera status model.</p> StereoCameraStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera status.</p> StereoCaptureBatchResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch stereo capture.</p> StereoCaptureBatchResult <p>               Bases: <code>BaseModel</code></p> <p>Batch stereo capture result model.</p> StereoCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo capture.</p> StereoCaptureResult <p>               Bases: <code>BaseModel</code></p> <p>Stereo capture result model.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p> requests <p>Request models for StereoCameraService.</p> <p>Contains all Pydantic models for API requests, ensuring proper input validation and documentation for all stereo camera operations.</p> BackendFilterRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for backend filtering.</p> StereoCameraOpenRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for opening a stereo camera.</p> StereoCameraOpenBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera opening.</p> StereoCameraCloseRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for closing a stereo camera.</p> StereoCameraCloseBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera closing.</p> StereoCameraQueryRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo camera queries.</p> StereoCameraConfigureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo camera configuration.</p> StereoCameraConfigureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo camera configuration.</p> StereoCaptureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for stereo capture.</p> StereoCaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch stereo capture.</p> PointCloudCaptureRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for point cloud capture.</p> PointCloudCaptureBatchRequest <p>               Bases: <code>BaseModel</code></p> <p>Request model for batch point cloud capture.</p> responses <p>Response models for StereoCameraService.</p> <p>Contains all Pydantic models for API responses, ensuring consistent response formatting across all stereo camera management endpoints.</p> BaseResponse <p>               Bases: <code>BaseModel</code></p> <p>Base response model for all API endpoints.</p> BoolResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for boolean operations.</p> StringResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for string values.</p> ListResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for list data.</p> DictResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for dictionary data.</p> BackendInfo <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera backend information model.</p> BackendsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for backend listing.</p> BackendInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for detailed backend information.</p> StereoCameraStatus <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera status model.</p> StereoCameraStatusResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera status.</p> StereoCameraInfo <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera information model.</p> StereoCameraInfoResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera information.</p> StereoCameraConfiguration <p>               Bases: <code>BaseModel</code></p> <p>Stereo camera configuration model.</p> StereoCameraConfigurationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo camera configuration.</p> StereoCaptureResult <p>               Bases: <code>BaseModel</code></p> <p>Stereo capture result model.</p> StereoCaptureResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for stereo capture.</p> StereoCaptureBatchResult <p>               Bases: <code>BaseModel</code></p> <p>Batch stereo capture result model.</p> StereoCaptureBatchResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch stereo capture.</p> PointCloudResult <p>               Bases: <code>BaseModel</code></p> <p>Point cloud capture result model.</p> PointCloudResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for point cloud capture.</p> PointCloudBatchResult <p>               Bases: <code>BaseModel</code></p> <p>Batch point cloud capture result model.</p> PointCloudBatchResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch point cloud capture.</p> BatchOperationResult <p>               Bases: <code>BaseModel</code></p> <p>Individual batch operation result.</p> BatchOperationResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for batch operations.</p> ActiveStereoCamerasResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for listing active stereo cameras.</p> SystemDiagnostics <p>               Bases: <code>BaseModel</code></p> <p>System diagnostics model.</p> SystemDiagnosticsResponse <p>               Bases: <code>BaseResponse</code></p> <p>Response model for system diagnostics.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.schemas","title":"schemas","text":"<p>MCP TaskSchemas for StereoCameraService.</p> capture_schemas <p>Stereo Camera Capture TaskSchemas.</p> config_schemas <p>Stereo Camera Configuration TaskSchemas.</p> info_schemas <p>Stereo Camera Information TaskSchemas.</p> lifecycle_schemas <p>Stereo Camera Lifecycle TaskSchemas.</p>"},{"location":"hardware/api/#mindtrace.hardware.api.stereo_cameras.service","title":"service","text":"<p>StereoCameraService - Service-based API for stereo camera management.</p> <p>This service provides comprehensive REST API and MCP tools for managing Basler Stereo ace cameras with multi-component capture (intensity, disparity, depth).</p> StereoCameraService <pre><code>StereoCameraService(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Stereo Camera Management Service.</p> <p>Provides comprehensive REST API and MCP tools for managing stereo cameras with multi-component capture capabilities (intensity, disparity, point clouds).</p> <p>Supported Operations: - Backend discovery and information - Camera lifecycle management (open, close, status) - Multi-component capture (intensity + disparity) - Point cloud generation with optional color - Camera configuration (depth range, illumination, binning, quality, exposure, gain) - Batch operations for multiple cameras - System diagnostics and monitoring</p> <p>Initialize StereoCameraService.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to Service base class</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.cameras","title":"cameras","text":"<p>Camera module for mindtrace hardware.</p> <p>Provides unified camera management across different camera manufacturers with graceful SDK handling and comprehensive error management.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend","title":"CameraBackend","text":"<pre><code>CameraBackend(\n    camera_name: Optional[str] = None,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n)\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for all camera implementations.</p> <p>This class defines the async interface that all camera backends must implement to ensure consistent behavior across different camera types and manufacturers. Uses async-first design consistent with PLC backends.</p> <p>Attributes:</p> Name Type Description <code>camera_name</code> <p>Unique identifier for the camera</p> <code>camera_config_file</code> <p>Path to camera configuration file</p> <code>img_quality_enhancement</code> <p>Whether image quality enhancement is enabled</p> <code>retrieve_retry_count</code> <p>Number of retries for image retrieval</p> <code>camera</code> <code>Optional[Any]</code> <p>The initialized camera object (implementation-specific)</p> <code>device_manager</code> <code>Optional[Any]</code> <p>Device manager object (implementation-specific)</p> <code>initialized</code> <code>bool</code> <p>Camera initialization status</p> Implementation Guide <ul> <li>Offload blocking SDK calls from async methods:   Use <code>asyncio.to_thread</code> for simple cases or <code>loop.run_in_executor</code> with a per-instance single-thread   executor when the SDK requires thread affinity.</li> <li>Thread affinity:   Many vendor SDKs are safest when all calls originate from one OS thread. Prefer a dedicated single-thread   executor created during <code>initialize()</code> and shut down in <code>close()</code> to serialize SDK access without   blocking the event loop.</li> <li>Timeouts and cancellation:   Prefer SDK-native timeouts where available. Otherwise, wrap awaited futures with <code>asyncio.wait_for</code> to   bound runtime. Note that cancelling an await does not stop the underlying thread function; design   idempotent/short tasks when possible.</li> <li>Event loop hygiene:   Never call blocking functions (e.g., long SDK calls, <code>time.sleep</code>) directly in async methods. Replace   sleeps with <code>await asyncio.sleep</code> or run blocking work in the executor.</li> <li>Sync helpers:   Lightweight getters/setters that do not touch hardware may remain synchronous. If a \"getter\" calls into the   SDK, route it through the executor to avoid blocking.</li> <li>Errors:   Map SDK-specific exceptions to the domain exceptions in <code>mindtrace.hardware.core.exceptions</code> with clear,   contextual messages.</li> <li>Cleanup:   Ensure resources (device handles, executors, buffers) are released in <code>close()</code>. <code>__aenter__/__aexit__</code>   already call <code>setup_camera</code>/<code>close</code> for async contexts.</li> </ul> <p>Initialize base camera with configuration integration.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>Optional[str]</code> <p>Unique identifier for the camera (auto-generated if None)</p> <code>None</code> <code>camera_config</code> <code>Optional[str]</code> <p>Path to camera configuration file</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Whether to apply image quality enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of retries for image retrieval (uses config default if None)</p> <code>None</code>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.setup_camera","title":"setup_camera  <code>async</code>","text":"<pre><code>setup_camera()\n</code></pre> <p>Common setup method for camera initialization.</p> <p>This method provides a standardized setup pattern that can be used by all camera backends. It calls the abstract initialize() method and handles common initialization patterns.</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera cannot be found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.set_bandwidth_limit","title":"set_bandwidth_limit  <code>async</code>","text":"<pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.get_bandwidth_limit","title":"get_bandwidth_limit  <code>async</code>","text":"<pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.set_packet_size","title":"set_packet_size  <code>async</code>","text":"<pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.get_packet_size","title":"get_packet_size  <code>async</code>","text":"<pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.set_inter_packet_delay","title":"set_inter_packet_delay  <code>async</code>","text":"<pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.get_inter_packet_delay","title":"get_inter_packet_delay  <code>async</code>","text":"<pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.set_capture_timeout","title":"set_capture_timeout  <code>async</code>","text":"<pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required Note <p>This is a runtime-configurable parameter that can be changed without reinitializing the camera.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.CameraBackend.get_capture_timeout","title":"get_capture_timeout  <code>async</code>","text":"<pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends","title":"backends","text":"<p>Camera backends for different manufacturers and types.</p> <p>This module provides camera backend implementations for the Mindtrace hardware system. Each backend implements the CameraBackend interface for consistent camera operations.</p> Available Backends <ul> <li>CameraBackend: Abstract base class defining the camera interface</li> <li>BaslerCameraBackend: Industrial cameras from Basler (when available)</li> <li>OpenCVCameraBackend: USB cameras and webcams via OpenCV (when available)</li> <li>GenICamCameraBackend: GenICam-compliant cameras via Harvesters (when available)</li> </ul> <p>Usage: from mindtrace.hardware.cameras.backends import CameraBackend from mindtrace.hardware.cameras.backends.basler import BaslerCameraBackend from mindtrace.hardware.cameras.backends.opencv import OpenCVCameraBackend from mindtrace.hardware.cameras.backends.genicam import GenICamCameraBackend</p> Configuration <p>Camera backends integrate with the Mindtrace configuration system to provide consistent default values and settings across all camera types.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.CameraBackend","title":"CameraBackend","text":"<pre><code>CameraBackend(\n    camera_name: Optional[str] = None,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n)\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for all camera implementations.</p> <p>This class defines the async interface that all camera backends must implement to ensure consistent behavior across different camera types and manufacturers. Uses async-first design consistent with PLC backends.</p> <p>Attributes:</p> Name Type Description <code>camera_name</code> <p>Unique identifier for the camera</p> <code>camera_config_file</code> <p>Path to camera configuration file</p> <code>img_quality_enhancement</code> <p>Whether image quality enhancement is enabled</p> <code>retrieve_retry_count</code> <p>Number of retries for image retrieval</p> <code>camera</code> <code>Optional[Any]</code> <p>The initialized camera object (implementation-specific)</p> <code>device_manager</code> <code>Optional[Any]</code> <p>Device manager object (implementation-specific)</p> <code>initialized</code> <code>bool</code> <p>Camera initialization status</p> Implementation Guide <ul> <li>Offload blocking SDK calls from async methods:   Use <code>asyncio.to_thread</code> for simple cases or <code>loop.run_in_executor</code> with a per-instance single-thread   executor when the SDK requires thread affinity.</li> <li>Thread affinity:   Many vendor SDKs are safest when all calls originate from one OS thread. Prefer a dedicated single-thread   executor created during <code>initialize()</code> and shut down in <code>close()</code> to serialize SDK access without   blocking the event loop.</li> <li>Timeouts and cancellation:   Prefer SDK-native timeouts where available. Otherwise, wrap awaited futures with <code>asyncio.wait_for</code> to   bound runtime. Note that cancelling an await does not stop the underlying thread function; design   idempotent/short tasks when possible.</li> <li>Event loop hygiene:   Never call blocking functions (e.g., long SDK calls, <code>time.sleep</code>) directly in async methods. Replace   sleeps with <code>await asyncio.sleep</code> or run blocking work in the executor.</li> <li>Sync helpers:   Lightweight getters/setters that do not touch hardware may remain synchronous. If a \"getter\" calls into the   SDK, route it through the executor to avoid blocking.</li> <li>Errors:   Map SDK-specific exceptions to the domain exceptions in <code>mindtrace.hardware.core.exceptions</code> with clear,   contextual messages.</li> <li>Cleanup:   Ensure resources (device handles, executors, buffers) are released in <code>close()</code>. <code>__aenter__/__aexit__</code>   already call <code>setup_camera</code>/<code>close</code> for async contexts.</li> </ul> <p>Initialize base camera with configuration integration.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>Optional[str]</code> <p>Unique identifier for the camera (auto-generated if None)</p> <code>None</code> <code>camera_config</code> <code>Optional[str]</code> <p>Path to camera configuration file</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Whether to apply image quality enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of retries for image retrieval (uses config default if None)</p> <code>None</code> setup_camera <code>async</code> <pre><code>setup_camera()\n</code></pre> <p>Common setup method for camera initialization.</p> <p>This method provides a standardized setup pattern that can be used by all camera backends. It calls the abstract initialize() method and handles common initialization patterns.</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera cannot be found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps.</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit.</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size.</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required Note <p>This is a runtime-configurable parameter that can be changed without reinitializing the camera.</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.basler","title":"basler","text":"<p>Basler Camera Backend</p> <p>Provides support for Basler cameras via pypylon SDK with mock implementation for testing.</p> Components <ul> <li>BaslerCameraBackend: Real Basler camera implementation (requires pypylon SDK)</li> <li>MockBaslerCameraBackend: Mock implementation for testing and development</li> </ul> Requirements <ul> <li>Real cameras: pypylon SDK (Pylon SDK for Python)</li> <li>Mock cameras: No additional dependencies</li> </ul> Installation <ol> <li>Install Pylon SDK from Basler</li> <li>pip install pypylon</li> <li>Configure camera permissions (Linux may require udev rules)</li> </ol> Usage <p>from mindtrace.hardware.cameras.backends.basler import BaslerCameraBackend, MockBaslerCameraBackend</p> BaslerCameraBackend <pre><code>BaslerCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    multicast_enabled: Optional[bool] = None,\n    target_ips: Optional[List[str]] = None,\n    multicast_group: Optional[str] = None,\n    multicast_port: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Basler Camera Backend Implementation</p> <p>This class provides a comprehensive implementation for Basler cameras using the pypylon SDK. It supports advanced camera features including trigger modes, exposure control, ROI settings, and image quality enhancement.</p> Features <ul> <li>Full Basler camera support via pypylon SDK</li> <li>Hardware trigger and continuous capture modes</li> <li>ROI (Region of Interest) control</li> <li>Automatic exposure and gain control</li> <li>Image quality enhancement with CLAHE</li> <li>Configuration import/export functionality</li> <li>Robust error handling and connection management</li> </ul> Requirements <ul> <li>pypylon SDK (Pylon SDK for Python)</li> <li>OpenCV for image processing</li> <li>Basler Pylon SDK installed on system</li> </ul> Installation <ol> <li>Install Basler Pylon SDK from manufacturer</li> <li>pip install pypylon</li> <li>Configure camera permissions (Linux may require udev rules)</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.basler import BaslerCameraBackend\n\n# Get available cameras\ncameras = BaslerCameraBackend.get_available_cameras()\n\n# Initialize camera\ncamera = BaslerCameraBackend(\"camera_name\", img_quality_enhancement=True)\nsuccess, cam_obj, remote_obj = await camera.initialize()  # Initialize first\n\nif success:\n    # Configure and capture\n    await camera.set_exposure(20000)\n    await camera.set_triggermode(\"continuous\")\n    image = await camera.capture()\n    await camera.close()\n</code></pre> Configuration <p>All parameters are configurable via the hardware configuration system: - MINDTRACE_CAMERA_EXPOSURE_TIME: Default exposure time in microseconds - MINDTRACE_CAMERA_TRIGGER_MODE: Default trigger mode (\"continuous\" or \"trigger\") - MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT: Enable CLAHE enhancement - MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT: Number of capture retry attempts - MINDTRACE_CAMERA_BUFFER_COUNT: Number of frame buffers for streaming - MINDTRACE_CAMERA_TIMEOUT_MS: Capture timeout in milliseconds</p> Supported Camera Models <ul> <li>All Basler USB3 cameras (acA, daA series)</li> <li>All Basler GigE cameras (acA, daA series)</li> <li>Both monochrome and color variants</li> <li>Various resolutions and frame rates</li> </ul> Error Handling <p>The class uses a comprehensive exception hierarchy for precise error reporting: - SDKNotAvailableError: pypylon SDK not installed - CameraNotFoundError: Camera not detected or accessible - CameraInitializationError: Failed to initialize camera - CameraConfigurationError: Invalid configuration parameters - CameraConnectionError: Connection issues - CameraCaptureError: Image acquisition failures - CameraTimeoutError: Operation timeout - HardwareOperationError: General hardware operation failures</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>camera</code> <code>Optional[Any]</code> <p>Underlying pypylon camera object</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>buffer_count</code> <p>Number of frame buffers</p> <code>converter</code> <p>Image format converter for pypylon</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>default_pixel_format</code> <p>Default pixel format for image conversion</p> <code>camera_config_path</code> <p>Path to camera configuration file</p> <code>grabbing_mode</code> <p>Pylon grabbing strategy</p> <p>Initialize Basler camera with configurable parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (serial number, IP, or user-defined name)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to Pylon Feature Stream (.pfs) file (optional)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable CLAHE image enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>multicast_enabled</code> <code>Optional[bool]</code> <p>Enable multicast streaming mode (uses config default if None)</p> <code>None</code> <code>target_ips</code> <code>Optional[List[str]]</code> <p>List of target IP addresses for multicast discovery (optional)</p> <code>None</code> <code>multicast_group</code> <code>Optional[str]</code> <p>Multicast group IP address (uses config default if None)</p> <code>None</code> <code>multicast_port</code> <code>Optional[int]</code> <p>Multicast port number (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - pixel_format: Default pixel format (uses config default if None) - buffer_count: Number of frame buffers (uses config default if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon SDK is not available</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False, target_ips: Optional[List[str]] = None\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available Basler cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <code>target_ips</code> <code>Optional[List[str]]</code> <p>Optional list of IP addresses to specifically discover</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names (user-defined names preferred, serial numbers as fallback) or dict with details</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Basler SDK is not available</p> <code>HardwareOperationError</code> <p>If camera discovery fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera connection.</p> <p>This searches for the camera by name, serial number, or IP and establishes a connection if found. Uses multicast-aware discovery if enabled.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, camera object, None)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> configure_streaming <code>async</code> <pre><code>configure_streaming()\n</code></pre> <p>Configure multicast streaming settings for the camera.</p> <p>This method sets up multicast parameters when multicast mode is enabled. It configures the camera using the StreamGrabber interface for multicast streaming.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If multicast configuration fails</p> <code>HardwareOperationError</code> <p>If streaming configuration fails</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement setting.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(value: bool)\n</code></pre> <p>Set image quality enhancement setting.</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure range retrieval fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure_value</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If trigger mode retrieval fails</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the camera's trigger mode for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> <code>HardwareOperationError</code> <p>If trigger mode setting fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the camera.</p> <p>In continuous mode, returns the latest available frame. In trigger mode, executes a software trigger and waits for the image.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image array in BGR format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration import fails</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path where to save configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration export fails</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set the Region of Interest (ROI) for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>X offset from sensor top-left</p> required <code>y</code> <code>int</code> <p>Y offset from sensor top-left</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> <code>HardwareOperationError</code> <p>If ROI setting fails</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest settings.</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with x, y, width, height</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI retrieval fails</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to maximum sensor area.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI reset fails</p> set_gain <code>async</code> <pre><code>set_gain(gain: float)\n</code></pre> <p>Set the camera's gain value.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (camera-specific range)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If gain value is out of range</p> <code>HardwareOperationError</code> <p>If gain setting fails</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If gain retrieval fails</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get camera gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List containing [min_gain, max_gain]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If gain range retrieval fails</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps.</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit in Mbps.</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size.</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes (lowercase for API compatibility)</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If width range retrieval fails</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If height range retrieval fails</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If pixel format range retrieval fails</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If pixel format retrieval fails</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If pixel format is invalid</p> <code>HardwareOperationError</code> <p>If pixel format setting fails</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get the current white balance auto setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>White balance auto setting (\"off\", \"once\", \"continuous\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If white balance retrieval fails</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set the white balance auto mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"off\", \"once\", \"continuous\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If white balance mode is invalid</p> <code>HardwareOperationError</code> <p>If white balance setting fails</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for Basler cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available trigger modes based on GenICam TriggerMode and TriggerSource</p> get_bandwidth_limit_range <code>async</code> <pre><code>get_bandwidth_limit_range() -&gt; List[float]\n</code></pre> <p>Get bandwidth limit range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [min_bandwidth, max_bandwidth] in Mbps</p> get_packet_size_range <code>async</code> <pre><code>get_packet_size_range() -&gt; List[int]\n</code></pre> <p>Get packet size range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_packet_size, max_packet_size] in bytes</p> get_inter_packet_delay_range <code>async</code> <pre><code>get_inter_packet_delay_range() -&gt; List[int]\n</code></pre> <p>Get inter-packet delay range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_delay, max_delay] in ticks</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the camera and release resources.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> MockBaslerCameraBackend <pre><code>MockBaslerCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Mock Basler Camera Backend Implementation</p> <p>This class provides a mock implementation of the Basler camera backend for testing and development. It simulates Basler camera functionality without requiring actual hardware, with configurable behavior and error simulation.</p> Features <ul> <li>Complete simulation of Basler camera API</li> <li>Configurable image generation with realistic patterns</li> <li>Error simulation for testing error handling</li> <li>Configuration import/export simulation</li> <li>Camera control features (exposure, ROI, trigger modes, etc.)</li> <li>Realistic timing and behavior simulation</li> </ul> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.basler import MockBaslerCameraBackend\n\ncamera = MockBaslerCameraBackend(\"mock_camera_1\")\nawait camera.set_exposure(20000)\nimage = await camera.capture()\nawait camera.close()\n</code></pre> Error Simulation <p>Enable error simulation via environment variables: - MOCK_BASLER_FAIL_INIT: Simulate initialization failure - MOCK_BASLER_FAIL_CAPTURE: Simulate capture failure - MOCK_BASLER_TIMEOUT: Simulate timeout errors</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <p>Whether camera was successfully initialized</p> <code>camera_name</code> <p>Name/identifier of the mock camera</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>exposure_time</code> <p>Current exposure time in microseconds</p> <code>gain</code> <p>Current gain value</p> <code>roi</code> <p>Current region of interest settings</p> <code>white_balance_mode</code> <p>Current white balance mode</p> <code>image_counter</code> <p>Counter for generating unique images</p> <code>fail_init</code> <p>Whether to simulate initialization failure</p> <code>fail_capture</code> <p>Whether to simulate capture failure</p> <code>simulate_timeout</code> <p>Whether to simulate timeout errors</p> <p>Initialize mock Basler camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable image enhancement simulation (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - pixel_format: Pixel format (simulated) - buffer_count: Buffer count (simulated) - timeout_ms: Timeout in milliseconds - fast_mode: If True, skip all sleep delays for fast unit tests (default: False) - simulate_fail_init: If True, simulate initialization failure (overrides env) - simulate_fail_capture: If True, simulate capture failure (overrides env) - simulate_timeout: If True, simulate timeout on capture (overrides env) - simulate_cancel: If True, simulate asyncio cancellation during capture - synthetic_width: Override synthetic image width (int) - synthetic_height: Override synthetic image height (int) - synthetic_pattern: One of {\"auto\",\"gradient\",\"checkerboard\",\"circular\",\"noise\"} - synthetic_checker_size: Checker size (int) used when pattern is checkerboard - synthetic_overlay_text: If False, disables text overlays in synthetic images</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available mock Basler cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of mock camera names or dict with details</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock camera connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, mock camera object, None)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the mock camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Captured BGR image array</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> IsGrabbing <pre><code>IsGrabbing() -&gt; bool\n</code></pre> <p>Return whether the mock camera is currently in a grabbing state.</p> StartGrabbing <pre><code>StartGrabbing(grabbing_mode: Optional[str] = None) -&gt; None\n</code></pre> <p>Enter grabbing state, optionally updating grabbing mode.</p> <p>Parameters:</p> Name Type Description Default <code>grabbing_mode</code> <code>Optional[str]</code> <p>Optional grabbing mode string; if provided, updates current mode.</p> <code>None</code> StopGrabbing <pre><code>StopGrabbing() -&gt; None\n</code></pre> <p>Exit grabbing state.</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement setting.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if enhancement is enabled, otherwise False.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(value: bool)\n</code></pre> <p>Set image quality enhancement setting.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>True to enable enhancement, False to disable.</p> required get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current trigger mode</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set trigger mode.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if mock camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration file is not found or invalid</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest (ROI).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>ROI x offset</p> required <code>y</code> <code>int</code> <p>ROI y offset</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest (ROI).</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with ROI parameters</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to full sensor size.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>Union[int, float]</code> <p>Gain value</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If gain value is out of range</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_gain, max_gain]</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set white balance mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode</p> required get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes (lowercase for API compatibility)</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps (simulated).</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit (simulated).</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization (simulated).</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size (simulated).</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control (simulated).</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay (simulated).</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for mock Basler cameras.</p> get_bandwidth_limit_range <code>async</code> <pre><code>get_bandwidth_limit_range() -&gt; List[float]\n</code></pre> <p>Get bandwidth limit range for mock GigE cameras.</p> get_packet_size_range <code>async</code> <pre><code>get_packet_size_range() -&gt; List[int]\n</code></pre> <p>Get packet size range for mock GigE cameras.</p> get_inter_packet_delay_range <code>async</code> <pre><code>get_inter_packet_delay_range() -&gt; List[int]\n</code></pre> <p>Get inter-packet delay range for mock GigE cameras.</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the mock camera and release resources.</p> basler_camera_backend <p>Basler Camera Backend Module</p> BaslerCameraBackend <pre><code>BaslerCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    multicast_enabled: Optional[bool] = None,\n    target_ips: Optional[List[str]] = None,\n    multicast_group: Optional[str] = None,\n    multicast_port: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Basler Camera Backend Implementation</p> <p>This class provides a comprehensive implementation for Basler cameras using the pypylon SDK. It supports advanced camera features including trigger modes, exposure control, ROI settings, and image quality enhancement.</p> Features <ul> <li>Full Basler camera support via pypylon SDK</li> <li>Hardware trigger and continuous capture modes</li> <li>ROI (Region of Interest) control</li> <li>Automatic exposure and gain control</li> <li>Image quality enhancement with CLAHE</li> <li>Configuration import/export functionality</li> <li>Robust error handling and connection management</li> </ul> Requirements <ul> <li>pypylon SDK (Pylon SDK for Python)</li> <li>OpenCV for image processing</li> <li>Basler Pylon SDK installed on system</li> </ul> Installation <ol> <li>Install Basler Pylon SDK from manufacturer</li> <li>pip install pypylon</li> <li>Configure camera permissions (Linux may require udev rules)</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.basler import BaslerCameraBackend\n\n# Get available cameras\ncameras = BaslerCameraBackend.get_available_cameras()\n\n# Initialize camera\ncamera = BaslerCameraBackend(\"camera_name\", img_quality_enhancement=True)\nsuccess, cam_obj, remote_obj = await camera.initialize()  # Initialize first\n\nif success:\n    # Configure and capture\n    await camera.set_exposure(20000)\n    await camera.set_triggermode(\"continuous\")\n    image = await camera.capture()\n    await camera.close()\n</code></pre> Configuration <p>All parameters are configurable via the hardware configuration system: - MINDTRACE_CAMERA_EXPOSURE_TIME: Default exposure time in microseconds - MINDTRACE_CAMERA_TRIGGER_MODE: Default trigger mode (\"continuous\" or \"trigger\") - MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT: Enable CLAHE enhancement - MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT: Number of capture retry attempts - MINDTRACE_CAMERA_BUFFER_COUNT: Number of frame buffers for streaming - MINDTRACE_CAMERA_TIMEOUT_MS: Capture timeout in milliseconds</p> Supported Camera Models <ul> <li>All Basler USB3 cameras (acA, daA series)</li> <li>All Basler GigE cameras (acA, daA series)</li> <li>Both monochrome and color variants</li> <li>Various resolutions and frame rates</li> </ul> Error Handling <p>The class uses a comprehensive exception hierarchy for precise error reporting: - SDKNotAvailableError: pypylon SDK not installed - CameraNotFoundError: Camera not detected or accessible - CameraInitializationError: Failed to initialize camera - CameraConfigurationError: Invalid configuration parameters - CameraConnectionError: Connection issues - CameraCaptureError: Image acquisition failures - CameraTimeoutError: Operation timeout - HardwareOperationError: General hardware operation failures</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>camera</code> <code>Optional[Any]</code> <p>Underlying pypylon camera object</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>buffer_count</code> <p>Number of frame buffers</p> <code>converter</code> <p>Image format converter for pypylon</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>default_pixel_format</code> <p>Default pixel format for image conversion</p> <code>camera_config_path</code> <p>Path to camera configuration file</p> <code>grabbing_mode</code> <p>Pylon grabbing strategy</p> <p>Initialize Basler camera with configurable parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (serial number, IP, or user-defined name)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to Pylon Feature Stream (.pfs) file (optional)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable CLAHE image enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>multicast_enabled</code> <code>Optional[bool]</code> <p>Enable multicast streaming mode (uses config default if None)</p> <code>None</code> <code>target_ips</code> <code>Optional[List[str]]</code> <p>List of target IP addresses for multicast discovery (optional)</p> <code>None</code> <code>multicast_group</code> <code>Optional[str]</code> <p>Multicast group IP address (uses config default if None)</p> <code>None</code> <code>multicast_port</code> <code>Optional[int]</code> <p>Multicast port number (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - pixel_format: Default pixel format (uses config default if None) - buffer_count: Number of frame buffers (uses config default if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon SDK is not available</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False, target_ips: Optional[List[str]] = None\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available Basler cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <code>target_ips</code> <code>Optional[List[str]]</code> <p>Optional list of IP addresses to specifically discover</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names (user-defined names preferred, serial numbers as fallback) or dict with details</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Basler SDK is not available</p> <code>HardwareOperationError</code> <p>If camera discovery fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera connection.</p> <p>This searches for the camera by name, serial number, or IP and establishes a connection if found. Uses multicast-aware discovery if enabled.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, camera object, None)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> configure_streaming <code>async</code> <pre><code>configure_streaming()\n</code></pre> <p>Configure multicast streaming settings for the camera.</p> <p>This method sets up multicast parameters when multicast mode is enabled. It configures the camera using the StreamGrabber interface for multicast streaming.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If multicast configuration fails</p> <code>HardwareOperationError</code> <p>If streaming configuration fails</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement setting.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(value: bool)\n</code></pre> <p>Set image quality enhancement setting.</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure range retrieval fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure_value</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If trigger mode retrieval fails</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the camera's trigger mode for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> <code>HardwareOperationError</code> <p>If trigger mode setting fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the camera.</p> <p>In continuous mode, returns the latest available frame. In trigger mode, executes a software trigger and waits for the image.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image array in BGR format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration import fails</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path where to save configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration export fails</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set the Region of Interest (ROI) for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>X offset from sensor top-left</p> required <code>y</code> <code>int</code> <p>Y offset from sensor top-left</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> <code>HardwareOperationError</code> <p>If ROI setting fails</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest settings.</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with x, y, width, height</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI retrieval fails</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to maximum sensor area.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI reset fails</p> set_gain <code>async</code> <pre><code>set_gain(gain: float)\n</code></pre> <p>Set the camera's gain value.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (camera-specific range)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If gain value is out of range</p> <code>HardwareOperationError</code> <p>If gain setting fails</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If gain retrieval fails</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get camera gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List containing [min_gain, max_gain]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If gain range retrieval fails</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps.</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit in Mbps.</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size.</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes (lowercase for API compatibility)</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If width range retrieval fails</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If height range retrieval fails</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If pixel format range retrieval fails</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If pixel format retrieval fails</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If pixel format is invalid</p> <code>HardwareOperationError</code> <p>If pixel format setting fails</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get the current white balance auto setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>White balance auto setting (\"off\", \"once\", \"continuous\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If white balance retrieval fails</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set the white balance auto mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"off\", \"once\", \"continuous\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If white balance mode is invalid</p> <code>HardwareOperationError</code> <p>If white balance setting fails</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for Basler cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available trigger modes based on GenICam TriggerMode and TriggerSource</p> get_bandwidth_limit_range <code>async</code> <pre><code>get_bandwidth_limit_range() -&gt; List[float]\n</code></pre> <p>Get bandwidth limit range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing [min_bandwidth, max_bandwidth] in Mbps</p> get_packet_size_range <code>async</code> <pre><code>get_packet_size_range() -&gt; List[int]\n</code></pre> <p>Get packet size range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_packet_size, max_packet_size] in bytes</p> get_inter_packet_delay_range <code>async</code> <pre><code>get_inter_packet_delay_range() -&gt; List[int]\n</code></pre> <p>Get inter-packet delay range for GigE cameras.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_delay, max_delay] in ticks</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the camera and release resources.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> mock_basler_camera_backend <p>Mock Basler Camera Backend Module</p> MockBaslerCameraBackend <pre><code>MockBaslerCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Mock Basler Camera Backend Implementation</p> <p>This class provides a mock implementation of the Basler camera backend for testing and development. It simulates Basler camera functionality without requiring actual hardware, with configurable behavior and error simulation.</p> Features <ul> <li>Complete simulation of Basler camera API</li> <li>Configurable image generation with realistic patterns</li> <li>Error simulation for testing error handling</li> <li>Configuration import/export simulation</li> <li>Camera control features (exposure, ROI, trigger modes, etc.)</li> <li>Realistic timing and behavior simulation</li> </ul> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.basler import MockBaslerCameraBackend\n\ncamera = MockBaslerCameraBackend(\"mock_camera_1\")\nawait camera.set_exposure(20000)\nimage = await camera.capture()\nawait camera.close()\n</code></pre> Error Simulation <p>Enable error simulation via environment variables: - MOCK_BASLER_FAIL_INIT: Simulate initialization failure - MOCK_BASLER_FAIL_CAPTURE: Simulate capture failure - MOCK_BASLER_TIMEOUT: Simulate timeout errors</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <p>Whether camera was successfully initialized</p> <code>camera_name</code> <p>Name/identifier of the mock camera</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>exposure_time</code> <p>Current exposure time in microseconds</p> <code>gain</code> <p>Current gain value</p> <code>roi</code> <p>Current region of interest settings</p> <code>white_balance_mode</code> <p>Current white balance mode</p> <code>image_counter</code> <p>Counter for generating unique images</p> <code>fail_init</code> <p>Whether to simulate initialization failure</p> <code>fail_capture</code> <p>Whether to simulate capture failure</p> <code>simulate_timeout</code> <p>Whether to simulate timeout errors</p> <p>Initialize mock Basler camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable image enhancement simulation (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - pixel_format: Pixel format (simulated) - buffer_count: Buffer count (simulated) - timeout_ms: Timeout in milliseconds - fast_mode: If True, skip all sleep delays for fast unit tests (default: False) - simulate_fail_init: If True, simulate initialization failure (overrides env) - simulate_fail_capture: If True, simulate capture failure (overrides env) - simulate_timeout: If True, simulate timeout on capture (overrides env) - simulate_cancel: If True, simulate asyncio cancellation during capture - synthetic_width: Override synthetic image width (int) - synthetic_height: Override synthetic image height (int) - synthetic_pattern: One of {\"auto\",\"gradient\",\"checkerboard\",\"circular\",\"noise\"} - synthetic_checker_size: Checker size (int) used when pattern is checkerboard - synthetic_overlay_text: If False, disables text overlays in synthetic images</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available mock Basler cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of mock camera names or dict with details</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock camera connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, mock camera object, None)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the mock camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Captured BGR image array</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> IsGrabbing <pre><code>IsGrabbing() -&gt; bool\n</code></pre> <p>Return whether the mock camera is currently in a grabbing state.</p> StartGrabbing <pre><code>StartGrabbing(grabbing_mode: Optional[str] = None) -&gt; None\n</code></pre> <p>Enter grabbing state, optionally updating grabbing mode.</p> <p>Parameters:</p> Name Type Description Default <code>grabbing_mode</code> <code>Optional[str]</code> <p>Optional grabbing mode string; if provided, updates current mode.</p> <code>None</code> StopGrabbing <pre><code>StopGrabbing() -&gt; None\n</code></pre> <p>Exit grabbing state.</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement setting.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if enhancement is enabled, otherwise False.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(value: bool)\n</code></pre> <p>Set image quality enhancement setting.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>True to enable enhancement, False to disable.</p> required get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current trigger mode</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set trigger mode.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if mock camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration file is not found or invalid</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest (ROI).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>ROI x offset</p> required <code>y</code> <code>int</code> <p>ROI y offset</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest (ROI).</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with ROI parameters</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to full sensor size.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>Union[int, float]</code> <p>Gain value</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If gain value is out of range</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_gain, max_gain]</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set white balance mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode</p> required get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes (lowercase for API compatibility)</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps (simulated).</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit (simulated).</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization (simulated).</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size (simulated).</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control (simulated).</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay (simulated).</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for mock Basler cameras.</p> get_bandwidth_limit_range <code>async</code> <pre><code>get_bandwidth_limit_range() -&gt; List[float]\n</code></pre> <p>Get bandwidth limit range for mock GigE cameras.</p> get_packet_size_range <code>async</code> <pre><code>get_packet_size_range() -&gt; List[int]\n</code></pre> <p>Get packet size range for mock GigE cameras.</p> get_inter_packet_delay_range <code>async</code> <pre><code>get_inter_packet_delay_range() -&gt; List[int]\n</code></pre> <p>Get inter-packet delay range for mock GigE cameras.</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the mock camera and release resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.basler--real-camera","title":"Real camera","text":"<p>if BASLER_AVAILABLE:     camera = BaslerCameraBackend(\"camera_name\")     success, cam_obj, remote_obj = await camera.initialize()  # Initialize first     if success:         image = await camera.capture()         await camera.close()</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.basler--mock-camera-always-available","title":"Mock camera (always available)","text":"<p>mock_camera = MockBaslerCameraBackend(\"mock_cam_0\") success, cam_obj, remote_obj = await mock_camera.initialize()  # Initialize first if success:     image = await mock_camera.capture()     await mock_camera.close()</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.camera_backend","title":"camera_backend","text":"CameraBackend <pre><code>CameraBackend(\n    camera_name: Optional[str] = None,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n)\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for all camera implementations.</p> <p>This class defines the async interface that all camera backends must implement to ensure consistent behavior across different camera types and manufacturers. Uses async-first design consistent with PLC backends.</p> <p>Attributes:</p> Name Type Description <code>camera_name</code> <p>Unique identifier for the camera</p> <code>camera_config_file</code> <p>Path to camera configuration file</p> <code>img_quality_enhancement</code> <p>Whether image quality enhancement is enabled</p> <code>retrieve_retry_count</code> <p>Number of retries for image retrieval</p> <code>camera</code> <code>Optional[Any]</code> <p>The initialized camera object (implementation-specific)</p> <code>device_manager</code> <code>Optional[Any]</code> <p>Device manager object (implementation-specific)</p> <code>initialized</code> <code>bool</code> <p>Camera initialization status</p> Implementation Guide <ul> <li>Offload blocking SDK calls from async methods:   Use <code>asyncio.to_thread</code> for simple cases or <code>loop.run_in_executor</code> with a per-instance single-thread   executor when the SDK requires thread affinity.</li> <li>Thread affinity:   Many vendor SDKs are safest when all calls originate from one OS thread. Prefer a dedicated single-thread   executor created during <code>initialize()</code> and shut down in <code>close()</code> to serialize SDK access without   blocking the event loop.</li> <li>Timeouts and cancellation:   Prefer SDK-native timeouts where available. Otherwise, wrap awaited futures with <code>asyncio.wait_for</code> to   bound runtime. Note that cancelling an await does not stop the underlying thread function; design   idempotent/short tasks when possible.</li> <li>Event loop hygiene:   Never call blocking functions (e.g., long SDK calls, <code>time.sleep</code>) directly in async methods. Replace   sleeps with <code>await asyncio.sleep</code> or run blocking work in the executor.</li> <li>Sync helpers:   Lightweight getters/setters that do not touch hardware may remain synchronous. If a \"getter\" calls into the   SDK, route it through the executor to avoid blocking.</li> <li>Errors:   Map SDK-specific exceptions to the domain exceptions in <code>mindtrace.hardware.core.exceptions</code> with clear,   contextual messages.</li> <li>Cleanup:   Ensure resources (device handles, executors, buffers) are released in <code>close()</code>. <code>__aenter__/__aexit__</code>   already call <code>setup_camera</code>/<code>close</code> for async contexts.</li> </ul> <p>Initialize base camera with configuration integration.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>Optional[str]</code> <p>Unique identifier for the camera (auto-generated if None)</p> <code>None</code> <code>camera_config</code> <code>Optional[str]</code> <p>Path to camera configuration file</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Whether to apply image quality enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of retries for image retrieval (uses config default if None)</p> <code>None</code> setup_camera <code>async</code> <pre><code>setup_camera()\n</code></pre> <p>Common setup method for camera initialization.</p> <p>This method provides a standardized setup pattern that can be used by all camera backends. It calls the abstract initialize() method and handles common initialization patterns.</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera cannot be found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> set_bandwidth_limit <code>async</code> <pre><code>set_bandwidth_limit(limit_mbps: Optional[float])\n</code></pre> <p>Set GigE camera bandwidth limit in Mbps.</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Get current bandwidth limit.</p> set_packet_size <code>async</code> <pre><code>set_packet_size(size: int)\n</code></pre> <p>Set GigE packet size for network optimization.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Get current packet size.</p> set_inter_packet_delay <code>async</code> <pre><code>set_inter_packet_delay(delay_ticks: int)\n</code></pre> <p>Set inter-packet delay for network traffic control.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Get current inter-packet delay.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required Note <p>This is a runtime-configurable parameter that can be changed without reinitializing the camera.</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.genicam","title":"genicam","text":"<p>GenICam Camera Backend Module</p> GenICamCameraBackend <pre><code>GenICamCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>GenICam Camera Backend Implementation</p> <p>This class provides a comprehensive implementation for GenICam-compliant cameras using the Harvesters library with Matrix Vision GenTL Producer. It supports advanced camera features including trigger modes, exposure control, ROI settings, and image quality enhancement.</p> Thread Safety <p>Uses a singleton Harvester instance shared across all backend instances to avoid GenTL device conflicts. Multiple cameras can be opened simultaneously using the same Harvester.</p> Features <ul> <li>Full GenICam camera support via Harvesters</li> <li>Matrix Vision GenTL Producer integration</li> <li>Hardware trigger and continuous capture modes</li> <li>ROI (Region of Interest) control</li> <li>Automatic exposure and gain control</li> <li>Image quality enhancement with CLAHE</li> <li>Configuration import/export functionality</li> <li>Robust error handling and connection management</li> <li>Vendor-specific parameter handling (Keyence, Basler, etc.)</li> </ul> Requirements <ul> <li>Harvesters library (pip install harvesters)</li> <li>Matrix Vision mvIMPACT Acquire SDK</li> <li>OpenCV for image processing</li> <li>GenTL Producer (.cti file) installed on system</li> </ul> Installation <ol> <li>Install Matrix Vision mvIMPACT Acquire SDK</li> <li>pip install harvesters opencv-python numpy</li> <li>Configure network interface for GigE cameras</li> <li>Set GENICAM_CTI_PATH environment variable (optional)</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.genicam import GenICamCameraBackend\n\n# Get available cameras\ncameras = GenICamCameraBackend.get_available_cameras()\n\n# Initialize camera\ncamera = GenICamCameraBackend(\"device_serial\", img_quality_enhancement=True)\nsuccess, cam_obj, remote_obj = await camera.initialize()\n\nif success:\n    # Configure and capture\n    await camera.set_exposure(50000)\n    await camera.set_triggermode(\"continuous\")\n    image = await camera.capture()\n    await camera.close()\n</code></pre> Configuration <p>All parameters are configurable via environment variables or the hardware configuration system: - GENICAM_CTI_PATH: Path to GenTL Producer (.cti file) - MINDTRACE_CAMERA_EXPOSURE_TIME: Default exposure time in microseconds - MINDTRACE_CAMERA_TRIGGER_MODE: Default trigger mode (\"continuous\" or \"trigger\") - MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT: Enable CLAHE enhancement - MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT: Number of capture retry attempts - MINDTRACE_CAMERA_TIMEOUT_MS: Capture timeout in milliseconds</p> Supported Camera Models <ul> <li>Keyence VJ series cameras</li> <li>Basler GigE cameras (alternative to pypylon)</li> <li>Allied Vision cameras</li> <li>FLIR/Teledyne cameras</li> <li>Any GenICam-compliant camera with compatible GenTL Producer</li> </ul> Error Handling <p>The class uses a comprehensive exception hierarchy for precise error reporting: - SDKNotAvailableError: Harvesters library not installed - CameraNotFoundError: Camera not detected or accessible - CameraInitializationError: Failed to initialize camera - CameraConfigurationError: Invalid configuration parameters - CameraConnectionError: Connection issues - CameraCaptureError: Image acquisition failures - CameraTimeoutError: Operation timeout - HardwareOperationError: General hardware operation failures</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>image_acquirer</code> <code>Optional[Any]</code> <p>Harvesters ImageAcquirer object</p> <code>harvester</code> <code>Optional[Harvester]</code> <p>Harvesters Harvester object</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>device_info</code> <code>Optional[Dict[str, Any]]</code> <p>Camera device information from discovery</p> <code>vendor_quirks</code> <code>Dict[str, bool]</code> <p>Vendor-specific parameter handling flags</p> <code>cti_path</code> <p>Path to GenTL Producer file</p> <p>Initialize GenICam camera with configurable parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (serial number, device ID, or user-defined name)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to JSON configuration file (optional)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable CLAHE image enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - cti_path: Path to GenTL Producer file (auto-detected if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None) - buffer_count: Number of frame buffers (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Harvesters library is not available</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available GenICam cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names (serial numbers or device IDs) or dict with details</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Harvesters library is not available</p> <code>HardwareOperationError</code> <p>If camera discovery fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera connection.</p> <p>This searches for the camera by name, serial number, or device ID and establishes a connection if found.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, image_acquirer object, device_info)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure range retrieval fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format string (e.g., \"Mono8\", \"RGB8\", \"BayerRG8\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If pixel format retrieval fails</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If width range retrieval fails</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If height range retrieval fails</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get list of supported pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported pixel format strings</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If pixel format list retrieval fails</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set the camera pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format string (e.g., \"Mono8\", \"RGB8\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> <code>HardwareOperationError</code> <p>If pixel format setting fails</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If trigger mode retrieval fails</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the camera's trigger mode for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> <code>HardwareOperationError</code> <p>If trigger mode setting fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the camera.</p> <p>In continuous mode, returns the latest available frame. In trigger mode, executes a software trigger and waits for the image.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image array in BGR format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the camera and release resources.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get camera gain range.</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode using GenICam nodes.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode string</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Execute automatic white balance once using GenICam nodes.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"auto\", \"once\", \"manual\", \"off\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If white balance setting fails</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes using GenICam nodes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance mode strings</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to JSON configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration file is invalid</p> <code>HardwareOperationError</code> <p>If configuration import fails</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export camera configuration to JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save JSON configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If configuration export fails</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest using GenICam nodes.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>Left offset</p> required <code>y</code> <code>int</code> <p>Top offset</p> required <code>width</code> <code>int</code> <p>Width of ROI</p> required <code>height</code> <code>int</code> <p>Height of ROI</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> <code>HardwareOperationError</code> <p>If ROI setting fails</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current ROI settings from GenICam nodes.</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with 'x', 'y', 'width', 'height' keys</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to maximum sensor area using GenICam nodes.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI reset fails</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> MockGenICamCameraBackend <pre><code>MockGenICamCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Mock GenICam Camera Backend Implementation</p> <p>This class provides a mock implementation of the GenICam camera backend for testing and development. It simulates GenICam camera functionality without requiring actual hardware, Harvesters library, or GenTL Producer files.</p> Features <ul> <li>Complete simulation of GenICam camera API</li> <li>Configurable image generation with realistic patterns</li> <li>Error simulation for testing error handling</li> <li>Configuration import/export simulation</li> <li>Camera control features (exposure, ROI, trigger modes, etc.)</li> <li>Vendor-specific quirks simulation (Keyence, Basler, etc.)</li> <li>Realistic timing and behavior simulation</li> </ul> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.genicam import MockGenICamCameraBackend\n\ncamera = MockGenICamCameraBackend(\"mock_keyence_001\", vendor=\"KEYENCE\")\nawait camera.set_exposure(50000)\nimage = await camera.capture()\nawait camera.close()\n</code></pre> Error Simulation <p>Enable error simulation via environment variables: - MOCK_GENICAM_FAIL_INIT: Simulate initialization failure - MOCK_GENICAM_FAIL_CAPTURE: Simulate capture failure - MOCK_GENICAM_TIMEOUT: Simulate timeout errors</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>camera_name</code> <p>Name/identifier of the mock camera</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>exposure_time</code> <p>Current exposure time in microseconds</p> <code>gain</code> <p>Current gain value</p> <code>roi</code> <p>Current region of interest settings</p> <code>vendor</code> <p>Simulated camera vendor</p> <code>model</code> <p>Simulated camera model</p> <code>serial_number</code> <p>Simulated serial number</p> <code>vendor_quirks</code> <p>Vendor-specific parameter handling flags</p> <code>image_counter</code> <p>Counter for generating unique images</p> <code>fail_init</code> <p>Whether to simulate initialization failure</p> <code>fail_capture</code> <p>Whether to simulate capture failure</p> <code>simulate_timeout</code> <p>Whether to simulate timeout errors</p> <p>Initialize mock GenICam camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable image enhancement simulation (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - vendor: Simulated vendor (\"KEYENCE\", \"BASLER\", \"FLIR\", etc.) - model: Simulated model name - serial_number: Simulated serial number - cti_path: Simulated CTI path (ignored in mock) - timeout_ms: Timeout in milliseconds - buffer_count: Buffer count (simulated) - simulate_fail_init: If True, simulate initialization failure - simulate_fail_capture: If True, simulate capture failure - simulate_timeout: If True, simulate timeout on capture - synthetic_width: Override synthetic image width (int) - synthetic_height: Override synthetic image height (int) - synthetic_pattern: One of {\"auto\",\"gradient\",\"checkerboard\",\"circular\",\"noise\"} - synthetic_overlay_text: If False, disables text overlays in synthetic images</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available mock GenICam cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names or dict with details</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock camera connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, mock camera object, device_info)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera not found (when simulated)</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> <code>CameraConnectionError</code> <p>If connection fails (when simulated)</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the simulated exposure time range in microseconds.</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current simulated exposure time in microseconds.</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the simulated camera exposure time in microseconds.</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current simulated trigger mode.</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the simulated camera's trigger mode.</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a simulated image from the mock camera.</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if mock camera is connected and operational.</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the mock camera and release simulated resources.</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get simulated camera gain range.</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current simulated camera gain.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set simulated camera gain.</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set simulated Region of Interest.</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current simulated ROI settings.</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset simulated ROI to maximum sensor area.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import simulated camera configuration from JSON file.</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current simulated camera configuration to JSON file.</p> genicam_camera_backend <p>GenICam Camera Backend Module</p> GenICamCameraBackend <pre><code>GenICamCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>GenICam Camera Backend Implementation</p> <p>This class provides a comprehensive implementation for GenICam-compliant cameras using the Harvesters library with Matrix Vision GenTL Producer. It supports advanced camera features including trigger modes, exposure control, ROI settings, and image quality enhancement.</p> Thread Safety <p>Uses a singleton Harvester instance shared across all backend instances to avoid GenTL device conflicts. Multiple cameras can be opened simultaneously using the same Harvester.</p> Features <ul> <li>Full GenICam camera support via Harvesters</li> <li>Matrix Vision GenTL Producer integration</li> <li>Hardware trigger and continuous capture modes</li> <li>ROI (Region of Interest) control</li> <li>Automatic exposure and gain control</li> <li>Image quality enhancement with CLAHE</li> <li>Configuration import/export functionality</li> <li>Robust error handling and connection management</li> <li>Vendor-specific parameter handling (Keyence, Basler, etc.)</li> </ul> Requirements <ul> <li>Harvesters library (pip install harvesters)</li> <li>Matrix Vision mvIMPACT Acquire SDK</li> <li>OpenCV for image processing</li> <li>GenTL Producer (.cti file) installed on system</li> </ul> Installation <ol> <li>Install Matrix Vision mvIMPACT Acquire SDK</li> <li>pip install harvesters opencv-python numpy</li> <li>Configure network interface for GigE cameras</li> <li>Set GENICAM_CTI_PATH environment variable (optional)</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.genicam import GenICamCameraBackend\n\n# Get available cameras\ncameras = GenICamCameraBackend.get_available_cameras()\n\n# Initialize camera\ncamera = GenICamCameraBackend(\"device_serial\", img_quality_enhancement=True)\nsuccess, cam_obj, remote_obj = await camera.initialize()\n\nif success:\n    # Configure and capture\n    await camera.set_exposure(50000)\n    await camera.set_triggermode(\"continuous\")\n    image = await camera.capture()\n    await camera.close()\n</code></pre> Configuration <p>All parameters are configurable via environment variables or the hardware configuration system: - GENICAM_CTI_PATH: Path to GenTL Producer (.cti file) - MINDTRACE_CAMERA_EXPOSURE_TIME: Default exposure time in microseconds - MINDTRACE_CAMERA_TRIGGER_MODE: Default trigger mode (\"continuous\" or \"trigger\") - MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT: Enable CLAHE enhancement - MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT: Number of capture retry attempts - MINDTRACE_CAMERA_TIMEOUT_MS: Capture timeout in milliseconds</p> Supported Camera Models <ul> <li>Keyence VJ series cameras</li> <li>Basler GigE cameras (alternative to pypylon)</li> <li>Allied Vision cameras</li> <li>FLIR/Teledyne cameras</li> <li>Any GenICam-compliant camera with compatible GenTL Producer</li> </ul> Error Handling <p>The class uses a comprehensive exception hierarchy for precise error reporting: - SDKNotAvailableError: Harvesters library not installed - CameraNotFoundError: Camera not detected or accessible - CameraInitializationError: Failed to initialize camera - CameraConfigurationError: Invalid configuration parameters - CameraConnectionError: Connection issues - CameraCaptureError: Image acquisition failures - CameraTimeoutError: Operation timeout - HardwareOperationError: General hardware operation failures</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>image_acquirer</code> <code>Optional[Any]</code> <p>Harvesters ImageAcquirer object</p> <code>harvester</code> <code>Optional[Harvester]</code> <p>Harvesters Harvester object</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>device_info</code> <code>Optional[Dict[str, Any]]</code> <p>Camera device information from discovery</p> <code>vendor_quirks</code> <code>Dict[str, bool]</code> <p>Vendor-specific parameter handling flags</p> <code>cti_path</code> <p>Path to GenTL Producer file</p> <p>Initialize GenICam camera with configurable parameters.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (serial number, device ID, or user-defined name)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to JSON configuration file (optional)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable CLAHE image enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - cti_path: Path to GenTL Producer file (auto-detected if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None) - buffer_count: Number of frame buffers (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Harvesters library is not available</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available GenICam cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names (serial numbers or device IDs) or dict with details</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If Harvesters library is not available</p> <code>HardwareOperationError</code> <p>If camera discovery fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera connection.</p> <p>This searches for the camera by name, serial number, or device ID and establishes a connection if found.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, image_acquirer object, device_info)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If no cameras found or specified camera not found</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported exposure time range in microseconds.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_exposure, max_exposure] in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure range retrieval fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the camera exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure time in microseconds</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If exposure value is out of range</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format string (e.g., \"Mono8\", \"RGB8\", \"BayerRG8\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If pixel format retrieval fails</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get camera width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If width range retrieval fails</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get camera height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If height range retrieval fails</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get list of supported pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported pixel format strings</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If pixel format list retrieval fails</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set the camera pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format string (e.g., \"Mono8\", \"RGB8\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> <code>HardwareOperationError</code> <p>If pixel format setting fails</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current trigger mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>HardwareOperationError</code> <p>If trigger mode retrieval fails</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the camera's trigger mode for image acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraConfigurationError</code> <p>If trigger mode is invalid</p> <code>HardwareOperationError</code> <p>If trigger mode setting fails</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a single image from the camera.</p> <p>In continuous mode, returns the latest available frame. In trigger mode, executes a software trigger and waits for the image.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image array in BGR format</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera is connected and operational.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected and operational, False otherwise</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the camera and release resources.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get camera gain range.</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode using GenICam nodes.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode string</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Execute automatic white balance once using GenICam nodes.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"auto\", \"once\", \"manual\", \"off\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If white balance setting fails</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes using GenICam nodes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance mode strings</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to JSON configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If configuration file is invalid</p> <code>HardwareOperationError</code> <p>If configuration import fails</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export camera configuration to JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save JSON configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If configuration export fails</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest using GenICam nodes.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>Left offset</p> required <code>y</code> <code>int</code> <p>Top offset</p> required <code>width</code> <code>int</code> <p>Width of ROI</p> required <code>height</code> <code>int</code> <p>Height of ROI</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If ROI parameters are invalid</p> <code>HardwareOperationError</code> <p>If ROI setting fails</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current ROI settings from GenICam nodes.</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with 'x', 'y', 'width', 'height' keys</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to maximum sensor area using GenICam nodes.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If ROI reset fails</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> mock_genicam_camera_backend <p>Mock GenICam Camera Backend Module</p> MockGenICamCameraBackend <pre><code>MockGenICamCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>Mock GenICam Camera Backend Implementation</p> <p>This class provides a mock implementation of the GenICam camera backend for testing and development. It simulates GenICam camera functionality without requiring actual hardware, Harvesters library, or GenTL Producer files.</p> Features <ul> <li>Complete simulation of GenICam camera API</li> <li>Configurable image generation with realistic patterns</li> <li>Error simulation for testing error handling</li> <li>Configuration import/export simulation</li> <li>Camera control features (exposure, ROI, trigger modes, etc.)</li> <li>Vendor-specific quirks simulation (Keyence, Basler, etc.)</li> <li>Realistic timing and behavior simulation</li> </ul> <p>Usage::</p> <pre><code>from mindtrace.hardware.cameras.backends.genicam import MockGenICamCameraBackend\n\ncamera = MockGenICamCameraBackend(\"mock_keyence_001\", vendor=\"KEYENCE\")\nawait camera.set_exposure(50000)\nimage = await camera.capture()\nawait camera.close()\n</code></pre> Error Simulation <p>Enable error simulation via environment variables: - MOCK_GENICAM_FAIL_INIT: Simulate initialization failure - MOCK_GENICAM_FAIL_CAPTURE: Simulate capture failure - MOCK_GENICAM_TIMEOUT: Simulate timeout errors</p> <p>Attributes:</p> Name Type Description <code>initialized</code> <code>bool</code> <p>Whether camera was successfully initialized</p> <code>camera_name</code> <p>Name/identifier of the mock camera</p> <code>triggermode</code> <p>Current trigger mode (\"continuous\" or \"trigger\")</p> <code>img_quality_enhancement</code> <p>Current image enhancement setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <code>retrieve_retry_count</code> <p>Number of capture retry attempts</p> <code>exposure_time</code> <p>Current exposure time in microseconds</p> <code>gain</code> <p>Current gain value</p> <code>roi</code> <p>Current region of interest settings</p> <code>vendor</code> <p>Simulated camera vendor</p> <code>model</code> <p>Simulated camera model</p> <code>serial_number</code> <p>Simulated serial number</p> <code>vendor_quirks</code> <p>Vendor-specific parameter handling flags</p> <code>image_counter</code> <p>Counter for generating unique images</p> <code>fail_init</code> <p>Whether to simulate initialization failure</p> <code>fail_capture</code> <p>Whether to simulate capture failure</p> <code>simulate_timeout</code> <p>Whether to simulate timeout errors</p> <p>Initialize mock GenICam camera.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Enable image enhancement simulation (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of capture retry attempts (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - vendor: Simulated vendor (\"KEYENCE\", \"BASLER\", \"FLIR\", etc.) - model: Simulated model name - serial_number: Simulated serial number - cti_path: Simulated CTI path (ignored in mock) - timeout_ms: Timeout in milliseconds - buffer_count: Buffer count (simulated) - simulate_fail_init: If True, simulate initialization failure - simulate_fail_capture: If True, simulate capture failure - simulate_timeout: If True, simulate timeout on capture - synthetic_width: Override synthetic image width (int) - synthetic_height: Override synthetic image height (int) - synthetic_pattern: One of {\"auto\",\"gradient\",\"checkerboard\",\"circular\",\"noise\"} - synthetic_overlay_text: If False, disables text overlays in synthetic images</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Get available mock GenICam cameras.</p> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>List of camera names or dict with details</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock camera connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success status, mock camera object, device_info)</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera not found (when simulated)</p> <code>CameraInitializationError</code> <p>If initialization fails (when simulated)</p> <code>CameraConnectionError</code> <p>If connection fails (when simulated)</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the simulated exposure time range in microseconds.</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current simulated exposure time in microseconds.</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set the simulated camera exposure time in microseconds.</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get current simulated trigger mode.</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set the simulated camera's trigger mode.</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture a simulated image from the mock camera.</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if mock camera is connected and operational.</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close the mock camera and release simulated resources.</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get simulated camera gain range.</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current simulated camera gain.</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set simulated camera gain.</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set simulated Region of Interest.</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current simulated ROI settings.</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset simulated ROI to maximum sensor area.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import simulated camera configuration from JSON file.</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current simulated camera configuration to JSON file.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.opencv","title":"opencv","text":"<p>OpenCV Camera Backend</p> <p>Provides support for USB cameras and webcams via OpenCV with comprehensive error handling.</p> Components <ul> <li>OpenCVCameraBackend: OpenCV camera implementation (requires opencv-python)</li> </ul> Requirements <ul> <li>opencv-python: For camera access and image processing</li> <li>numpy: For image array operations</li> </ul> Installation <p>pip install opencv-python numpy</p> Usage <p>from mindtrace.hardware.cameras.backends.opencv import OpenCVCameraBackend</p> OpenCVCameraBackend <pre><code>OpenCVCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>OpenCV camera implementation for USB cameras and webcams.</p> <p>This backend provides a comprehensive interface to USB cameras, webcams, and other video capture devices using OpenCV's <code>VideoCapture</code> with robust error handling and resource management. It works across Windows, Linux, and macOS with platform-aware discovery.</p> Features <ul> <li>USB camera and webcam support across Windows, Linux, and macOS</li> <li>Automatic camera discovery and enumeration</li> <li>Configurable resolution, frame rate, and exposure settings</li> <li>Optional image quality enhancement (CLAHE)</li> <li>Robust error handling with retries and bounded timeouts</li> <li>BGR to RGB conversion for consistency</li> <li>Thread-safe operations with per-instance serialization</li> <li>Platform-specific optimizations</li> </ul> Configuration <p>All parameters are configurable via the hardware configuration system: - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_WIDTH</code>: Default frame width (1280) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_HEIGHT</code>: Default frame height (720) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_FPS</code>: Default frame rate (30) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_EXPOSURE</code>: Default exposure (-1 for auto) - <code>MINDTRACE_CAMERA_OPENCV_MAX_CAMERA_INDEX</code>: Maximum camera index to test (10) - <code>MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT</code>: Enable CLAHE enhancement - <code>MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT</code>: Number of capture retry attempts - <code>MINDTRACE_CAMERA_TIMEOUT_MS</code>: Capture timeout in milliseconds</p> <p>Concurrency and serialization: - All OpenCV SDK calls are executed on a per-instance single-thread executor to maintain thread affinity. - A per-instance asyncio.Lock (_io_lock) serializes mutating operations to prevent concurrent set/read races. - Unlike Basler, OpenCV cameras do not have an explicit \"grabbing\" state; all operations use continuous mode.</p> <p>Attributes:</p> Name Type Description <code>camera_index</code> <p>Camera device index or path</p> <code>cap</code> <code>Optional[VideoCapture]</code> <p>OpenCV VideoCapture object</p> <code>initialized</code> <code>bool</code> <p>Camera initialization status</p> <code>width</code> <code>bool</code> <p>Current frame width</p> <code>height</code> <code>bool</code> <p>Current frame height</p> <code>fps</code> <code>bool</code> <p>Current frame rate</p> <code>exposure</code> <code>bool</code> <p>Current exposure setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <p>Example::</p> <pre><code>from mindtrace.hardware.cameras.backends.opencv import OpenCVCameraBackend\n\nasync def main():\n    camera = OpenCVCameraBackend(\"0\", width=1280, height=720)\n    ok, cap, _ = await camera.initialize()\n    if ok:\n        image = await camera.capture()\n        await camera.close()\n</code></pre> <p>Initialize OpenCV camera with configuration.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (index number or device path)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to camera config file (not used for OpenCV)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Whether to apply image quality enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of times to retry capture (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - width: Frame width (uses config default if None) - height: Frame height (uses config default if None) - fps: Frame rate (uses config default if None) - exposure: Exposure value (uses config default if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If OpenCV is not installed</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera and establish connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Tuple[bool, Any, Any]: (success, camera_object, remote_control_object). For OpenCV</p> <code>Any</code> <p>cameras, both objects are the same <code>VideoCapture</code> instance.</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera cannot be opened</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Discover cameras with backend-aware probing.</p> <ul> <li>Linux: prefer CAP_V4L2 probing across indices</li> <li>Windows: try CAP_DSHOW then CAP_MSMF</li> <li>macOS: try CAP_AVFOUNDATION</li> <li>Fallback: default backend probing</li> </ul> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return a dict of details per camera.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>Union[List[str], Dict[str, Dict[str, str]]]: List of camera names (e.g.,</p> <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p><code>[\"opencv_camera_0\"]</code>) or a dict of details when <code>include_details=True</code>.</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture an image from the camera.</p> <p>Implements retry logic and proper error handling for robust image capture. Converts OpenCV's default BGR format to RGB for consistency.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Captured image as an RGB numpy array.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera connection is active and healthy.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if camera is connected and responsive, False otherwise</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close camera connection and cleanup resources.</p> <p>Properly releases the VideoCapture object and resets camera state.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> is_exposure_control_supported <code>async</code> <pre><code>is_exposure_control_supported() -&gt; bool\n</code></pre> <p>Check if exposure control is actually supported for this camera. Tests both reading and setting exposure to verify true support. Returns:     True if exposure control is supported, False otherwise</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set camera exposure time.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure value (OpenCV uses log scale, typically -13 to -1)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If exposure value is invalid or unsupported</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current camera exposure time.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; Optional[List[Union[int, float]]]\n</code></pre> <p>Get camera exposure time range.</p> <p>Returns:</p> Type Description <code>Optional[List[Union[int, float]]]</code> <p>List containing [min_exposure, max_exposure] in OpenCV log scale, or None if exposure control not supported</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get supported width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get supported height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_gain, max_gain]</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>Union[int, float]</code> <p>Gain value</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If gain value is out of range or setting fails</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest (ROI).</p> <p>Note: OpenCV cameras typically don't support hardware ROI; implement in software if needed.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>ROI x offset</p> required <code>y</code> <code>int</code> <p>ROI y offset</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>ROI is not supported by the OpenCV backend</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest (ROI).</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with full frame dimensions (ROI not supported)</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to full sensor size.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>ROI reset is not supported by the OpenCV backend</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode (\"auto\" or \"manual\")</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set white balance mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"auto\", \"manual\", \"off\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If value is invalid</p> <code>HardwareOperationError</code> <p>If the operation fails</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats (OpenCV always uses BGR internally)</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (always BGR8 for OpenCV, converted to RGB8 in capture)</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get trigger mode (always continuous for USB cameras).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" (USB cameras only support continuous mode)</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set trigger mode.</p> <p>USB cameras only support continuous mode.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" only)</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If trigger mode is not supported</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement status.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(img_quality_enhancement: bool)\n</code></pre> <p>Set image quality enhancement.</p> <p>Parameters:</p> Name Type Description Default <code>img_quality_enhancement</code> <code>bool</code> <p>Whether to enable image quality enhancement</p> required <p>Raises:</p> Type Description <code>HardwareOperationError</code> <p>If setting cannot be applied</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not connected</p> <code>CameraConfigurationError</code> <p>If configuration export fails</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not connected</p> <code>CameraConfigurationError</code> <p>If configuration import fails</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Bandwidth limiting not applicable for OpenCV cameras.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Packet size not applicable for OpenCV cameras.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Inter-packet delay not applicable for OpenCV cameras.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for OpenCV cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available trigger modes (OpenCV only supports continuous)</p> opencv_camera_backend <p>OpenCV camera backend module.</p> OpenCVCameraBackend <pre><code>OpenCVCameraBackend(\n    camera_name: str,\n    camera_config: Optional[str] = None,\n    img_quality_enhancement: Optional[bool] = None,\n    retrieve_retry_count: Optional[int] = None,\n    **backend_kwargs\n)\n</code></pre> <p>               Bases: <code>CameraBackend</code></p> <p>OpenCV camera implementation for USB cameras and webcams.</p> <p>This backend provides a comprehensive interface to USB cameras, webcams, and other video capture devices using OpenCV's <code>VideoCapture</code> with robust error handling and resource management. It works across Windows, Linux, and macOS with platform-aware discovery.</p> Features <ul> <li>USB camera and webcam support across Windows, Linux, and macOS</li> <li>Automatic camera discovery and enumeration</li> <li>Configurable resolution, frame rate, and exposure settings</li> <li>Optional image quality enhancement (CLAHE)</li> <li>Robust error handling with retries and bounded timeouts</li> <li>BGR to RGB conversion for consistency</li> <li>Thread-safe operations with per-instance serialization</li> <li>Platform-specific optimizations</li> </ul> Configuration <p>All parameters are configurable via the hardware configuration system: - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_WIDTH</code>: Default frame width (1280) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_HEIGHT</code>: Default frame height (720) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_FPS</code>: Default frame rate (30) - <code>MINDTRACE_CAMERA_OPENCV_DEFAULT_EXPOSURE</code>: Default exposure (-1 for auto) - <code>MINDTRACE_CAMERA_OPENCV_MAX_CAMERA_INDEX</code>: Maximum camera index to test (10) - <code>MINDTRACE_CAMERA_IMAGE_QUALITY_ENHANCEMENT</code>: Enable CLAHE enhancement - <code>MINDTRACE_CAMERA_RETRIEVE_RETRY_COUNT</code>: Number of capture retry attempts - <code>MINDTRACE_CAMERA_TIMEOUT_MS</code>: Capture timeout in milliseconds</p> <p>Concurrency and serialization: - All OpenCV SDK calls are executed on a per-instance single-thread executor to maintain thread affinity. - A per-instance asyncio.Lock (_io_lock) serializes mutating operations to prevent concurrent set/read races. - Unlike Basler, OpenCV cameras do not have an explicit \"grabbing\" state; all operations use continuous mode.</p> <p>Attributes:</p> Name Type Description <code>camera_index</code> <p>Camera device index or path</p> <code>cap</code> <code>Optional[VideoCapture]</code> <p>OpenCV VideoCapture object</p> <code>initialized</code> <code>bool</code> <p>Camera initialization status</p> <code>width</code> <code>bool</code> <p>Current frame width</p> <code>height</code> <code>bool</code> <p>Current frame height</p> <code>fps</code> <code>bool</code> <p>Current frame rate</p> <code>exposure</code> <code>bool</code> <p>Current exposure setting</p> <code>timeout_ms</code> <p>Capture timeout in milliseconds</p> <p>Example::</p> <pre><code>from mindtrace.hardware.cameras.backends.opencv import OpenCVCameraBackend\n\nasync def main():\n    camera = OpenCVCameraBackend(\"0\", width=1280, height=720)\n    ok, cap, _ = await camera.initialize()\n    if ok:\n        image = await camera.capture()\n        await camera.close()\n</code></pre> <p>Initialize OpenCV camera with configuration.</p> <p>Parameters:</p> Name Type Description Default <code>camera_name</code> <code>str</code> <p>Camera identifier (index number or device path)</p> required <code>camera_config</code> <code>Optional[str]</code> <p>Path to camera config file (not used for OpenCV)</p> <code>None</code> <code>img_quality_enhancement</code> <code>Optional[bool]</code> <p>Whether to apply image quality enhancement (uses config default if None)</p> <code>None</code> <code>retrieve_retry_count</code> <code>Optional[int]</code> <p>Number of times to retry capture (uses config default if None)</p> <code>None</code> <code>**backend_kwargs</code> <p>Backend-specific parameters: - width: Frame width (uses config default if None) - height: Frame height (uses config default if None) - fps: Frame rate (uses config default if None) - exposure: Exposure value (uses config default if None) - timeout_ms: Capture timeout in milliseconds (uses config default if None)</p> <code>{}</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If OpenCV is not installed</p> <code>CameraConfigurationError</code> <p>If configuration is invalid</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the camera and establish connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Tuple[bool, Any, Any]: (success, camera_object, remote_control_object). For OpenCV</p> <code>Any</code> <p>cameras, both objects are the same <code>VideoCapture</code> instance.</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera cannot be opened</p> <code>CameraInitializationError</code> <p>If camera initialization fails</p> <code>CameraConnectionError</code> <p>If camera connection fails</p> get_available_cameras <code>staticmethod</code> <pre><code>get_available_cameras(\n    include_details: bool = False,\n) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>Discover cameras with backend-aware probing.</p> <ul> <li>Linux: prefer CAP_V4L2 probing across indices</li> <li>Windows: try CAP_DSHOW then CAP_MSMF</li> <li>macOS: try CAP_AVFOUNDATION</li> <li>Fallback: default backend probing</li> </ul> <p>Parameters:</p> Name Type Description Default <code>include_details</code> <code>bool</code> <p>If True, return a dict of details per camera.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p>Union[List[str], Dict[str, Dict[str, str]]]: List of camera names (e.g.,</p> <code>Union[List[str], Dict[str, Dict[str, str]]]</code> <p><code>[\"opencv_camera_0\"]</code>) or a dict of details when <code>include_details=True</code>.</p> capture <code>async</code> <pre><code>capture() -&gt; np.ndarray\n</code></pre> <p>Capture an image from the camera.</p> <p>Implements retry logic and proper error handling for robust image capture. Converts OpenCV's default BGR format to RGB for consistency.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Captured image as an RGB numpy array.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized or accessible</p> <code>CameraCaptureError</code> <p>If image capture fails</p> <code>CameraTimeoutError</code> <p>If capture times out</p> check_connection <code>async</code> <pre><code>check_connection() -&gt; bool\n</code></pre> <p>Check if camera connection is active and healthy.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if camera is connected and responsive, False otherwise</p> close <code>async</code> <pre><code>close()\n</code></pre> <p>Close camera connection and cleanup resources.</p> <p>Properly releases the VideoCapture object and resets camera state.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera closure fails</p> is_exposure_control_supported <code>async</code> <pre><code>is_exposure_control_supported() -&gt; bool\n</code></pre> <p>Check if exposure control is actually supported for this camera. Tests both reading and setting exposure to verify true support. Returns:     True if exposure control is supported, False otherwise</p> set_exposure <code>async</code> <pre><code>set_exposure(exposure: Union[int, float])\n</code></pre> <p>Set camera exposure time.</p> <p>Parameters:</p> Name Type Description Default <code>exposure</code> <code>Union[int, float]</code> <p>Exposure value (OpenCV uses log scale, typically -13 to -1)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If exposure value is invalid or unsupported</p> <code>HardwareOperationError</code> <p>If exposure setting fails</p> get_exposure <code>async</code> <pre><code>get_exposure() -&gt; float\n</code></pre> <p>Get current camera exposure time.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>HardwareOperationError</code> <p>If exposure retrieval fails</p> get_exposure_range <code>async</code> <pre><code>get_exposure_range() -&gt; Optional[List[Union[int, float]]]\n</code></pre> <p>Get camera exposure time range.</p> <p>Returns:</p> Type Description <code>Optional[List[Union[int, float]]]</code> <p>List containing [min_exposure, max_exposure] in OpenCV log scale, or None if exposure control not supported</p> get_width_range <code>async</code> <pre><code>get_width_range() -&gt; List[int]\n</code></pre> <p>Get supported width range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_width, max_width]</p> get_height_range <code>async</code> <pre><code>get_height_range() -&gt; List[int]\n</code></pre> <p>Get supported height range.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List containing [min_height, max_height]</p> get_gain_range <code>async</code> <pre><code>get_gain_range() -&gt; List[Union[int, float]]\n</code></pre> <p>Get the supported gain range.</p> <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>List with [min_gain, max_gain]</p> set_gain <code>async</code> <pre><code>set_gain(gain: Union[int, float])\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>Union[int, float]</code> <p>Gain value</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If gain value is out of range or setting fails</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> set_ROI <code>async</code> <pre><code>set_ROI(x: int, y: int, width: int, height: int)\n</code></pre> <p>Set Region of Interest (ROI).</p> <p>Note: OpenCV cameras typically don't support hardware ROI; implement in software if needed.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>ROI x offset</p> required <code>y</code> <code>int</code> <p>ROI y offset</p> required <code>width</code> <code>int</code> <p>ROI width</p> required <code>height</code> <code>int</code> <p>ROI height</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>ROI is not supported by the OpenCV backend</p> get_ROI <code>async</code> <pre><code>get_ROI() -&gt; Dict[str, int]\n</code></pre> <p>Get current Region of Interest (ROI).</p> <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary with full frame dimensions (ROI not supported)</p> reset_ROI <code>async</code> <pre><code>reset_ROI()\n</code></pre> <p>Reset ROI to full sensor size.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>ROI reset is not supported by the OpenCV backend</p> get_wb <code>async</code> <pre><code>get_wb() -&gt; str\n</code></pre> <p>Get current white balance mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current white balance mode (\"auto\" or \"manual\")</p> set_auto_wb_once <code>async</code> <pre><code>set_auto_wb_once(value: str)\n</code></pre> <p>Set white balance mode.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>White balance mode (\"auto\", \"manual\", \"off\")</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not initialized</p> <code>CameraConfigurationError</code> <p>If value is invalid</p> <code>HardwareOperationError</code> <p>If the operation fails</p> get_wb_range <code>async</code> <pre><code>get_wb_range() -&gt; List[str]\n</code></pre> <p>Get available white balance modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available white balance modes</p> get_pixel_format_range <code>async</code> <pre><code>get_pixel_format_range() -&gt; List[str]\n</code></pre> <p>Get available pixel formats.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available pixel formats (OpenCV always uses BGR internally)</p> get_current_pixel_format <code>async</code> <pre><code>get_current_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (always BGR8 for OpenCV, converted to RGB8 in capture)</p> set_pixel_format <code>async</code> <pre><code>set_pixel_format(pixel_format: str)\n</code></pre> <p>Set pixel format.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_format</code> <code>str</code> <p>Pixel format to set</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If pixel format is not supported</p> get_triggermode <code>async</code> <pre><code>get_triggermode() -&gt; str\n</code></pre> <p>Get trigger mode (always continuous for USB cameras).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" (USB cameras only support continuous mode)</p> set_triggermode <code>async</code> <pre><code>set_triggermode(triggermode: str = 'continuous')\n</code></pre> <p>Set trigger mode.</p> <p>USB cameras only support continuous mode.</p> <p>Parameters:</p> Name Type Description Default <code>triggermode</code> <code>str</code> <p>Trigger mode (\"continuous\" only)</p> <code>'continuous'</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If trigger mode is not supported</p> get_image_quality_enhancement <code>async</code> <pre><code>get_image_quality_enhancement() -&gt; bool\n</code></pre> <p>Get image quality enhancement status.</p> set_image_quality_enhancement <code>async</code> <pre><code>set_image_quality_enhancement(img_quality_enhancement: bool)\n</code></pre> <p>Set image quality enhancement.</p> <p>Parameters:</p> Name Type Description Default <code>img_quality_enhancement</code> <code>bool</code> <p>Whether to enable image quality enhancement</p> required <p>Raises:</p> Type Description <code>HardwareOperationError</code> <p>If setting cannot be applied</p> export_config <code>async</code> <pre><code>export_config(config_path: str)\n</code></pre> <p>Export current camera configuration to common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to save configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not connected</p> <code>CameraConfigurationError</code> <p>If configuration export fails</p> import_config <code>async</code> <pre><code>import_config(config_path: str)\n</code></pre> <p>Import camera configuration from common JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to configuration file</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera is not connected</p> <code>CameraConfigurationError</code> <p>If configuration import fails</p> get_bandwidth_limit <code>async</code> <pre><code>get_bandwidth_limit() -&gt; float\n</code></pre> <p>Bandwidth limiting not applicable for OpenCV cameras.</p> get_packet_size <code>async</code> <pre><code>get_packet_size() -&gt; int\n</code></pre> <p>Packet size not applicable for OpenCV cameras.</p> get_inter_packet_delay <code>async</code> <pre><code>get_inter_packet_delay() -&gt; int\n</code></pre> <p>Inter-packet delay not applicable for OpenCV cameras.</p> set_capture_timeout <code>async</code> <pre><code>set_capture_timeout(timeout_ms: int)\n</code></pre> <p>Set capture timeout in milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Timeout value in milliseconds</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeout_ms is negative</p> get_capture_timeout <code>async</code> <pre><code>get_capture_timeout() -&gt; int\n</code></pre> <p>Get current capture timeout in milliseconds.</p> <p>Returns:</p> Type Description <code>int</code> <p>Current timeout value in milliseconds</p> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes for OpenCV cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available trigger modes (OpenCV only supports continuous)</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.backends.opencv--usb-camera-index-0","title":"USB camera (index 0)","text":"<p>if OPENCV_AVAILABLE:     camera = OpenCVCameraBackend(\"0\")     success, cam_obj, remote_obj = await camera.initialize()  # Initialize first     if success:         image = await camera.capture()         await camera.close()</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography","title":"homography","text":"<p>Homography-based planar measurement system.</p> <p>This module provides homography calibration and measurement capabilities for converting pixel-space object detections to real-world metric dimensions on planar surfaces.</p> Features <ul> <li>Automatic checkerboard calibration</li> <li>Manual point correspondence calibration</li> <li>RANSAC-based robust homography estimation</li> <li>Multi-unit measurement support (mm, cm, m, in, ft)</li> <li>Batch processing for multiple objects</li> <li>Framework-integrated logging and configuration</li> </ul> <p>Typical Usage::</p> <pre><code>from mindtrace.hardware import HomographyCalibrator, HomographyMeasurer\n\n# One-time calibration\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),\n    square_size=25.0,\n    world_unit=\"mm\"\n)\ncalibration.save(\"camera_calibration.json\")\n\n# Repeated measurement\nmeasurer = HomographyMeasurer(calibration)\ndetections = yolo.detect(frame)\nmeasurements = measurer.measure_bounding_boxes(detections, target_unit=\"cm\")\n\nfor measured in measurements:\n    print(f\"Size: {measured.width_world:.1f} \u00d7 {measured.height_world:.1f} cm\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.HomographyCalibrator","title":"HomographyCalibrator","text":"<pre><code>HomographyCalibrator(**kwargs)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Calibrates planar homography for pixel-to-world coordinate mapping.</p> <p>Establishes a homography matrix H that maps planar world coordinates (X, Y, Z=0) in metric units to image pixel coordinates (u, v). Supports both automatic checkerboard-based calibration and manual point correspondence calibration.</p> <p>The homography enables real-world measurements from camera images for objects lying on a known planar surface (e.g., overhead cameras, objects on tables/floors).</p> Features <ul> <li>Automatic checkerboard pattern detection and calibration</li> <li>Manual point correspondence calibration</li> <li>RANSAC-based robust homography estimation</li> <li>Sub-pixel corner refinement for improved accuracy</li> <li>Lens distortion correction support</li> <li>Camera intrinsics estimation from FOV</li> </ul> Typical Workflow <ol> <li>Place calibration target (checkerboard) on measurement plane</li> <li>Capture image with known world coordinates</li> <li>Calibrate to obtain homography matrix</li> <li>Use calibration for repeated measurements</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware import HomographyCalibrator\n\n# Automatic checkerboard calibration\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),     # Inner corners\n    square_width=25.0,       # mm width per square\n    square_height=25.0,      # mm height per square\n    world_unit=\"mm\"\n)\n\n# Manual point correspondence calibration\ncalibration = calibrator.calibrate_from_correspondences(\n    world_points=[(0, 0), (300, 0), (300, 200), (0, 200)],  # mm\n    image_points=[(100, 50), (500, 50), (500, 400), (100, 400)],  # pixels\n    world_unit=\"mm\"\n)\n\n# Save for later use\ncalibration.save(\"camera_calibration.json\")\n</code></pre> Configuration <p>All parameters can be configured via hardware config: - ransac_threshold: RANSAC reprojection error threshold (default: 3.0 pixels) - refine_corners: Enable sub-pixel corner refinement (default: True) - corner_refinement_window: Refinement window size (default: 11) - min_correspondences: Minimum points needed (default: 4) - default_world_unit: Default measurement unit (default: \"mm\")</p> Limitations <ul> <li>Only works for planar surfaces (Z=0 assumption)</li> <li>Requires camera to remain fixed after calibration</li> <li>Accuracy degrades with severe viewing angles</li> </ul> <p>Initialize homography calibrator.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to Mindtrace base class</p> <code>{}</code> estimate_intrinsics_from_fov <pre><code>estimate_intrinsics_from_fov(\n    image_size: Tuple[int, int],\n    fov_horizontal_deg: float,\n    fov_vertical_deg: float,\n    principal_point: Optional[Tuple[float, float]] = None,\n) -&gt; np.ndarray\n</code></pre> <p>Estimate camera intrinsics matrix from field-of-view parameters.</p> <p>Computes a simple pinhole camera model intrinsics matrix (K) from the camera's horizontal and vertical field of view angles and image dimensions. Useful when full camera calibration is not available.</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Tuple[int, int]</code> <p>Image dimensions as (width, height) in pixels</p> required <code>fov_horizontal_deg</code> <code>float</code> <p>Horizontal field of view in degrees</p> required <code>fov_vertical_deg</code> <code>float</code> <p>Vertical field of view in degrees</p> required <code>principal_point</code> <code>Optional[Tuple[float, float]]</code> <p>Optional (cx, cy) principal point in pixels.            Defaults to image center if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>3x3 camera intrinsics matrix K</p> <p>Example::</p> <pre><code>K = calibrator.estimate_intrinsics_from_fov(\n    image_size=(1920, 1080),\n    fov_horizontal_deg=70.0,\n    fov_vertical_deg=45.0\n)\n</code></pre> calibrate_from_correspondences <pre><code>calibrate_from_correspondences(\n    world_points: ndarray,\n    image_points: ndarray,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Compute homography from known point correspondences.</p> <p>Establishes the homography matrix H given known world coordinates (on Z=0 plane) and their corresponding image pixel coordinates. Uses RANSAC for robust estimation in the presence of outliers.</p> <p>Parameters:</p> Name Type Description Default <code>world_points</code> <code>ndarray</code> <p>Nx2 array of world coordinates in metric units (X, Y on Z=0 plane)</p> required <code>image_points</code> <code>ndarray</code> <p>Nx2 array of corresponding image coordinates in pixels (u, v)</p> required <code>world_unit</code> <code>Optional[str]</code> <p>Unit of world coordinates (e.g., 'mm', 'cm', 'm'). Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix and metadata</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If inputs are invalid (wrong shape, too few points)</p> <code>HardwareOperationError</code> <p>If homography estimation fails</p> <p>Example::</p> <pre><code># Four corner correspondences (world in mm, image in pixels)\nworld_pts = np.array([[0, 0], [300, 0], [300, 200], [0, 200]])\nimage_pts = np.array([[100, 50], [500, 50], [500, 400], [100, 400]])\n\ncalibration = calibrator.calibrate_from_correspondences(\n    world_points=world_pts,\n    image_points=image_pts,\n    world_unit=\"mm\"\n)\n</code></pre> calibrate_checkerboard <pre><code>calibrate_checkerboard(\n    image: Union[Image, ndarray],\n    board_size: Optional[Tuple[int, int]] = None,\n    square_size: Optional[float] = None,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    refine_corners: Optional[bool] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Automatic calibration from checkerboard pattern detection.</p> <p>Detects a checkerboard calibration pattern in the image, extracts corner correspondences, and computes the homography matrix. The checkerboard is assumed to lie on the Z=0 plane with known square dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Union[Image, ndarray]</code> <p>PIL Image or BGR numpy array containing checkerboard pattern</p> required <code>board_size</code> <code>Optional[Tuple[int, int]]</code> <p>Number of inner corners as (columns, rows). Uses config default if None.        For a standard 8x8 checkerboard, use (7, 7).</p> <code>None</code> <code>square_size</code> <code>Optional[float]</code> <p>Physical size of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>world_unit</code> <code>Optional[str]</code> <p>Unit of square_size (e.g., 'mm', 'cm', 'm'). Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <code>refine_corners</code> <code>Optional[bool]</code> <p>Enable sub-pixel corner refinement. Uses config default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix and metadata</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If image format is unsupported</p> <code>HardwareOperationError</code> <p>If checkerboard detection fails</p> <p>Example::</p> <pre><code># Use config defaults for standard calibration board\ncalibration = calibrator.calibrate_checkerboard(image=checkerboard_image)\n\n# Or override specific parameters\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(9, 6),         # Custom board size\n    square_size=30.0,          # Custom square size\n    world_unit=\"mm\"\n)\n</code></pre> Notes <ul> <li>board_size is the number of INNER corners, not squares</li> <li>A standard 8x8 checkerboard has 7x7 inner corners</li> <li>Ensure good lighting and focus for accurate detection</li> <li>Checkerboard should fill significant portion of image</li> <li>If using a standard calibration board, configure dimensions via:   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_COLS   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_ROWS   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_SQUARE</li> </ul> calibrate_checkerboard_multi_view <pre><code>calibrate_checkerboard_multi_view(\n    images: list[Union[Image, ndarray]],\n    positions: list[Tuple[float, float]],\n    board_size: Optional[Tuple[int, int]] = None,\n    square_width: Optional[float] = None,\n    square_height: Optional[float] = None,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    refine_corners: Optional[bool] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Calibrate from multiple checkerboard positions on the same plane.</p> <p>Combines corner detections from multiple images where the checkerboard is placed at different positions on the measurement plane. This provides better calibration coverage over large areas without requiring an oversized calibration target.</p> <p>Ideal for calibrating long surfaces (e.g., metallic bars, conveyor belts) using a standard-sized checkerboard moved to multiple positions.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list[Union[Image, ndarray]]</code> <p>List of images, each containing the checkerboard at a different position</p> required <code>positions</code> <code>list[Tuple[float, float]]</code> <p>List of (x_offset, y_offset) tuples in world units specifying       the checkerboard's origin position in each image. The first position       is typically (0, 0), and subsequent positions indicate how far the       checkerboard was moved.</p> required <code>board_size</code> <code>Optional[Tuple[int, int]]</code> <p>Number of inner corners as (columns, rows). Uses config default if None.</p> <code>None</code> <code>square_width</code> <code>Optional[float]</code> <p>Physical width of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>square_height</code> <code>Optional[float]</code> <p>Physical height of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>world_unit</code> <code>Optional[str]</code> <p>Unit of positions and square_width/height. Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <code>refine_corners</code> <code>Optional[bool]</code> <p>Enable sub-pixel corner refinement. Uses config default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix computed from all positions</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If inputs are invalid or inconsistent</p> <code>HardwareOperationError</code> <p>If checkerboard detection fails in any image</p> <p>Example::</p> <pre><code># Calibrate a 2-meter long bar using 3 checkerboard positions\nimages = [image1, image2, image3]\npositions = [\n    (0, 0),      # Start of bar\n    (1000, 0),   # Middle (1000mm from start)\n    (2000, 0)    # End (2000mm from start)\n]\n\ncalibration = calibrator.calibrate_checkerboard_multi_view(\n    images=images,\n    positions=positions,\n    board_size=(12, 12),\n    square_width=25.0,    # 25mm wide squares\n    square_height=25.0,   # 25mm tall squares\n    world_unit=\"mm\"\n)\n</code></pre> Notes <ul> <li>All images must show the same plane (Z=0)</li> <li>Positions specify where the checkerboard origin (top-left corner) is located</li> <li>Use more positions for better coverage of large measurement areas</li> <li>Typical usage: 3-5 positions for long surfaces</li> <li>RANSAC automatically handles slight inaccuracies in position measurements</li> </ul>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.CalibrationData","title":"CalibrationData  <code>dataclass</code>","text":"<pre><code>CalibrationData(\n    H: ndarray,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    world_unit: str = \"mm\",\n    plane_normal_camera: Optional[ndarray] = None,\n)\n</code></pre> <p>Immutable container for homography calibration data.</p> <p>Holds the homography matrix and optional camera intrinsics derived or provided during calibration. The homography maps world plane coordinates (Z=0) in metric units to image pixel coordinates.</p> <p>Attributes:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>3x3 homography matrix from world plane (Z=0) to image pixels</p> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>3x3 camera intrinsics matrix (K) if known or estimated</p> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Lens distortion coefficients if available</p> <code>world_unit</code> <code>str</code> <p>Unit used for world coordinates (e.g., 'mm', 'cm', 'm', 'in', 'ft')</p> <code>plane_normal_camera</code> <code>Optional[ndarray]</code> <p>Optional 3D normal of the plane in camera frame if recovered</p> save <pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save calibration data to JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to save the calibration data</p> required Note <p>NumPy arrays are converted to lists for JSON serialization.</p> load <code>classmethod</code> <pre><code>load(filepath: str) -&gt; CalibrationData\n</code></pre> <p>Load calibration data from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the calibration data file</p> required <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData instance loaded from file</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>ValueError</code> <p>If the file format is invalid</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.MeasuredBox","title":"MeasuredBox  <code>dataclass</code>","text":"<pre><code>MeasuredBox(\n    corners_world: ndarray,\n    width_world: float,\n    height_world: float,\n    area_world: float,\n    unit: str,\n)\n</code></pre> <p>Immutable container for metric-space measurement of a bounding box.</p> <p>Stores the result of projecting a pixel-space bounding box to world coordinates on a planar surface using homography inversion. Contains the projected corner points and computed physical dimensions.</p> <p>Attributes:</p> Name Type Description <code>corners_world</code> <code>ndarray</code> <p>4x2 array of corner coordinates in world units (top-left, top-right, bottom-right, bottom-left)</p> <code>width_world</code> <code>float</code> <p>Width in world units (distance between top-left and top-right)</p> <code>height_world</code> <code>float</code> <p>Height in world units (distance between top-left and bottom-left)</p> <code>area_world</code> <code>float</code> <p>Area in square world units (computed via shoelace formula)</p> <code>unit</code> <code>str</code> <p>Unit of measurement (e.g., 'mm', 'cm', 'm', 'in', 'ft')</p> to_dict <pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert measurement to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation with corners as list</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.HomographyMeasurer","title":"HomographyMeasurer","text":"<pre><code>HomographyMeasurer(calibration: CalibrationData, **kwargs)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Measures physical dimensions of objects using planar homography.</p> <p>Projects pixel-space bounding boxes from object detection to real-world metric coordinates on a planar surface using a pre-calibrated homography matrix. Enables accurate physical size measurements from camera images.</p> <p>The measurer uses the inverse homography (H\u207b\u00b9) to map image pixels back to world coordinates, then computes Euclidean distances and polygon areas for size measurements.</p> Features <ul> <li>Pixel-to-world coordinate projection</li> <li>Bounding box dimension measurement (width, height, area)</li> <li>Multi-unit support with automatic conversion</li> <li>Batch processing for multiple detections</li> <li>Pre-computed inverse homography for performance</li> </ul> Typical Workflow <ol> <li>Calibrate camera view to obtain HomographyCalibrator.calibrate_*()</li> <li>Create measurer with calibration data</li> <li>Detect objects with vision model (YOLO, etc.)</li> <li>Measure physical dimensions from bounding boxes</li> <li>Apply size-based filtering or quality control</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware import HomographyCalibrator, HomographyMeasurer\nfrom mindtrace.core.types import BoundingBox\n\n# One-time calibration\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),\n    square_size=25.0,\n    world_unit=\"mm\"\n)\n\n# Create measurer (reuse for all measurements)\nmeasurer = HomographyMeasurer(calibration)\n\n# Measure objects from detection results\ndetections = yolo.detect(frame)  # List[BoundingBox]\nmeasurements = measurer.measure_bounding_boxes(detections, target_unit=\"cm\")\n\nfor measured in measurements:\n    print(f\"Width: {measured.width_world:.2f} cm\")\n    print(f\"Height: {measured.height_world:.2f} cm\")\n    print(f\"Area: {measured.area_world:.2f} cm\u00b2\")\n\n    # Size-based filtering\n    if measured.width_world &gt; 10.0:\n        reject_oversized_part(measured)\n</code></pre> Configuration <ul> <li>Supported units: mm, cm, m, in, ft (configurable via hardware config)</li> <li>Default world unit: Inherited from calibration data</li> </ul> Limitations <ul> <li>Only works for planar surfaces (Z=0 assumption)</li> <li>Accuracy depends on calibration quality and viewing angle</li> <li>Assumes objects lie flat on the calibrated plane</li> <li>Camera must remain fixed after calibration</li> </ul> <p>Initialize homography measurer with calibration data.</p> <p>Parameters:</p> Name Type Description Default <code>calibration</code> <code>CalibrationData</code> <p>CalibrationData from HomographyCalibrator</p> required <code>**kwargs</code> <p>Additional arguments passed to Mindtrace base class</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If homography matrix is invalid</p> pixels_to_world <pre><code>pixels_to_world(points_px: ndarray) -&gt; np.ndarray\n</code></pre> <p>Project pixel coordinates to world plane coordinates.</p> <p>Maps Nx2 pixel coordinates to world plane coordinates using the inverse homography matrix H\u207b\u00b9. This is the core projection operation for all measurement functionality.</p> <p>Parameters:</p> Name Type Description Default <code>points_px</code> <code>ndarray</code> <p>Nx2 array of pixel coordinates (u, v)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Nx2 array of world coordinates (X, Y) in calibration world unit</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If input array has wrong shape</p> <p>Example::</p> <pre><code># Project single point\nworld_point = measurer.pixels_to_world(np.array([[320, 240]]))\n\n# Project multiple points\npixel_corners = np.array([[100, 50], [500, 50], [500, 400], [100, 400]])\nworld_corners = measurer.pixels_to_world(pixel_corners)\n</code></pre> measure_bounding_box <pre><code>measure_bounding_box(\n    box: BoundingBox, target_unit: Optional[str] = None\n) -&gt; MeasuredBox\n</code></pre> <p>Measure physical dimensions of a bounding box on the calibrated plane.</p> <p>Projects the four corners of a pixel-space bounding box to world coordinates, then computes width, height, and area in the specified unit.</p> <p>Parameters:</p> Name Type Description Default <code>box</code> <code>BoundingBox</code> <p>BoundingBox from object detection (x, y, width, height in pixels)</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output measurements (e.g., 'cm', 'm').         Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MeasuredBox</code> <p>MeasuredBox with physical dimensions and corner coordinates</p> <p>Example::</p> <pre><code># From object detection\ndetection = BoundingBox(x=100, y=50, width=400, height=350)\nmeasured = measurer.measure_bounding_box(detection, target_unit=\"cm\")\n\nprint(f\"Object is {measured.width_world:.1f} \u00d7 {measured.height_world:.1f} cm\")\nprint(f\"Area: {measured.area_world:.1f} cm\u00b2\")\n</code></pre> measure_bounding_boxes <pre><code>measure_bounding_boxes(\n    boxes: Sequence[BoundingBox], target_unit: Optional[str] = None\n) -&gt; List[MeasuredBox]\n</code></pre> <p>Measure physical dimensions of multiple bounding boxes.</p> <p>Batch processing of multiple object detections. More efficient than calling measure_bounding_box() in a loop.</p> <p>Parameters:</p> Name Type Description Default <code>boxes</code> <code>Sequence[BoundingBox]</code> <p>Sequence of BoundingBox objects from object detection</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output measurements. Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[MeasuredBox]</code> <p>List of MeasuredBox objects with physical dimensions</p> <p>Example::</p> <pre><code># Batch measurement from multiple detections\ndetections = yolo.detect(frame)  # List[BoundingBox]\nmeasurements = measurer.measure_bounding_boxes(detections, target_unit=\"cm\")\n\n# Size-based filtering\nlarge_objects = [m for m in measurements if m.width_world &gt; 15.0]\n\n# Quality control\nfor measured in measurements:\n    if not (10.0 &lt;= measured.width_world &lt;= 20.0):\n        reject_part(measured)\n</code></pre> measure_distance <pre><code>measure_distance(\n    point1: Union[Tuple[float, float], ndarray],\n    point2: Union[Tuple[float, float], ndarray],\n    target_unit: Optional[str] = None,\n) -&gt; Tuple[float, str]\n</code></pre> <p>Measure Euclidean distance between two points on the calibrated plane.</p> <p>Converts pixel coordinates to world coordinates and computes the distance. Useful for measuring gaps, spacing, or verifying known distances.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>Union[Tuple[float, float], ndarray]</code> <p>First point as (x, y) pixel coordinates</p> required <code>point2</code> <code>Union[Tuple[float, float], ndarray]</code> <p>Second point as (x, y) pixel coordinates</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output distance. Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, str]</code> <p>Tuple of (distance, unit)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If target_unit is not supported</p> <p>Example::</p> <pre><code># Measure distance between two detected points\npoint1 = (150, 200)  # pixels\npoint2 = (350, 200)  # pixels\ndistance, unit = measurer.measure_distance(point1, point2, target_unit=\"mm\")\nprint(f\"Distance: {distance:.2f} {unit}\")\n\n# Verify calibration accuracy\nknown_distance_mm = 100.0\nmeasured_distance, _ = measurer.measure_distance(ref_point1, ref_point2, \"mm\")\nerror_percent = abs(measured_distance - known_distance_mm) / known_distance_mm * 100\nprint(f\"Calibration error: {error_percent:.2f}%\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.calibrator","title":"calibrator","text":"<p>Homography calibration for planar surface measurement.</p> <p>This module provides calibration methods for establishing the relationship between image pixel coordinates and real-world metric coordinates on a planar surface.</p> HomographyCalibrator <pre><code>HomographyCalibrator(**kwargs)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Calibrates planar homography for pixel-to-world coordinate mapping.</p> <p>Establishes a homography matrix H that maps planar world coordinates (X, Y, Z=0) in metric units to image pixel coordinates (u, v). Supports both automatic checkerboard-based calibration and manual point correspondence calibration.</p> <p>The homography enables real-world measurements from camera images for objects lying on a known planar surface (e.g., overhead cameras, objects on tables/floors).</p> Features <ul> <li>Automatic checkerboard pattern detection and calibration</li> <li>Manual point correspondence calibration</li> <li>RANSAC-based robust homography estimation</li> <li>Sub-pixel corner refinement for improved accuracy</li> <li>Lens distortion correction support</li> <li>Camera intrinsics estimation from FOV</li> </ul> Typical Workflow <ol> <li>Place calibration target (checkerboard) on measurement plane</li> <li>Capture image with known world coordinates</li> <li>Calibrate to obtain homography matrix</li> <li>Use calibration for repeated measurements</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware import HomographyCalibrator\n\n# Automatic checkerboard calibration\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),     # Inner corners\n    square_width=25.0,       # mm width per square\n    square_height=25.0,      # mm height per square\n    world_unit=\"mm\"\n)\n\n# Manual point correspondence calibration\ncalibration = calibrator.calibrate_from_correspondences(\n    world_points=[(0, 0), (300, 0), (300, 200), (0, 200)],  # mm\n    image_points=[(100, 50), (500, 50), (500, 400), (100, 400)],  # pixels\n    world_unit=\"mm\"\n)\n\n# Save for later use\ncalibration.save(\"camera_calibration.json\")\n</code></pre> Configuration <p>All parameters can be configured via hardware config: - ransac_threshold: RANSAC reprojection error threshold (default: 3.0 pixels) - refine_corners: Enable sub-pixel corner refinement (default: True) - corner_refinement_window: Refinement window size (default: 11) - min_correspondences: Minimum points needed (default: 4) - default_world_unit: Default measurement unit (default: \"mm\")</p> Limitations <ul> <li>Only works for planar surfaces (Z=0 assumption)</li> <li>Requires camera to remain fixed after calibration</li> <li>Accuracy degrades with severe viewing angles</li> </ul> <p>Initialize homography calibrator.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to Mindtrace base class</p> <code>{}</code> estimate_intrinsics_from_fov <pre><code>estimate_intrinsics_from_fov(\n    image_size: Tuple[int, int],\n    fov_horizontal_deg: float,\n    fov_vertical_deg: float,\n    principal_point: Optional[Tuple[float, float]] = None,\n) -&gt; np.ndarray\n</code></pre> <p>Estimate camera intrinsics matrix from field-of-view parameters.</p> <p>Computes a simple pinhole camera model intrinsics matrix (K) from the camera's horizontal and vertical field of view angles and image dimensions. Useful when full camera calibration is not available.</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Tuple[int, int]</code> <p>Image dimensions as (width, height) in pixels</p> required <code>fov_horizontal_deg</code> <code>float</code> <p>Horizontal field of view in degrees</p> required <code>fov_vertical_deg</code> <code>float</code> <p>Vertical field of view in degrees</p> required <code>principal_point</code> <code>Optional[Tuple[float, float]]</code> <p>Optional (cx, cy) principal point in pixels.            Defaults to image center if not provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>3x3 camera intrinsics matrix K</p> <p>Example::</p> <pre><code>K = calibrator.estimate_intrinsics_from_fov(\n    image_size=(1920, 1080),\n    fov_horizontal_deg=70.0,\n    fov_vertical_deg=45.0\n)\n</code></pre> calibrate_from_correspondences <pre><code>calibrate_from_correspondences(\n    world_points: ndarray,\n    image_points: ndarray,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Compute homography from known point correspondences.</p> <p>Establishes the homography matrix H given known world coordinates (on Z=0 plane) and their corresponding image pixel coordinates. Uses RANSAC for robust estimation in the presence of outliers.</p> <p>Parameters:</p> Name Type Description Default <code>world_points</code> <code>ndarray</code> <p>Nx2 array of world coordinates in metric units (X, Y on Z=0 plane)</p> required <code>image_points</code> <code>ndarray</code> <p>Nx2 array of corresponding image coordinates in pixels (u, v)</p> required <code>world_unit</code> <code>Optional[str]</code> <p>Unit of world coordinates (e.g., 'mm', 'cm', 'm'). Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix and metadata</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If inputs are invalid (wrong shape, too few points)</p> <code>HardwareOperationError</code> <p>If homography estimation fails</p> <p>Example::</p> <pre><code># Four corner correspondences (world in mm, image in pixels)\nworld_pts = np.array([[0, 0], [300, 0], [300, 200], [0, 200]])\nimage_pts = np.array([[100, 50], [500, 50], [500, 400], [100, 400]])\n\ncalibration = calibrator.calibrate_from_correspondences(\n    world_points=world_pts,\n    image_points=image_pts,\n    world_unit=\"mm\"\n)\n</code></pre> calibrate_checkerboard <pre><code>calibrate_checkerboard(\n    image: Union[Image, ndarray],\n    board_size: Optional[Tuple[int, int]] = None,\n    square_size: Optional[float] = None,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    refine_corners: Optional[bool] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Automatic calibration from checkerboard pattern detection.</p> <p>Detects a checkerboard calibration pattern in the image, extracts corner correspondences, and computes the homography matrix. The checkerboard is assumed to lie on the Z=0 plane with known square dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Union[Image, ndarray]</code> <p>PIL Image or BGR numpy array containing checkerboard pattern</p> required <code>board_size</code> <code>Optional[Tuple[int, int]]</code> <p>Number of inner corners as (columns, rows). Uses config default if None.        For a standard 8x8 checkerboard, use (7, 7).</p> <code>None</code> <code>square_size</code> <code>Optional[float]</code> <p>Physical size of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>world_unit</code> <code>Optional[str]</code> <p>Unit of square_size (e.g., 'mm', 'cm', 'm'). Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <code>refine_corners</code> <code>Optional[bool]</code> <p>Enable sub-pixel corner refinement. Uses config default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix and metadata</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If image format is unsupported</p> <code>HardwareOperationError</code> <p>If checkerboard detection fails</p> <p>Example::</p> <pre><code># Use config defaults for standard calibration board\ncalibration = calibrator.calibrate_checkerboard(image=checkerboard_image)\n\n# Or override specific parameters\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(9, 6),         # Custom board size\n    square_size=30.0,          # Custom square size\n    world_unit=\"mm\"\n)\n</code></pre> Notes <ul> <li>board_size is the number of INNER corners, not squares</li> <li>A standard 8x8 checkerboard has 7x7 inner corners</li> <li>Ensure good lighting and focus for accurate detection</li> <li>Checkerboard should fill significant portion of image</li> <li>If using a standard calibration board, configure dimensions via:   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_COLS   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_ROWS   MINDTRACE_HW_HOMOGRAPHY_CHECKERBOARD_SQUARE</li> </ul> calibrate_checkerboard_multi_view <pre><code>calibrate_checkerboard_multi_view(\n    images: list[Union[Image, ndarray]],\n    positions: list[Tuple[float, float]],\n    board_size: Optional[Tuple[int, int]] = None,\n    square_width: Optional[float] = None,\n    square_height: Optional[float] = None,\n    world_unit: Optional[str] = None,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    refine_corners: Optional[bool] = None,\n) -&gt; CalibrationData\n</code></pre> <p>Calibrate from multiple checkerboard positions on the same plane.</p> <p>Combines corner detections from multiple images where the checkerboard is placed at different positions on the measurement plane. This provides better calibration coverage over large areas without requiring an oversized calibration target.</p> <p>Ideal for calibrating long surfaces (e.g., metallic bars, conveyor belts) using a standard-sized checkerboard moved to multiple positions.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list[Union[Image, ndarray]]</code> <p>List of images, each containing the checkerboard at a different position</p> required <code>positions</code> <code>list[Tuple[float, float]]</code> <p>List of (x_offset, y_offset) tuples in world units specifying       the checkerboard's origin position in each image. The first position       is typically (0, 0), and subsequent positions indicate how far the       checkerboard was moved.</p> required <code>board_size</code> <code>Optional[Tuple[int, int]]</code> <p>Number of inner corners as (columns, rows). Uses config default if None.</p> <code>None</code> <code>square_width</code> <code>Optional[float]</code> <p>Physical width of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>square_height</code> <code>Optional[float]</code> <p>Physical height of one checkerboard square in world units. Uses config default if None.</p> <code>None</code> <code>world_unit</code> <code>Optional[str]</code> <p>Unit of positions and square_width/height. Uses config default if None.</p> <code>None</code> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>Optional 3x3 camera intrinsics matrix for undistortion</p> <code>None</code> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Optional distortion coefficients for undistortion</p> <code>None</code> <code>refine_corners</code> <code>Optional[bool]</code> <p>Enable sub-pixel corner refinement. Uses config default if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData containing homography matrix computed from all positions</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If inputs are invalid or inconsistent</p> <code>HardwareOperationError</code> <p>If checkerboard detection fails in any image</p> <p>Example::</p> <pre><code># Calibrate a 2-meter long bar using 3 checkerboard positions\nimages = [image1, image2, image3]\npositions = [\n    (0, 0),      # Start of bar\n    (1000, 0),   # Middle (1000mm from start)\n    (2000, 0)    # End (2000mm from start)\n]\n\ncalibration = calibrator.calibrate_checkerboard_multi_view(\n    images=images,\n    positions=positions,\n    board_size=(12, 12),\n    square_width=25.0,    # 25mm wide squares\n    square_height=25.0,   # 25mm tall squares\n    world_unit=\"mm\"\n)\n</code></pre> Notes <ul> <li>All images must show the same plane (Z=0)</li> <li>Positions specify where the checkerboard origin (top-left corner) is located</li> <li>Use more positions for better coverage of large measurement areas</li> <li>Typical usage: 3-5 positions for long surfaces</li> <li>RANSAC automatically handles slight inaccuracies in position measurements</li> </ul>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.data","title":"data","text":"<p>Data structures for homography calibration and measurement.</p> <p>This module defines immutable data containers for homography-based measurement operations.</p> CalibrationData <code>dataclass</code> <pre><code>CalibrationData(\n    H: ndarray,\n    camera_matrix: Optional[ndarray] = None,\n    dist_coeffs: Optional[ndarray] = None,\n    world_unit: str = \"mm\",\n    plane_normal_camera: Optional[ndarray] = None,\n)\n</code></pre> <p>Immutable container for homography calibration data.</p> <p>Holds the homography matrix and optional camera intrinsics derived or provided during calibration. The homography maps world plane coordinates (Z=0) in metric units to image pixel coordinates.</p> <p>Attributes:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>3x3 homography matrix from world plane (Z=0) to image pixels</p> <code>camera_matrix</code> <code>Optional[ndarray]</code> <p>3x3 camera intrinsics matrix (K) if known or estimated</p> <code>dist_coeffs</code> <code>Optional[ndarray]</code> <p>Lens distortion coefficients if available</p> <code>world_unit</code> <code>str</code> <p>Unit used for world coordinates (e.g., 'mm', 'cm', 'm', 'in', 'ft')</p> <code>plane_normal_camera</code> <code>Optional[ndarray]</code> <p>Optional 3D normal of the plane in camera frame if recovered</p> save <pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save calibration data to JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to save the calibration data</p> required Note <p>NumPy arrays are converted to lists for JSON serialization.</p> load <code>classmethod</code> <pre><code>load(filepath: str) -&gt; CalibrationData\n</code></pre> <p>Load calibration data from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the calibration data file</p> required <p>Returns:</p> Type Description <code>CalibrationData</code> <p>CalibrationData instance loaded from file</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>ValueError</code> <p>If the file format is invalid</p> MeasuredBox <code>dataclass</code> <pre><code>MeasuredBox(\n    corners_world: ndarray,\n    width_world: float,\n    height_world: float,\n    area_world: float,\n    unit: str,\n)\n</code></pre> <p>Immutable container for metric-space measurement of a bounding box.</p> <p>Stores the result of projecting a pixel-space bounding box to world coordinates on a planar surface using homography inversion. Contains the projected corner points and computed physical dimensions.</p> <p>Attributes:</p> Name Type Description <code>corners_world</code> <code>ndarray</code> <p>4x2 array of corner coordinates in world units (top-left, top-right, bottom-right, bottom-left)</p> <code>width_world</code> <code>float</code> <p>Width in world units (distance between top-left and top-right)</p> <code>height_world</code> <code>float</code> <p>Height in world units (distance between top-left and bottom-left)</p> <code>area_world</code> <code>float</code> <p>Area in square world units (computed via shoelace formula)</p> <code>unit</code> <code>str</code> <p>Unit of measurement (e.g., 'mm', 'cm', 'm', 'in', 'ft')</p> to_dict <pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert measurement to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation with corners as list</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.homography.measurer","title":"measurer","text":"<p>Homography-based measurement for planar objects.</p> <p>This module provides measurement operations that project pixel-space bounding boxes to real-world metric coordinates using calibrated homography transformations.</p> HomographyMeasurer <pre><code>HomographyMeasurer(calibration: CalibrationData, **kwargs)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Measures physical dimensions of objects using planar homography.</p> <p>Projects pixel-space bounding boxes from object detection to real-world metric coordinates on a planar surface using a pre-calibrated homography matrix. Enables accurate physical size measurements from camera images.</p> <p>The measurer uses the inverse homography (H\u207b\u00b9) to map image pixels back to world coordinates, then computes Euclidean distances and polygon areas for size measurements.</p> Features <ul> <li>Pixel-to-world coordinate projection</li> <li>Bounding box dimension measurement (width, height, area)</li> <li>Multi-unit support with automatic conversion</li> <li>Batch processing for multiple detections</li> <li>Pre-computed inverse homography for performance</li> </ul> Typical Workflow <ol> <li>Calibrate camera view to obtain HomographyCalibrator.calibrate_*()</li> <li>Create measurer with calibration data</li> <li>Detect objects with vision model (YOLO, etc.)</li> <li>Measure physical dimensions from bounding boxes</li> <li>Apply size-based filtering or quality control</li> </ol> <p>Usage::</p> <pre><code>from mindtrace.hardware import HomographyCalibrator, HomographyMeasurer\nfrom mindtrace.core.types import BoundingBox\n\n# One-time calibration\ncalibrator = HomographyCalibrator()\ncalibration = calibrator.calibrate_checkerboard(\n    image=checkerboard_image,\n    board_size=(12, 12),\n    square_size=25.0,\n    world_unit=\"mm\"\n)\n\n# Create measurer (reuse for all measurements)\nmeasurer = HomographyMeasurer(calibration)\n\n# Measure objects from detection results\ndetections = yolo.detect(frame)  # List[BoundingBox]\nmeasurements = measurer.measure_bounding_boxes(detections, target_unit=\"cm\")\n\nfor measured in measurements:\n    print(f\"Width: {measured.width_world:.2f} cm\")\n    print(f\"Height: {measured.height_world:.2f} cm\")\n    print(f\"Area: {measured.area_world:.2f} cm\u00b2\")\n\n    # Size-based filtering\n    if measured.width_world &gt; 10.0:\n        reject_oversized_part(measured)\n</code></pre> Configuration <ul> <li>Supported units: mm, cm, m, in, ft (configurable via hardware config)</li> <li>Default world unit: Inherited from calibration data</li> </ul> Limitations <ul> <li>Only works for planar surfaces (Z=0 assumption)</li> <li>Accuracy depends on calibration quality and viewing angle</li> <li>Assumes objects lie flat on the calibrated plane</li> <li>Camera must remain fixed after calibration</li> </ul> <p>Initialize homography measurer with calibration data.</p> <p>Parameters:</p> Name Type Description Default <code>calibration</code> <code>CalibrationData</code> <p>CalibrationData from HomographyCalibrator</p> required <code>**kwargs</code> <p>Additional arguments passed to Mindtrace base class</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If homography matrix is invalid</p> pixels_to_world <pre><code>pixels_to_world(points_px: ndarray) -&gt; np.ndarray\n</code></pre> <p>Project pixel coordinates to world plane coordinates.</p> <p>Maps Nx2 pixel coordinates to world plane coordinates using the inverse homography matrix H\u207b\u00b9. This is the core projection operation for all measurement functionality.</p> <p>Parameters:</p> Name Type Description Default <code>points_px</code> <code>ndarray</code> <p>Nx2 array of pixel coordinates (u, v)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Nx2 array of world coordinates (X, Y) in calibration world unit</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If input array has wrong shape</p> <p>Example::</p> <pre><code># Project single point\nworld_point = measurer.pixels_to_world(np.array([[320, 240]]))\n\n# Project multiple points\npixel_corners = np.array([[100, 50], [500, 50], [500, 400], [100, 400]])\nworld_corners = measurer.pixels_to_world(pixel_corners)\n</code></pre> measure_bounding_box <pre><code>measure_bounding_box(\n    box: BoundingBox, target_unit: Optional[str] = None\n) -&gt; MeasuredBox\n</code></pre> <p>Measure physical dimensions of a bounding box on the calibrated plane.</p> <p>Projects the four corners of a pixel-space bounding box to world coordinates, then computes width, height, and area in the specified unit.</p> <p>Parameters:</p> Name Type Description Default <code>box</code> <code>BoundingBox</code> <p>BoundingBox from object detection (x, y, width, height in pixels)</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output measurements (e.g., 'cm', 'm').         Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MeasuredBox</code> <p>MeasuredBox with physical dimensions and corner coordinates</p> <p>Example::</p> <pre><code># From object detection\ndetection = BoundingBox(x=100, y=50, width=400, height=350)\nmeasured = measurer.measure_bounding_box(detection, target_unit=\"cm\")\n\nprint(f\"Object is {measured.width_world:.1f} \u00d7 {measured.height_world:.1f} cm\")\nprint(f\"Area: {measured.area_world:.1f} cm\u00b2\")\n</code></pre> measure_bounding_boxes <pre><code>measure_bounding_boxes(\n    boxes: Sequence[BoundingBox], target_unit: Optional[str] = None\n) -&gt; List[MeasuredBox]\n</code></pre> <p>Measure physical dimensions of multiple bounding boxes.</p> <p>Batch processing of multiple object detections. More efficient than calling measure_bounding_box() in a loop.</p> <p>Parameters:</p> Name Type Description Default <code>boxes</code> <code>Sequence[BoundingBox]</code> <p>Sequence of BoundingBox objects from object detection</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output measurements. Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[MeasuredBox]</code> <p>List of MeasuredBox objects with physical dimensions</p> <p>Example::</p> <pre><code># Batch measurement from multiple detections\ndetections = yolo.detect(frame)  # List[BoundingBox]\nmeasurements = measurer.measure_bounding_boxes(detections, target_unit=\"cm\")\n\n# Size-based filtering\nlarge_objects = [m for m in measurements if m.width_world &gt; 15.0]\n\n# Quality control\nfor measured in measurements:\n    if not (10.0 &lt;= measured.width_world &lt;= 20.0):\n        reject_part(measured)\n</code></pre> measure_distance <pre><code>measure_distance(\n    point1: Union[Tuple[float, float], ndarray],\n    point2: Union[Tuple[float, float], ndarray],\n    target_unit: Optional[str] = None,\n) -&gt; Tuple[float, str]\n</code></pre> <p>Measure Euclidean distance between two points on the calibrated plane.</p> <p>Converts pixel coordinates to world coordinates and computes the distance. Useful for measuring gaps, spacing, or verifying known distances.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>Union[Tuple[float, float], ndarray]</code> <p>First point as (x, y) pixel coordinates</p> required <code>point2</code> <code>Union[Tuple[float, float], ndarray]</code> <p>Second point as (x, y) pixel coordinates</p> required <code>target_unit</code> <code>Optional[str]</code> <p>Unit for output distance. Uses calibration unit if None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, str]</code> <p>Tuple of (distance, unit)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If target_unit is not supported</p> <p>Example::</p> <pre><code># Measure distance between two detected points\npoint1 = (150, 200)  # pixels\npoint2 = (350, 200)  # pixels\ndistance, unit = measurer.measure_distance(point1, point2, target_unit=\"mm\")\nprint(f\"Distance: {distance:.2f} {unit}\")\n\n# Verify calibration accuracy\nknown_distance_mm = 100.0\nmeasured_distance, _ = measurer.measure_distance(ref_point1, ref_point2, \"mm\")\nerror_percent = abs(measured_distance - known_distance_mm) / known_distance_mm * 100\nprint(f\"Calibration error: {error_percent:.2f}%\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup","title":"setup","text":"<p>Camera Setup Module</p> <p>This module provides setup scripts for various camera SDKs and utilities for configuring camera hardware in the Mindtrace system.</p> <p>Available CLI commands (after package installation):     mindtrace-camera-setup install      # Install all camera SDKs     mindtrace-camera-setup uninstall    # Uninstall all camera SDKs     mindtrace-camera-basler install     # Install Basler Pylon SDK     mindtrace-camera-basler uninstall   # Uninstall Basler Pylon SDK     mindtrace-camera-genicam install    # Install GenICam CTI files     mindtrace-camera-genicam uninstall  # Uninstall GenICam SDK     mindtrace-camera-genicam verify     # Verify GenICam installation</p> <p>Each setup script uses Typer for CLI and can be run independently.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.PylonSDKInstaller","title":"PylonSDKInstaller","text":"<pre><code>PylonSDKInstaller(package_path: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Basler Pylon SDK installer with guided wizard.</p> <p>This class provides an interactive installation wizard that guides users through downloading and installing the Basler Pylon SDK from the official Basler website.</p> <p>Initialize the Pylon SDK installer.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>Optional[str]</code> <p>Optional path to pre-downloaded package file</p> <code>None</code> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Pylon SDK using interactive wizard or pre-downloaded package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Pylon SDK.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.CameraSystemSetup","title":"CameraSystemSetup","text":"<pre><code>CameraSystemSetup()\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Unified camera system setup and configuration manager.</p> <p>This class handles the installation and configuration of all camera SDKs and related network settings for the Mindtrace hardware system.</p> <p>Initialize the camera system setup manager.</p> install_all_sdks <pre><code>install_all_sdks(release_version: str = 'v1.0-stable') -&gt; bool\n</code></pre> <p>Install all camera SDKs.</p> <p>Parameters:</p> Name Type Description Default <code>release_version</code> <code>str</code> <p>SDK release version to install</p> <code>'v1.0-stable'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if all installations successful, False otherwise</p> uninstall_all_sdks <pre><code>uninstall_all_sdks() -&gt; bool\n</code></pre> <p>Uninstall all camera SDKs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all uninstallations successful, False otherwise</p> configure_firewall <pre><code>configure_firewall(ip_range: Optional[str] = None) -&gt; bool\n</code></pre> <p>Configure firewall rules to allow camera communication.</p> <p>This method configures platform-specific firewall rules to allow communication with GigE Vision cameras on the specified IP range.</p> <p>Parameters:</p> Name Type Description Default <code>ip_range</code> <code>Optional[str]</code> <p>IP range to allow (uses config default if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if firewall configuration successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.GenICamCTIInstaller","title":"GenICamCTIInstaller","text":"<pre><code>GenICamCTIInstaller(release_version: str = 'latest')\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Matrix Vision GenICam CTI installer and manager.</p> <p>This class handles the download, installation, and uninstallation of the Matrix Vision Impact Acquire SDK and GenTL Producer across different platforms.</p> <p>Initialize the GenICam CTI installer.</p> <p>Parameters:</p> Name Type Description Default <code>release_version</code> <code>str</code> <p>SDK release version to download</p> <code>'latest'</code> get_cti_path <pre><code>get_cti_path() -&gt; str\n</code></pre> <p>Get the expected CTI file path for the current platform.</p> <p>Returns:</p> Type Description <code>str</code> <p>Path to the CTI file for the current platform</p> verify_installation <pre><code>verify_installation() -&gt; bool\n</code></pre> <p>Verify that the CTI file is properly installed.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if CTI file exists and is accessible, False otherwise</p> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Matrix Vision Impact Acquire SDK for the current platform.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Impact Acquire SDK.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.configure_firewall_helper","title":"configure_firewall_helper","text":"<pre><code>configure_firewall_helper(ip_range: Optional[str] = None) -&gt; bool\n</code></pre> <p>Configure firewall rules to allow camera communication.</p> <p>This function provides a simple interface to configure firewall rules for camera network communication. It works on both Windows and Linux.</p> <p>Parameters:</p> Name Type Description Default <code>ip_range</code> <code>Optional[str]</code> <p>IP range to allow (uses config default if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if firewall configuration successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.setup_basler","title":"setup_basler","text":"<p>Basler Pylon SDK Setup Script</p> <p>This script provides a guided installation wizard for the Basler Pylon SDK for both Linux and Windows systems. The Pylon SDK provides tools like Pylon Viewer and IP Configurator for camera management.</p> <p>Note: pypylon (the Python package) is self-contained for camera operations. This SDK installation is only needed for the GUI tools.</p> <p>Features: - Interactive guided wizard with browser integration - Platform-specific installation instructions - Support for pre-downloaded packages (--package flag) - Comprehensive logging and error handling - Uninstallation support</p> Usage <p>python setup_basler.py                      # Interactive wizard python setup_basler.py --package /path/to/file  # Use pre-downloaded file python setup_basler.py --uninstall          # Uninstall SDK mindtrace-camera-basler-install            # Console script (install) mindtrace-camera-basler-uninstall          # Console script (uninstall)</p> PylonSDKInstaller <pre><code>PylonSDKInstaller(package_path: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Basler Pylon SDK installer with guided wizard.</p> <p>This class provides an interactive installation wizard that guides users through downloading and installing the Basler Pylon SDK from the official Basler website.</p> <p>Initialize the Pylon SDK installer.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>Optional[str]</code> <p>Optional path to pre-downloaded package file</p> <code>None</code> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Pylon SDK using interactive wizard or pre-downloaded package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Pylon SDK.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p> install <pre><code>install(\n    package: Optional[Path] = typer.Option(\n        None,\n        \"--package\",\n        \"-p\",\n        help=\"Path to pre-downloaded Pylon SDK package file\",\n        exists=True,\n        dir_okay=False,\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Install the Basler Pylon SDK using an interactive wizard.</p> <p>The wizard will guide you through downloading and installing the SDK from Basler's official website where you'll accept their EULA.</p> <p>For CI/automation, use --package to provide a pre-downloaded file.</p> uninstall <pre><code>uninstall(\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    )\n) -&gt; None\n</code></pre> <p>Uninstall the Basler Pylon SDK.</p> main <pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the script.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.setup_cameras","title":"setup_cameras","text":"<p>Camera Setup and Configuration Script</p> <p>This script provides a unified interface for installing and configuring all camera SDKs and related network settings for the Mindtrace hardware system. It combines Basler SDK installation with firewall configuration for camera network communication.</p> <p>Features: - Combined installation of all camera SDKs (Basler Pylon, Matrix Vision GenICam CTI) - Firewall configuration for camera network communication - Cross-platform support (Windows, Linux, and macOS) - Individual SDK uninstallation support - Comprehensive logging and error handling - Configurable IP range and firewall settings - Integration with Mindtrace configuration system</p> Configuration <p>The script uses the Mindtrace hardware configuration system for default values. Settings can be customized via:</p> <ol> <li>Environment Variables:</li> <li>MINDTRACE_HW_NETWORK_CAMERA_IP_RANGE: IP range for firewall rules (default: 192.168.50.0/24)</li> <li> <p>MINDTRACE_HW_NETWORK_FIREWALL_RULE_NAME: Name for firewall rules (default: \"Allow Camera Network\")</p> </li> <li> <p>Configuration File (hardware_config.json):    {      \"network\": {        \"camera_ip_range\": \"192.168.50.0/24\",        \"firewall_rule_name\": \"Allow Camera Network\"      }    }</p> </li> <li> <p>Command Line Arguments (highest priority)</p> </li> </ol> Usage <p>python setup_cameras.py                           # Install all SDKs python setup_cameras.py --uninstall               # Uninstall all SDKs python setup_cameras.py --configure-firewall      # Configure firewall only python setup_cameras.py --ip-range 10.0.0.0/24   # Use custom IP range mindtrace-setup-cameras                            # Console script</p> Network Configuration <p>The script configures firewall rules to allow camera communication on the specified IP range. This is essential for GigE Vision cameras that communicate over Ethernet. The default IP range (192.168.50.0/24) follows industrial camera networking standards.</p> CameraSystemSetup <pre><code>CameraSystemSetup()\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Unified camera system setup and configuration manager.</p> <p>This class handles the installation and configuration of all camera SDKs and related network settings for the Mindtrace hardware system.</p> <p>Initialize the camera system setup manager.</p> install_all_sdks <pre><code>install_all_sdks(release_version: str = 'v1.0-stable') -&gt; bool\n</code></pre> <p>Install all camera SDKs.</p> <p>Parameters:</p> Name Type Description Default <code>release_version</code> <code>str</code> <p>SDK release version to install</p> <code>'v1.0-stable'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if all installations successful, False otherwise</p> uninstall_all_sdks <pre><code>uninstall_all_sdks() -&gt; bool\n</code></pre> <p>Uninstall all camera SDKs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all uninstallations successful, False otherwise</p> configure_firewall <pre><code>configure_firewall(ip_range: Optional[str] = None) -&gt; bool\n</code></pre> <p>Configure firewall rules to allow camera communication.</p> <p>This method configures platform-specific firewall rules to allow communication with GigE Vision cameras on the specified IP range.</p> <p>Parameters:</p> Name Type Description Default <code>ip_range</code> <code>Optional[str]</code> <p>IP range to allow (uses config default if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if firewall configuration successful, False otherwise</p> configure_firewall_helper <pre><code>configure_firewall_helper(ip_range: Optional[str] = None) -&gt; bool\n</code></pre> <p>Configure firewall rules to allow camera communication.</p> <p>This function provides a simple interface to configure firewall rules for camera network communication. It works on both Windows and Linux.</p> <p>Parameters:</p> Name Type Description Default <code>ip_range</code> <code>Optional[str]</code> <p>IP range to allow (uses config default if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if firewall configuration successful, False otherwise</p> install <pre><code>install(\n    version: str = typer.Option(\n        \"v1.0-stable\", \"--version\", help=\"SDK release version to install\"\n    ),\n    ip_range: Optional[str] = typer.Option(\n        None,\n        \"--ip-range\",\n        help=\"IP range to allow in firewall (uses config default if not specified)\",\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Install all camera SDKs and configure firewall.</p> <p>Installs Basler Pylon SDK and Matrix Vision GenICam CTI files, then configures firewall rules for GigE Vision camera communication.</p> uninstall <pre><code>uninstall(\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    )\n) -&gt; None\n</code></pre> <p>Uninstall all camera SDKs.</p> configure_firewall <pre><code>configure_firewall(\n    ip_range: Optional[str] = typer.Option(\n        None,\n        \"--ip-range\",\n        help=\"IP range to allow in firewall (uses config default if not specified)\",\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Configure firewall rules for camera network communication.</p> <p>Configures platform-specific firewall rules to allow GigE Vision camera communication on the specified IP range.</p> <p>Windows: Uses netsh advfirewall commands Linux:   Uses UFW (Uncomplicated Firewall)</p> main <pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the camera setup script.</p>"},{"location":"hardware/api/#mindtrace.hardware.cameras.setup.setup_genicam","title":"setup_genicam","text":"<p>Matrix Vision GenICam CTI Setup Script</p> <p>This script automates the download and installation of the Matrix Vision Impact Acquire SDK and GenTL Producer (CTI files) for Linux, Windows, and macOS. The CTI files are required for GenICam camera communication via Harvesters.</p> <p>Features: - Automatic SDK download from Matrix Vision or GitHub releases - Platform-specific installation (Linux .deb/.tar.gz, Windows .exe, macOS .dmg/.pkg) - CTI file detection and verification - Administrative privilege handling - Comprehensive logging and error handling - Uninstallation support - Harvesters CTI path configuration</p> <p>CTI File Locations: - Linux: /opt/ImpactAcquire/lib/x86_64/mvGenTLProducer.cti - Windows: C:\\Program Files\\MATRIX VISION\\mvIMPACT Acquire\\bin\\x64\\mvGenTLProducer.cti - macOS: /Applications/mvIMPACT_Acquire.app/Contents/Libraries/x86_64/mvGenTLProducer.cti</p> Usage <p>python setup_genicam.py                      # Install CTI files python setup_genicam.py --uninstall          # Uninstall SDK python setup_genicam.py --verify             # Verify CTI installation mindtrace-camera-genicam-install            # Console script (install) mindtrace-camera-genicam-uninstall          # Console script (uninstall) mindtrace-camera-genicam-verify             # Console script (verify)</p> GenICamCTIInstaller <pre><code>GenICamCTIInstaller(release_version: str = 'latest')\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Matrix Vision GenICam CTI installer and manager.</p> <p>This class handles the download, installation, and uninstallation of the Matrix Vision Impact Acquire SDK and GenTL Producer across different platforms.</p> <p>Initialize the GenICam CTI installer.</p> <p>Parameters:</p> Name Type Description Default <code>release_version</code> <code>str</code> <p>SDK release version to download</p> <code>'latest'</code> get_cti_path <pre><code>get_cti_path() -&gt; str\n</code></pre> <p>Get the expected CTI file path for the current platform.</p> <p>Returns:</p> Type Description <code>str</code> <p>Path to the CTI file for the current platform</p> verify_installation <pre><code>verify_installation() -&gt; bool\n</code></pre> <p>Verify that the CTI file is properly installed.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if CTI file exists and is accessible, False otherwise</p> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Matrix Vision Impact Acquire SDK for the current platform.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Impact Acquire SDK.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p> install_genicam_cti <pre><code>install_genicam_cti(release_version: str = 'latest') -&gt; bool\n</code></pre> <p>Install the Matrix Vision GenICam CTI files.</p> <p>Parameters:</p> Name Type Description Default <code>release_version</code> <code>str</code> <p>SDK release version to install</p> <code>'latest'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall_genicam_cti <pre><code>uninstall_genicam_cti() -&gt; bool\n</code></pre> <p>Uninstall the Matrix Vision Impact Acquire SDK.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p> verify_genicam_cti <pre><code>verify_genicam_cti() -&gt; bool\n</code></pre> <p>Verify the Matrix Vision CTI installation.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if CTI files are properly installed, False otherwise</p> install <pre><code>install(\n    version: str = typer.Option(\n        \"latest\", \"--version\", help=\"SDK release version to install\"\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Install the Matrix Vision Impact Acquire SDK and CTI files.</p> <p>Downloads and installs the SDK from the official Balluff/Matrix Vision servers. The CTI files are required for GenICam camera communication via Harvesters.</p> uninstall <pre><code>uninstall(\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    )\n) -&gt; None\n</code></pre> <p>Uninstall the Matrix Vision Impact Acquire SDK.</p> verify <pre><code>verify(\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    )\n) -&gt; None\n</code></pre> <p>Verify that CTI files are properly installed.</p> main <pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the script.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli","title":"cli","text":"<p>Mindtrace Hardware CLI - Command-line interface for hardware management.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands","title":"commands","text":"<p>CLI command modules.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands.status_command","title":"status_command","text":"<pre><code>status_command()\n</code></pre> <p>Show status of all hardware services.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands.camera","title":"camera","text":"<p>Camera service commands.</p> start <pre><code>start(\n    api_host: Annotated[\n        str,\n        Option(--api - host, help=\"API service host\", envvar=CAMERA_API_HOST),\n    ] = \"localhost\",\n    api_port: Annotated[\n        int,\n        Option(--api - port, help=\"API service port\", envvar=CAMERA_API_PORT),\n    ] = 8002,\n    include_mocks: Annotated[\n        bool, Option(--include - mocks, help=\"Include mock cameras\")\n    ] = False,\n    open_docs: Annotated[\n        bool, Option(--open - docs, help=\"Open API documentation in browser\")\n    ] = False,\n)\n</code></pre> <p>Start camera API service (headless).</p> stop <pre><code>stop()\n</code></pre> <p>Stop camera API service.</p> status <pre><code>status()\n</code></pre> <p>Show camera API service status.</p> logs <pre><code>logs()\n</code></pre> <p>View camera API service logs.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands.plc","title":"plc","text":"<p>PLC service commands.</p> start <pre><code>start(\n    api_host: Annotated[\n        str, Option(--api - host, help=\"API service host\", envvar=PLC_API_HOST)\n    ] = \"localhost\",\n    api_port: Annotated[\n        int, Option(--api - port, help=\"API service port\", envvar=PLC_API_PORT)\n    ] = 8003,\n)\n</code></pre> <p>Start PLC API service.</p> stop <pre><code>stop()\n</code></pre> <p>Stop PLC API service.</p> status <pre><code>status()\n</code></pre> <p>Show PLC service status.</p> logs <pre><code>logs()\n</code></pre> <p>View PLC service logs.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands.status","title":"status","text":"<p>Status command for all hardware services.</p> status_command <pre><code>status_command()\n</code></pre> <p>Show status of all hardware services.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.commands.stereo","title":"stereo","text":"<p>Stereo camera service commands.</p> start <pre><code>start(\n    api_host: Annotated[\n        str,\n        Option(\n            --api - host,\n            help=\"Stereo Camera API service host\",\n            envvar=STEREO_CAMERA_API_HOST,\n        ),\n    ] = \"localhost\",\n    api_port: Annotated[\n        int,\n        Option(\n            --api - port,\n            help=\"Stereo Camera API service port\",\n            envvar=STEREO_CAMERA_API_PORT,\n        ),\n    ] = 8004,\n    open_docs: Annotated[\n        bool, Option(--open - docs, help=\"Open API documentation in browser\")\n    ] = False,\n)\n</code></pre> <p>Start stereo camera API service.</p> stop <pre><code>stop()\n</code></pre> <p>Stop stereo camera API service.</p> status <pre><code>status()\n</code></pre> <p>Show stereo camera service status.</p> logs <pre><code>logs()\n</code></pre> <p>View stereo camera service logs.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.core","title":"core","text":"<p>Core CLI functionality.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.core.ProcessManager","title":"ProcessManager","text":"<pre><code>ProcessManager()\n</code></pre> <p>Manages hardware service processes.</p> <p>Initialize process manager.</p> load_pids <pre><code>load_pids()\n</code></pre> <p>Load saved PIDs from file.</p> save_pids <pre><code>save_pids()\n</code></pre> <p>Save PIDs to file.</p> start_camera_api <pre><code>start_camera_api(\n    host: str = None, port: int = None, include_mocks: bool = False\n) -&gt; subprocess.Popen\n</code></pre> <p>Launch camera API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: CAMERA_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: CAMERA_API_PORT env var or 8002)</p> <code>None</code> <code>include_mocks</code> <code>bool</code> <p>Include mock cameras in discovery</p> <code>False</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> start_plc_api <pre><code>start_plc_api(host: str = None, port: int = None) -&gt; subprocess.Popen\n</code></pre> <p>Launch PLC API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: PLC_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: PLC_API_PORT env var or 8003)</p> <code>None</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> start_stereo_camera_api <pre><code>start_stereo_camera_api(host: str = None, port: int = None) -&gt; subprocess.Popen\n</code></pre> <p>Launch Stereo Camera API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: STEREO_CAMERA_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: STEREO_CAMERA_API_PORT env var or 8004)</p> <code>None</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> stop_service <pre><code>stop_service(service_name: str) -&gt; bool\n</code></pre> <p>Stop a service by name.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>Name of the service to stop</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if stopped successfully</p> stop_all <pre><code>stop_all()\n</code></pre> <p>Stop all running services.</p> get_status <pre><code>get_status() -&gt; Dict[str, Any]\n</code></pre> <p>Get status of all services.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with service status information</p> is_service_running <pre><code>is_service_running(service_name: str) -&gt; bool\n</code></pre> <p>Check if a specific service is running.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>Name of the service</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the service is running</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.core.setup_logger","title":"setup_logger","text":"<pre><code>setup_logger(\n    name: str = \"mindtrace-hw-cli\",\n    log_file: Optional[Path] = None,\n    verbose: bool = False,\n) -&gt; logging.Logger\n</code></pre> <p>Set up logger for the CLI.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Logger name</p> <code>'mindtrace-hw-cli'</code> <code>log_file</code> <code>Optional[Path]</code> <p>Optional log file path</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Enable verbose logging</p> <code>False</code> <p>Returns:</p> Type Description <code>Logger</code> <p>Configured logger instance</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.core.logger","title":"logger","text":"<p>Logging configuration for the CLI using Rich.</p> RichLogger <pre><code>RichLogger(console: Optional[Console] = None)\n</code></pre> <p>Logger that uses Rich Console for professional output.</p> <p>Initialize RichLogger.</p> <p>Parameters:</p> Name Type Description Default <code>console</code> <code>Optional[Console]</code> <p>Optional Rich Console instance. Creates new one if not provided.</p> <code>None</code> info <pre><code>info(message: str)\n</code></pre> <p>Log info message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message to log</p> required success <pre><code>success(message: str)\n</code></pre> <p>Log success message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Success message to log</p> required warning <pre><code>warning(message: str)\n</code></pre> <p>Log warning message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Warning message to log</p> required error <pre><code>error(message: str)\n</code></pre> <p>Log error message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message to log</p> required progress <pre><code>progress(message: str)\n</code></pre> <p>Log progress message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Progress message to log</p> required setup_logger <pre><code>setup_logger(\n    name: str = \"mindtrace-hw-cli\",\n    log_file: Optional[Path] = None,\n    verbose: bool = False,\n) -&gt; logging.Logger\n</code></pre> <p>Set up logger for the CLI.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Logger name</p> <code>'mindtrace-hw-cli'</code> <code>log_file</code> <code>Optional[Path]</code> <p>Optional log file path</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Enable verbose logging</p> <code>False</code> <p>Returns:</p> Type Description <code>Logger</code> <p>Configured logger instance</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.core.process_manager","title":"process_manager","text":"<p>Process management for hardware services.</p> ProcessManager <pre><code>ProcessManager()\n</code></pre> <p>Manages hardware service processes.</p> <p>Initialize process manager.</p> load_pids <pre><code>load_pids()\n</code></pre> <p>Load saved PIDs from file.</p> save_pids <pre><code>save_pids()\n</code></pre> <p>Save PIDs to file.</p> start_camera_api <pre><code>start_camera_api(\n    host: str = None, port: int = None, include_mocks: bool = False\n) -&gt; subprocess.Popen\n</code></pre> <p>Launch camera API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: CAMERA_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: CAMERA_API_PORT env var or 8002)</p> <code>None</code> <code>include_mocks</code> <code>bool</code> <p>Include mock cameras in discovery</p> <code>False</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> start_plc_api <pre><code>start_plc_api(host: str = None, port: int = None) -&gt; subprocess.Popen\n</code></pre> <p>Launch PLC API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: PLC_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: PLC_API_PORT env var or 8003)</p> <code>None</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> start_stereo_camera_api <pre><code>start_stereo_camera_api(host: str = None, port: int = None) -&gt; subprocess.Popen\n</code></pre> <p>Launch Stereo Camera API service.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to bind the service to (default: STEREO_CAMERA_API_HOST env var or 'localhost')</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to run the service on (default: STEREO_CAMERA_API_PORT env var or 8004)</p> <code>None</code> <p>Returns:</p> Type Description <code>Popen</code> <p>The subprocess handle</p> stop_service <pre><code>stop_service(service_name: str) -&gt; bool\n</code></pre> <p>Stop a service by name.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>Name of the service to stop</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if stopped successfully</p> stop_all <pre><code>stop_all()\n</code></pre> <p>Stop all running services.</p> get_status <pre><code>get_status() -&gt; Dict[str, Any]\n</code></pre> <p>Get status of all services.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with service status information</p> is_service_running <pre><code>is_service_running(service_name: str) -&gt; bool\n</code></pre> <p>Check if a specific service is running.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>Name of the service</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the service is running</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils","title":"utils","text":"<p>CLI utility functions.</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.format_status","title":"format_status","text":"<pre><code>format_status(status: Dict[str, Any]) -&gt; None\n</code></pre> <p>Format and display service status.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>Dict[str, Any]</code> <p>Status dictionary from ProcessManager</p> required"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.print_table","title":"print_table","text":"<pre><code>print_table(data: List[Dict[str, Any]], headers: Optional[List[str]] = None)\n</code></pre> <p>Print data as a formatted table.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>List of dictionaries to display</p> required <code>headers</code> <code>Optional[List[str]]</code> <p>Optional header names</p> <code>None</code>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.check_port_available","title":"check_port_available","text":"<pre><code>check_port_available(host: str, port: int) -&gt; bool\n</code></pre> <p>Check if a port is available for binding.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to check</p> required <code>port</code> <code>int</code> <p>Port number to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if port is available, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.get_free_port","title":"get_free_port","text":"<pre><code>get_free_port(\n    host: str = \"localhost\", start_port: int = 8000, end_port: int = 9000\n) -&gt; Optional[int]\n</code></pre> <p>Find a free port in the given range.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to check</p> <code>'localhost'</code> <code>start_port</code> <code>int</code> <p>Starting port number</p> <code>8000</code> <code>end_port</code> <code>int</code> <p>Ending port number</p> <code>9000</code> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Free port number or None if no free port found</p>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.display","title":"display","text":"<p>Display utilities for CLI output using Rich.</p> format_status <pre><code>format_status(status: Dict[str, Any]) -&gt; None\n</code></pre> <p>Format and display service status.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>Dict[str, Any]</code> <p>Status dictionary from ProcessManager</p> required print_table <pre><code>print_table(data: List[Dict[str, Any]], headers: Optional[List[str]] = None)\n</code></pre> <p>Print data as a formatted table.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Dict[str, Any]]</code> <p>List of dictionaries to display</p> required <code>headers</code> <code>Optional[List[str]]</code> <p>Optional header names</p> <code>None</code> print_service_box <pre><code>print_service_box(title: str, services: Dict[str, Dict[str, Any]])\n</code></pre> <p>Print services in a nice panel format.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Panel title</p> required <code>services</code> <code>Dict[str, Dict[str, Any]]</code> <p>Service information dictionary</p> required show_banner <pre><code>show_banner()\n</code></pre> <p>Display the CLI banner.</p> print_list <pre><code>print_list(items: List[str], title: Optional[str] = None, style: str = 'white')\n</code></pre> <p>Print a list of items.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>List[str]</code> <p>List of strings to display</p> required <code>title</code> <code>Optional[str]</code> <p>Optional title for the list</p> <code>None</code> <code>style</code> <code>str</code> <p>Rich style for items</p> <code>'white'</code>"},{"location":"hardware/api/#mindtrace.hardware.cli.utils.network","title":"network","text":"<p>Network utilities for the CLI.</p> check_port_available <pre><code>check_port_available(host: str, port: int) -&gt; bool\n</code></pre> <p>Check if a port is available for binding.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to check</p> required <code>port</code> <code>int</code> <p>Port number to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if port is available, False otherwise</p> get_free_port <pre><code>get_free_port(\n    host: str = \"localhost\", start_port: int = 8000, end_port: int = 9000\n) -&gt; Optional[int]\n</code></pre> <p>Find a free port in the given range.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Host to check</p> <code>'localhost'</code> <code>start_port</code> <code>int</code> <p>Starting port number</p> <code>8000</code> <code>end_port</code> <code>int</code> <p>Ending port number</p> <code>9000</code> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Free port number or None if no free port found</p> wait_for_service <pre><code>wait_for_service(host: str, port: int, timeout: int = 30) -&gt; bool\n</code></pre> <p>Wait for a service to become available.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>Service host</p> required <code>port</code> <code>int</code> <p>Service port</p> required <code>timeout</code> <code>int</code> <p>Maximum time to wait in seconds</p> <code>30</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if service became available, False if timeout</p> get_local_ip <pre><code>get_local_ip() -&gt; str\n</code></pre> <p>Get the local IP address of the machine.</p> <p>Returns:</p> Type Description <code>str</code> <p>Local IP address string</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs","title":"plcs","text":"<p>PLC module for Mindtrace hardware system.</p> <p>Provides unified interface for managing PLCs from different manufacturers with support for discovery, registration, and batch operations.</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager","title":"PLCManager","text":"<pre><code>PLCManager()\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Unified PLC management system for industrial automation.</p> <p>This manager provides a comprehensive interface for managing PLCs from different manufacturers with support for discovery, registration, connection management, and batch tag operations. It handles multiple PLC backends transparently and provides thread-safe operations with proper error handling.</p> <p>The manager supports: - Automatic PLC discovery across multiple backends - Dynamic PLC registration and connection management - Batch tag read/write operations for optimal performance - Connection monitoring and automatic reconnection - Comprehensive error handling and logging - Thread-safe operations with proper resource management</p> <p>Supported PLC Types: - Allen-Bradley: ControlLogix, CompactLogix, MicroLogix PLCs - Siemens: S7-300, S7-400, S7-1200, S7-1500 PLCs (Future) - Modbus: Modbus TCP/RTU devices (Future) - Mock PLCs: For testing and development</p> <p>Attributes:</p> Name Type Description <code>plcs</code> <code>Dict[str, BasePLC]</code> <p>Dictionary mapping PLC names to PLC instances</p> <code>config</code> <p>Hardware configuration manager instance</p> <code>logger</code> <p>Centralized logger for PLC operations</p> Example <p>Initialize the PLC manager.</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager--basic-usage","title":"Basic usage","text":"<p>async with PLCManager() as manager:     # Discover available PLCs     discovered = await manager.discover_plcs()</p> <pre><code># Register and connect to a PLC\nawait manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")\nawait manager.connect_plc(\"PLC1\")\n\n# Read and write tags\nvalues = await manager.read_tag(\"PLC1\", [\"Temperature\", \"Pressure\"])\nawait manager.write_tag(\"PLC1\", [(\"Setpoint\", 75.0)])\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager--batch-operations","title":"Batch operations","text":"<p>async with PLCManager() as manager:     # Register multiple PLCs     await manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")     await manager.register_plc(\"PLC2\", \"AllenBradley\", \"192.168.1.101\")</p> <pre><code># Batch read from multiple PLCs\nread_requests = [\n    (\"PLC1\", [\"Temperature\", \"Pressure\"]),\n    (\"PLC2\", [\"Speed\", \"Position\"])\n]\nresults = await manager.read_tags_batch(read_requests)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.discover_plcs","title":"discover_plcs  <code>async</code>","text":"<pre><code>discover_plcs() -&gt; Dict[str, List[str]]\n</code></pre> <p>Discover available PLCs from all enabled backends.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dictionary mapping backend names to lists of discovered PLCs</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.register_plc","title":"register_plc  <code>async</code>","text":"<pre><code>register_plc(\n    plc_name: str,\n    backend: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    **kwargs\n) -&gt; bool\n</code></pre> <p>Register a PLC with the manager.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>backend</code> <code>str</code> <p>Backend type (\"AllenBradley\", \"Siemens\", \"Modbus\")</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>Specific PLC type (backend-dependent)</p> <code>None</code> <code>**kwargs</code> <p>Additional backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if registration successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.unregister_plc","title":"unregister_plc  <code>async</code>","text":"<pre><code>unregister_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Unregister a PLC from the manager.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to unregister</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if unregistration successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.connect_plc","title":"connect_plc  <code>async</code>","text":"<pre><code>connect_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Connect to a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to connect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.disconnect_plc","title":"disconnect_plc  <code>async</code>","text":"<pre><code>disconnect_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Disconnect from a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to disconnect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.connect_all_plcs","title":"connect_all_plcs  <code>async</code>","text":"<pre><code>connect_all_plcs() -&gt; Dict[str, bool]\n</code></pre> <p>Connect to all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping PLC names to connection success status</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.disconnect_all_plcs","title":"disconnect_all_plcs  <code>async</code>","text":"<pre><code>disconnect_all_plcs() -&gt; Dict[str, bool]\n</code></pre> <p>Disconnect from all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping PLC names to disconnection success status</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.read_tag","title":"read_tag  <code>async</code>","text":"<pre><code>read_tag(plc_name: str, tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tags from a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.write_tag","title":"write_tag  <code>async</code>","text":"<pre><code>write_tag(\n    plc_name: str, tags: Union[Tuple[str, Any], List[Tuple[str, Any]]]\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tags to a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.read_tags_batch","title":"read_tags_batch  <code>async</code>","text":"<pre><code>read_tags_batch(\n    requests: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[str, List[str]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their tag read results</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.write_tags_batch","title":"write_tags_batch  <code>async</code>","text":"<pre><code>write_tags_batch(\n    requests: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; Dict[str, Dict[str, bool]]\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, bool]]</code> <p>Dictionary mapping PLC names to their tag write results</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.get_plc_status","title":"get_plc_status  <code>async</code>","text":"<pre><code>get_plc_status(plc_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get status information for a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC status information</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.get_all_plc_status","title":"get_all_plc_status  <code>async</code>","text":"<pre><code>get_all_plc_status() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get status information for all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their status information</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.get_plc_tags","title":"get_plc_tags  <code>async</code>","text":"<pre><code>get_plc_tags(plc_name: str) -&gt; List[str]\n</code></pre> <p>Get list of available tags for a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available tag names</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.get_registered_plcs","title":"get_registered_plcs","text":"<pre><code>get_registered_plcs() -&gt; List[str]\n</code></pre> <p>Get list of registered PLC names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of registered PLC names</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.get_backend_info","title":"get_backend_info","text":"<pre><code>get_backend_info() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get information about available PLC backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping backend names to their information</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.PLCManager.cleanup","title":"cleanup  <code>async</code>","text":"<pre><code>cleanup()\n</code></pre> <p>Clean up all PLC connections and resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.backends","title":"backends","text":"<p>PLC backends for different manufacturers and protocols.</p> <p>This module contains implementations for various PLC types including Allen Bradley, Siemens, Modbus, and other industrial protocols.</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.backends.allen_bradley","title":"allen_bradley","text":"<p>Allen Bradley PLC Backend.</p> <p>Implements PLC communication for Allen Bradley PLCs using the pycomm3 library.</p> AllenBradleyPLC <pre><code>AllenBradleyPLC(\n    plc_name: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    plc_config_file: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n)\n</code></pre> <p>               Bases: <code>BasePLC</code></p> <p>Allen Bradley PLC implementation using pycomm3.</p> <p>Supports multiple PLC types and Ethernet/IP devices: - ControlLogix, CompactLogix, Micro800 (LogixDriver) - SLC500, MicroLogix (SLCDriver) - Generic Ethernet/IP devices (CIPDriver)</p> <p>Attributes:</p> Name Type Description <code>plc</code> <p>pycomm3 driver instance (LogixDriver, SLCDriver, or CIPDriver)</p> <code>driver_type</code> <p>Type of driver being used</p> <code>plc_type</code> <p>Type of PLC (auto-detected or specified)</p> <code>_tags_cache</code> <code>Optional[List[str]]</code> <p>Cached list of available tags</p> <code>_cache_timestamp</code> <code>float</code> <p>Timestamp of last tag cache update</p> <code>_cache_ttl</code> <code>float</code> <p>Time-to-live for tag cache in seconds</p> <p>Initialize Allen Bradley PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>PLC type ('logix', 'slc', 'cip', or 'auto' for auto-detection)</p> <code>None</code> <code>plc_config_file</code> <code>Optional[str]</code> <p>Path to PLC configuration file</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pycomm3 is not installed</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the Allen Bradley PLC connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success, plc_object, device_manager)</p> connect <code>async</code> <pre><code>connect() -&gt; bool\n</code></pre> <p>Establish connection to the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; bool\n</code></pre> <p>Disconnect from the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> is_connected <code>async</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if Allen Bradley PLC is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p> read_tag <code>async</code> <pre><code>read_tag(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read values from Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> <p>Raises:</p> Type Description <code>PLCTagReadError</code> <p>If tag reading fails</p> write_tag <code>async</code> <pre><code>write_tag(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write values to Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> <p>Raises:</p> Type Description <code>PLCTagWriteError</code> <p>If tag writing fails</p> get_all_tags <code>async</code> <pre><code>get_all_tags() -&gt; List[str]\n</code></pre> <p>Get list of all available tags on the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(tag_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>tag_name</code> <code>str</code> <p>Name of the tag</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with tag information (type, description, etc.)</p> get_plc_info <code>async</code> <pre><code>get_plc_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about the connected PLC using proper pycomm3 methods.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC information</p> get_available_plcs <code>staticmethod</code> <pre><code>get_available_plcs() -&gt; List[str]\n</code></pre> <p>Discover available Allen Bradley PLCs using proper pycomm3 discovery methods.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers in format \"AllenBradley:IP:Type\"</p> get_backend_info <code>staticmethod</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the Allen Bradley PLC backend.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with backend information</p> MockAllenBradleyPLC <pre><code>MockAllenBradleyPLC(\n    plc_name: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    plc_config_file: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n)\n</code></pre> <p>               Bases: <code>BasePLC</code></p> <p>Mock implementation of Allen Bradley PLC for testing and development.</p> <p>This class provides a complete simulation of the Allen Bradley PLC API without requiring actual hardware. It simulates all three driver types and provides realistic tag behavior for comprehensive testing.</p> <p>Attributes:</p> Name Type Description <code>plc_name</code> <p>User-defined PLC identifier</p> <code>ip_address</code> <p>Simulated IP address</p> <code>plc_type</code> <p>PLC type (\"logix\", \"slc\", \"cip\", or \"auto\")</p> <code>driver_type</code> <p>Detected/simulated driver type</p> <code>_is_connected</code> <p>Connection status simulation</p> <code>_tag_values</code> <code>Dict[str, Any]</code> <p>Simulated tag values storage</p> <code>_tag_types</code> <code>Dict[str, str]</code> <p>Tag type mapping for different driver types</p> <code>_cache_ttl</code> <p>Tag cache time-to-live</p> <code>_tags_cache</code> <code>Optional[List[str]]</code> <p>Cached list of available tags</p> <code>_cache_timestamp</code> <code>float</code> <p>Timestamp of last cache update</p> <p>Initialize mock Allen Bradley PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>ip_address</code> <code>str</code> <p>Simulated IP address</p> required <code>plc_type</code> <code>Optional[str]</code> <p>PLC type ('logix', 'slc', 'cip', or 'auto' for auto-detection)</p> <code>None</code> <code>plc_config_file</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock Allen Bradley PLC connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success, mock_plc_object, mock_device_manager)</p> connect <code>async</code> <pre><code>connect() -&gt; bool\n</code></pre> <p>Simulate connection to the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; bool\n</code></pre> <p>Simulate disconnection from the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> is_connected <code>async</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if mock Allen Bradley PLC is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p> read_tag <code>async</code> <pre><code>read_tag(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Simulate reading values from Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tag <code>async</code> <pre><code>write_tag(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Simulate writing values to Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> get_all_tags <code>async</code> <pre><code>get_all_tags() -&gt; List[str]\n</code></pre> <p>Get list of all available mock tags.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(tag_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a mock tag.</p> <p>Parameters:</p> Name Type Description Default <code>tag_name</code> <code>str</code> <p>Name of the tag</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with tag information</p> get_plc_info <code>async</code> <pre><code>get_plc_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about the mock PLC.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC information</p> get_available_plcs <code>staticmethod</code> <pre><code>get_available_plcs() -&gt; List[str]\n</code></pre> <p>Discover available mock Allen Bradley PLCs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers in format \"AllenBradley:IP:Type\"</p> get_backend_info <code>staticmethod</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the mock Allen Bradley PLC backend.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with backend information</p> allen_bradley_plc <p>Allen Bradley PLC implementation using pycomm3.</p> <p>Provides communication interface for Allen Bradley PLCs and other Ethernet/IP devices using CIPDriver, LogixDriver, and SLCDriver from pycomm3 library.</p> AllenBradleyPLC <pre><code>AllenBradleyPLC(\n    plc_name: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    plc_config_file: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n)\n</code></pre> <p>               Bases: <code>BasePLC</code></p> <p>Allen Bradley PLC implementation using pycomm3.</p> <p>Supports multiple PLC types and Ethernet/IP devices: - ControlLogix, CompactLogix, Micro800 (LogixDriver) - SLC500, MicroLogix (SLCDriver) - Generic Ethernet/IP devices (CIPDriver)</p> <p>Attributes:</p> Name Type Description <code>plc</code> <p>pycomm3 driver instance (LogixDriver, SLCDriver, or CIPDriver)</p> <code>driver_type</code> <p>Type of driver being used</p> <code>plc_type</code> <p>Type of PLC (auto-detected or specified)</p> <code>_tags_cache</code> <code>Optional[List[str]]</code> <p>Cached list of available tags</p> <code>_cache_timestamp</code> <code>float</code> <p>Timestamp of last tag cache update</p> <code>_cache_ttl</code> <code>float</code> <p>Time-to-live for tag cache in seconds</p> <p>Initialize Allen Bradley PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>PLC type ('logix', 'slc', 'cip', or 'auto' for auto-detection)</p> <code>None</code> <code>plc_config_file</code> <code>Optional[str]</code> <p>Path to PLC configuration file</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pycomm3 is not installed</p> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the Allen Bradley PLC connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success, plc_object, device_manager)</p> connect <code>async</code> <pre><code>connect() -&gt; bool\n</code></pre> <p>Establish connection to the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; bool\n</code></pre> <p>Disconnect from the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> is_connected <code>async</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if Allen Bradley PLC is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p> read_tag <code>async</code> <pre><code>read_tag(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read values from Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> <p>Raises:</p> Type Description <code>PLCTagReadError</code> <p>If tag reading fails</p> write_tag <code>async</code> <pre><code>write_tag(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write values to Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> <p>Raises:</p> Type Description <code>PLCTagWriteError</code> <p>If tag writing fails</p> get_all_tags <code>async</code> <pre><code>get_all_tags() -&gt; List[str]\n</code></pre> <p>Get list of all available tags on the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(tag_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>tag_name</code> <code>str</code> <p>Name of the tag</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with tag information (type, description, etc.)</p> get_plc_info <code>async</code> <pre><code>get_plc_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about the connected PLC using proper pycomm3 methods.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC information</p> get_available_plcs <code>staticmethod</code> <pre><code>get_available_plcs() -&gt; List[str]\n</code></pre> <p>Discover available Allen Bradley PLCs using proper pycomm3 discovery methods.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers in format \"AllenBradley:IP:Type\"</p> get_backend_info <code>staticmethod</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the Allen Bradley PLC backend.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with backend information</p> mock_allen_bradley <p>Mock Allen Bradley PLC Implementation</p> <p>This module provides a mock implementation of Allen Bradley PLCs for testing and development without requiring actual hardware or the pycomm3 SDK.</p> Features <ul> <li>Complete simulation of all three driver types (Logix, SLC, CIP)</li> <li>Realistic tag data generation and management</li> <li>Configurable number of mock PLCs</li> <li>Error simulation capabilities for testing</li> <li>No hardware dependencies</li> </ul> Components <ul> <li>MockAllenBradleyPLC: Mock PLC implementation</li> </ul> Usage <p>from mindtrace.hardware.plcs.backends.allen_bradley import MockAllenBradleyPLC</p> MockAllenBradleyPLC <pre><code>MockAllenBradleyPLC(\n    plc_name: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    plc_config_file: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n)\n</code></pre> <p>               Bases: <code>BasePLC</code></p> <p>Mock implementation of Allen Bradley PLC for testing and development.</p> <p>This class provides a complete simulation of the Allen Bradley PLC API without requiring actual hardware. It simulates all three driver types and provides realistic tag behavior for comprehensive testing.</p> <p>Attributes:</p> Name Type Description <code>plc_name</code> <p>User-defined PLC identifier</p> <code>ip_address</code> <p>Simulated IP address</p> <code>plc_type</code> <p>PLC type (\"logix\", \"slc\", \"cip\", or \"auto\")</p> <code>driver_type</code> <p>Detected/simulated driver type</p> <code>_is_connected</code> <p>Connection status simulation</p> <code>_tag_values</code> <code>Dict[str, Any]</code> <p>Simulated tag values storage</p> <code>_tag_types</code> <code>Dict[str, str]</code> <p>Tag type mapping for different driver types</p> <code>_cache_ttl</code> <p>Tag cache time-to-live</p> <code>_tags_cache</code> <code>Optional[List[str]]</code> <p>Cached list of available tags</p> <code>_cache_timestamp</code> <code>float</code> <p>Timestamp of last cache update</p> <p>Initialize mock Allen Bradley PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>ip_address</code> <code>str</code> <p>Simulated IP address</p> required <code>plc_type</code> <code>Optional[str]</code> <p>PLC type ('logix', 'slc', 'cip', or 'auto' for auto-detection)</p> <code>None</code> <code>plc_config_file</code> <code>Optional[str]</code> <p>Path to configuration file (simulated)</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> initialize <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the mock Allen Bradley PLC connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success, mock_plc_object, mock_device_manager)</p> connect <code>async</code> <pre><code>connect() -&gt; bool\n</code></pre> <p>Simulate connection to the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; bool\n</code></pre> <p>Simulate disconnection from the Allen Bradley PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> is_connected <code>async</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if mock Allen Bradley PLC is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p> read_tag <code>async</code> <pre><code>read_tag(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Simulate reading values from Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tag <code>async</code> <pre><code>write_tag(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Simulate writing values to Allen Bradley PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> get_all_tags <code>async</code> <pre><code>get_all_tags() -&gt; List[str]\n</code></pre> <p>Get list of all available mock tags.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>async</code> <pre><code>get_tag_info(tag_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a mock tag.</p> <p>Parameters:</p> Name Type Description Default <code>tag_name</code> <code>str</code> <p>Name of the tag</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with tag information</p> get_plc_info <code>async</code> <pre><code>get_plc_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about the mock PLC.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC information</p> get_available_plcs <code>staticmethod</code> <pre><code>get_available_plcs() -&gt; List[str]\n</code></pre> <p>Discover available mock Allen Bradley PLCs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers in format \"AllenBradley:IP:Type\"</p> get_backend_info <code>staticmethod</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the mock Allen Bradley PLC backend.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with backend information</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.backends.allen_bradley.mock_allen_bradley--initialize-mock-plc","title":"Initialize mock PLC","text":"<p>plc = MockAllenBradleyPLC(\"TestPLC\", \"192.168.1.100\", plc_type=\"logix\")</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.backends.allen_bradley.mock_allen_bradley--use-exactly-like-real-plc","title":"Use exactly like real PLC","text":"<p>await plc.connect() tags = await plc.read_tag([\"Motor1_Speed\", \"Conveyor_Status\"]) await plc.write_tag([(\"Pump1_Command\", True)]) await plc.disconnect()</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.backends.base","title":"base","text":"<p>Abstract base classes for PLC implementations.</p> <p>This module defines the interface that all PLC backends must implement, providing a consistent API for PLC operations across different manufacturers and communication protocols.</p> Features <ul> <li>Abstract base class with comprehensive async PLC interface</li> <li>Consistent async pattern matching camera backends</li> <li>Type-safe method signatures with full type hints</li> <li>Configuration system integration</li> <li>Resource management and cleanup</li> <li>Default implementations for optional features</li> <li>Standardized constructor signature across all backends</li> <li>Retry logic with exponential backoff</li> <li>Connection management and monitoring</li> </ul> Usage <p>This is an abstract base class and cannot be instantiated directly. PLC backends should inherit from BasePLC and implement all abstract methods.</p> Example <p>class MyPLCBackend(BasePLC):     async def initialize(self) -&gt; Tuple[bool, Any, Any]:         # Implementation here         pass</p> <pre><code>async def connect(self) -&gt; bool:\n    # Implementation here\n    pass\n\nasync def read_tag(self, tags: Union[str, List[str]]) -&gt; Dict[str, Any]:\n    # Implementation here\n    pass\n\n# ... implement other abstract methods\n</code></pre> Backend Requirements <p>All PLC backends must implement the following abstract methods: - initialize(): Establish initial connection and setup - connect(): Connect to the PLC - disconnect(): Disconnect from the PLC - is_connected(): Check connection status - read_tag(): Read tag values from PLC - write_tag(): Write tag values to PLC - get_all_tags(): List all available tags - get_tag_info(): Get detailed tag information - get_available_plcs(): Static method for PLC discovery - get_backend_info(): Static method for backend information</p> Error Handling <p>Backends should raise appropriate exceptions from the PLC exception hierarchy: - PLCError: Base exception for all PLC-related errors - PLCNotFoundError: PLC not found during discovery - PLCConnectionError: Connection establishment or maintenance failures - PLCInitializationError: PLC initialization failures - PLCCommunicationError: Communication protocol errors - PLCTagError: Tag-related operation errors - PLCTimeoutError: Operation timeout errors - PLCConfigurationError: Configuration-related errors</p> BasePLC <pre><code>BasePLC(\n    plc_name: str,\n    ip_address: str,\n    plc_config_file: Optional[str] = None,\n    connection_timeout: Optional[float] = None,\n    read_timeout: Optional[float] = None,\n    write_timeout: Optional[float] = None,\n    retry_count: Optional[int] = None,\n    retry_delay: Optional[float] = None,\n)\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for PLC implementations.</p> <p>This class defines the interface that all PLC backends must implement to ensure consistent behavior across different manufacturers and protocols.</p> <p>Attributes:</p> Name Type Description <code>plc_name</code> <p>Unique identifier for the PLC instance</p> <code>plc_config_file</code> <p>Path to PLC-specific configuration file</p> <code>ip_address</code> <p>IP address of the PLC</p> <code>connection_timeout</code> <p>Connection timeout in seconds</p> <code>read_timeout</code> <p>Tag read timeout in seconds</p> <code>write_timeout</code> <p>Tag write timeout in seconds</p> <code>retry_count</code> <p>Number of retry attempts for operations</p> <code>retry_delay</code> <p>Delay between retry attempts in seconds</p> <code>plc</code> <p>The underlying PLC connection object</p> <code>device_manager</code> <p>Device-specific manager instance</p> <code>initialized</code> <p>Whether the PLC has been initialized</p> <p>Initialize the PLC instance.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_config_file</code> <code>Optional[str]</code> <p>Path to PLC configuration file</p> <code>None</code> <code>connection_timeout</code> <code>Optional[float]</code> <p>Connection timeout in seconds</p> <code>None</code> <code>read_timeout</code> <code>Optional[float]</code> <p>Tag read timeout in seconds</p> <code>None</code> <code>write_timeout</code> <code>Optional[float]</code> <p>Tag write timeout in seconds</p> <code>None</code> <code>retry_count</code> <code>Optional[int]</code> <p>Number of retry attempts</p> <code>None</code> <code>retry_delay</code> <code>Optional[float]</code> <p>Delay between retries in seconds</p> <code>None</code> initialize <code>abstractmethod</code> <code>async</code> <pre><code>initialize() -&gt; Tuple[bool, Any, Any]\n</code></pre> <p>Initialize the PLC connection.</p> <p>Returns:</p> Type Description <code>Tuple[bool, Any, Any]</code> <p>Tuple of (success, plc_object, device_manager)</p> connect <code>abstractmethod</code> <code>async</code> <pre><code>connect() -&gt; bool\n</code></pre> <p>Establish connection to the PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect <code>abstractmethod</code> <code>async</code> <pre><code>disconnect() -&gt; bool\n</code></pre> <p>Disconnect from the PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> is_connected <code>abstractmethod</code> <code>async</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if PLC is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p> read_tag <code>abstractmethod</code> <code>async</code> <pre><code>read_tag(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read values from PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tag <code>abstractmethod</code> <code>async</code> <pre><code>write_tag(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write values to PLC tags.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> get_all_tags <code>abstractmethod</code> <code>async</code> <pre><code>get_all_tags() -&gt; List[str]\n</code></pre> <p>Get list of all available tags on the PLC.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tag names</p> get_tag_info <code>abstractmethod</code> <code>async</code> <pre><code>get_tag_info(tag_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get detailed information about a specific tag.</p> <p>Parameters:</p> Name Type Description Default <code>tag_name</code> <code>str</code> <p>Name of the tag</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with tag information (type, description, etc.)</p> get_available_plcs <code>abstractmethod</code> <code>staticmethod</code> <pre><code>get_available_plcs() -&gt; List[str]\n</code></pre> <p>Discover available PLCs for this backend.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of PLC identifiers in format \"Backend:Identifier\"</p> get_backend_info <code>abstractmethod</code> <code>staticmethod</code> <pre><code>get_backend_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about this PLC backend.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with backend information</p> reconnect <code>async</code> <pre><code>reconnect() -&gt; bool\n</code></pre> <p>Attempt to reconnect to the PLC.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if reconnection successful, False otherwise</p> read_tag_with_retry <code>async</code> <pre><code>read_tag_with_retry(tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tags with retry mechanism.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> <p>Raises:</p> Type Description <code>PLCTagError</code> <p>If all retry attempts fail</p> write_tag_with_retry <code>async</code> <pre><code>write_tag_with_retry(\n    tags: Union[Tuple[str, Any], List[Tuple[str, Any]]],\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tags with retry mechanism.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> <p>Raises:</p> Type Description <code>PLCTagError</code> <p>If all retry attempts fail</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager","title":"plc_manager","text":"<p>Modern PLC Manager for Mindtrace Hardware System</p> <p>A comprehensive PLC management system that provides unified access to multiple PLC backends with async operations, proper resource management, and batch processing capabilities.</p> Key Features <ul> <li>Automatic PLC discovery and registration</li> <li>Unified interface for different PLC manufacturers</li> <li>Async operations with proper error handling</li> <li>Batch tag read/write operations</li> <li>Connection management and monitoring</li> <li>Thread-safe operations with proper locking</li> <li>Comprehensive configuration management</li> <li>Integrated logging and status reporting</li> </ul> Supported Backends <ul> <li>Allen-Bradley: ControlLogix, CompactLogix PLCs (pycomm3)</li> <li>Siemens: S7-300, S7-400, S7-1200, S7-1500 PLCs (python-snap7)</li> <li>Modbus: Modbus TCP/RTU devices (pymodbus)</li> <li>Mock backends for testing and development</li> </ul> Requirements <ul> <li>pycomm3: Allen-Bradley PLC communication</li> <li>python-snap7: Siemens PLC communication</li> <li>pymodbus: Modbus device communication</li> <li>asyncio: Async operations support</li> </ul> Installation <p>pip install pycomm3 python-snap7 pymodbus</p> Usage Configuration <p>All parameters are configurable via the hardware configuration system: - MINDTRACE_HW_PLC_AUTO_DISCOVERY: Enable automatic PLC discovery - MINDTRACE_HW_PLC_CONNECTION_TIMEOUT: Connection timeout in seconds - MINDTRACE_HW_PLC_READ_TIMEOUT: Tag read timeout in seconds - MINDTRACE_HW_PLC_WRITE_TIMEOUT: Tag write timeout in seconds - MINDTRACE_HW_PLC_RETRY_COUNT: Number of retry attempts - MINDTRACE_HW_PLC_MAX_CONCURRENT_CONNECTIONS: Maximum concurrent connections - MINDTRACE_HW_PLC_ALLEN_BRADLEY_ENABLED: Enable Allen-Bradley backend - MINDTRACE_HW_PLC_SIEMENS_ENABLED: Enable Siemens backend - MINDTRACE_HW_PLC_MODBUS_ENABLED: Enable Modbus backend</p> Error Handling <p>The module uses a comprehensive exception hierarchy for precise error reporting: - PLCError: Base exception for all PLC-related errors - PLCNotFoundError: PLC not found during discovery or registration - PLCConnectionError: Connection establishment or maintenance failures - PLCInitializationError: PLC initialization failures - PLCCommunicationError: Communication protocol errors - PLCTagError: Tag-related operation errors - PLCTagReadError: Tag read operation failures - PLCTagWriteError: Tag write operation failures - HardwareOperationError: General hardware operation failures</p> Thread Safety <p>All PLC operations are thread-safe. Multiple PLCs can be operated simultaneously from different threads without interference.</p> Performance Notes <ul> <li>PLC discovery may take several seconds depending on network size</li> <li>Batch operations are more efficient than individual tag operations</li> <li>Connection pooling is used for optimal performance</li> <li>Consider PLC-specific optimizations for production use</li> </ul>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager--simple-usage-with-discovery","title":"Simple usage with discovery","text":"<p>async with PLCManager() as manager:     plcs = await manager.discover_plcs()     await manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")     await manager.connect_plc(\"PLC1\")</p> <pre><code># Read tags\nvalues = await manager.read_tag(\"PLC1\", [\"Tag1\", \"Tag2\"])\n\n# Write tags\nawait manager.write_tag(\"PLC1\", [(\"Tag1\", 100), (\"Tag2\", 200)])\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager--batch-operations","title":"Batch operations","text":"<p>async with PLCManager() as manager:     # Register multiple PLCs     await manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")     await manager.register_plc(\"PLC2\", \"Siemens\", \"192.168.1.101\")</p> <pre><code># Connect all PLCs\nresults = await manager.connect_all_plcs()\n\n# Batch read from multiple PLCs\nread_requests = [\n    (\"PLC1\", [\"Temperature\", \"Pressure\"]),\n    (\"PLC2\", [\"Speed\", \"Position\"])\n]\nvalues = await manager.read_tags_batch(read_requests)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager.PLCManager","title":"PLCManager","text":"<pre><code>PLCManager()\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Unified PLC management system for industrial automation.</p> <p>This manager provides a comprehensive interface for managing PLCs from different manufacturers with support for discovery, registration, connection management, and batch tag operations. It handles multiple PLC backends transparently and provides thread-safe operations with proper error handling.</p> <p>The manager supports: - Automatic PLC discovery across multiple backends - Dynamic PLC registration and connection management - Batch tag read/write operations for optimal performance - Connection monitoring and automatic reconnection - Comprehensive error handling and logging - Thread-safe operations with proper resource management</p> <p>Supported PLC Types: - Allen-Bradley: ControlLogix, CompactLogix, MicroLogix PLCs - Siemens: S7-300, S7-400, S7-1200, S7-1500 PLCs (Future) - Modbus: Modbus TCP/RTU devices (Future) - Mock PLCs: For testing and development</p> <p>Attributes:</p> Name Type Description <code>plcs</code> <code>Dict[str, BasePLC]</code> <p>Dictionary mapping PLC names to PLC instances</p> <code>config</code> <p>Hardware configuration manager instance</p> <code>logger</code> <p>Centralized logger for PLC operations</p> Example <p>Initialize the PLC manager.</p> discover_plcs <code>async</code> <pre><code>discover_plcs() -&gt; Dict[str, List[str]]\n</code></pre> <p>Discover available PLCs from all enabled backends.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dictionary mapping backend names to lists of discovered PLCs</p> register_plc <code>async</code> <pre><code>register_plc(\n    plc_name: str,\n    backend: str,\n    ip_address: str,\n    plc_type: Optional[str] = None,\n    **kwargs\n) -&gt; bool\n</code></pre> <p>Register a PLC with the manager.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Unique identifier for the PLC</p> required <code>backend</code> <code>str</code> <p>Backend type (\"AllenBradley\", \"Siemens\", \"Modbus\")</p> required <code>ip_address</code> <code>str</code> <p>IP address of the PLC</p> required <code>plc_type</code> <code>Optional[str]</code> <p>Specific PLC type (backend-dependent)</p> <code>None</code> <code>**kwargs</code> <p>Additional backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if registration successful, False otherwise</p> unregister_plc <code>async</code> <pre><code>unregister_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Unregister a PLC from the manager.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to unregister</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if unregistration successful, False otherwise</p> connect_plc <code>async</code> <pre><code>connect_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Connect to a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to connect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if connection successful, False otherwise</p> disconnect_plc <code>async</code> <pre><code>disconnect_plc(plc_name: str) -&gt; bool\n</code></pre> <p>Disconnect from a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC to disconnect</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if disconnection successful, False otherwise</p> connect_all_plcs <code>async</code> <pre><code>connect_all_plcs() -&gt; Dict[str, bool]\n</code></pre> <p>Connect to all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping PLC names to connection success status</p> disconnect_all_plcs <code>async</code> <pre><code>disconnect_all_plcs() -&gt; Dict[str, bool]\n</code></pre> <p>Disconnect from all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping PLC names to disconnection success status</p> read_tag <code>async</code> <pre><code>read_tag(plc_name: str, tags: Union[str, List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Read tags from a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <code>tags</code> <code>Union[str, List[str]]</code> <p>Single tag name or list of tag names</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping tag names to their values</p> write_tag <code>async</code> <pre><code>write_tag(\n    plc_name: str, tags: Union[Tuple[str, Any], List[Tuple[str, Any]]]\n) -&gt; Dict[str, bool]\n</code></pre> <p>Write tags to a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <code>tags</code> <code>Union[Tuple[str, Any], List[Tuple[str, Any]]]</code> <p>Single (tag_name, value) tuple or list of tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping tag names to write success status</p> read_tags_batch <code>async</code> <pre><code>read_tags_batch(\n    requests: List[Tuple[str, Union[str, List[str]]]],\n) -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read tags from multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[str, List[str]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their tag read results</p> write_tags_batch <code>async</code> <pre><code>write_tags_batch(\n    requests: List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]],\n) -&gt; Dict[str, Dict[str, bool]]\n</code></pre> <p>Write tags to multiple PLCs in batch.</p> <p>Parameters:</p> Name Type Description Default <code>requests</code> <code>List[Tuple[str, Union[Tuple[str, Any], List[Tuple[str, Any]]]]]</code> <p>List of (plc_name, tags) tuples</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, bool]]</code> <p>Dictionary mapping PLC names to their tag write results</p> get_plc_status <code>async</code> <pre><code>get_plc_status(plc_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get status information for a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with PLC status information</p> get_all_plc_status <code>async</code> <pre><code>get_all_plc_status() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get status information for all registered PLCs.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping PLC names to their status information</p> get_plc_tags <code>async</code> <pre><code>get_plc_tags(plc_name: str) -&gt; List[str]\n</code></pre> <p>Get list of available tags for a specific PLC.</p> <p>Parameters:</p> Name Type Description Default <code>plc_name</code> <code>str</code> <p>Name of the PLC</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of available tag names</p> get_registered_plcs <pre><code>get_registered_plcs() -&gt; List[str]\n</code></pre> <p>Get list of registered PLC names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of registered PLC names</p> get_backend_info <pre><code>get_backend_info() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get information about available PLC backends.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping backend names to their information</p> cleanup <code>async</code> <pre><code>cleanup()\n</code></pre> <p>Clean up all PLC connections and resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager.PLCManager--basic-usage","title":"Basic usage","text":"<p>async with PLCManager() as manager:     # Discover available PLCs     discovered = await manager.discover_plcs()</p> <pre><code># Register and connect to a PLC\nawait manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")\nawait manager.connect_plc(\"PLC1\")\n\n# Read and write tags\nvalues = await manager.read_tag(\"PLC1\", [\"Temperature\", \"Pressure\"])\nawait manager.write_tag(\"PLC1\", [(\"Setpoint\", 75.0)])\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.plcs.plc_manager.PLCManager--batch-operations","title":"Batch operations","text":"<p>async with PLCManager() as manager:     # Register multiple PLCs     await manager.register_plc(\"PLC1\", \"AllenBradley\", \"192.168.1.100\")     await manager.register_plc(\"PLC2\", \"AllenBradley\", \"192.168.1.101\")</p> <pre><code># Batch read from multiple PLCs\nread_requests = [\n    (\"PLC1\", [\"Temperature\", \"Pressure\"]),\n    (\"PLC2\", [\"Speed\", \"Position\"])\n]\nresults = await manager.read_tags_batch(read_requests)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.sensors","title":"sensors","text":"<p>MindTrace Hardware Sensor System.</p> <p>A unified sensor system that abstracts different communication backends (MQTT, HTTP, Serial, Modbus) behind a simple AsyncSensor interface.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorBackend","title":"SensorBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor backends.</p> <p>This interface abstracts different communication patterns: - MQTT: Push-based (subscribe to topics, cache messages) - HTTP: Pull-based (make requests on-demand) - Serial: Pull-based (send commands, read responses) - Modbus: Pull-based (read registers)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorBackend.connect","title":"connect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Establish connection to the backend.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorBackend.disconnect","title":"disconnect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close connection to the backend.</p> <p>Should be safe to call multiple times.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorBackend.read_data","title":"read_data  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data from the specified address.</p> <p>For different backends, 'address' means: - MQTT: topic name (returns cached message) - HTTP: endpoint path (makes GET request) - Serial: sensor command (send command, read response) - Modbus: register address (read holding registers)</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Backend-specific address/identifier</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary with sensor data, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend not connected</p> <code>TimeoutError</code> <p>If read operation times out</p> <code>ValueError</code> <p>If address is invalid</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorBackend.is_connected","title":"is_connected  <code>abstractmethod</code>","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if backend is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorBackend","title":"HTTPSensorBackend","text":"<pre><code>HTTPSensorBackend(\n    base_url: str,\n    auth_token: Optional[str] = None,\n    timeout: float = 30.0,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>HTTP backend for sensor communication (placeholder).</p> <p>This backend will connect to REST APIs and make HTTP GET requests to read sensor data. It implements a pull-based pattern where we request data on-demand.</p> <p>Future implementation will: - Make HTTP GET requests to base_url + endpoint - Handle authentication headers - Parse JSON responses - Implement timeout and retry logic</p> <p>Initialize HTTP backend.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests (e.g., \"http://api.sensors.com\")</p> required <code>auth_token</code> <code>Optional[str]</code> <p>Optional authentication token</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds</p> <code>30.0</code> <code>**kwargs</code> <p>Additional HTTP client parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorBackend.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Establish HTTP client connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP backend not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorBackend.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close HTTP client connection.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorBackend.read_data","title":"read_data  <code>async</code>","text":"<pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data via HTTP GET request.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Endpoint path (e.g., \"/sensors/temperature/current\")</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>JSON response data, or None if request fails</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP backend not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorBackend.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if HTTP client is ready.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorBackend","title":"MQTTSensorBackend","text":"<pre><code>MQTTSensorBackend(\n    broker_url: str,\n    identifier: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    keepalive: int = 60,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>MQTT backend for sensor communication.</p> <p>This backend connects to an MQTT broker and subscribes to topics. Messages are cached when received, and read_data() returns the latest cached message.</p> <p>This implements a push-based pattern where data comes to us, unlike HTTP/Serial which are pull-based where we request data on-demand.</p> <p>Initialize MQTT backend.</p> <p>Parameters:</p> Name Type Description Default <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>Optional[str]</code> <p>MQTT client identifier (auto-generated if None)</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>MQTT username (optional)</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>MQTT password (optional)</p> <code>None</code> <code>keepalive</code> <code>int</code> <p>MQTT keepalive interval in seconds</p> <code>60</code> <code>**kwargs</code> <p>Additional MQTT client parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorBackend.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to MQTT broker.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection to broker fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorBackend.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from MQTT broker.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorBackend.read_data","title":"read_data  <code>async</code>","text":"<pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read cached data from MQTT topic.</p> <p>For MQTT, the address is the topic name. If we haven't subscribed to this topic yet, we'll subscribe and wait briefly for a message.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>MQTT topic name</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Latest cached message for the topic, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected to broker</p> <code>ValueError</code> <p>If topic name is invalid</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorBackend.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if connected to MQTT broker.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorBackend","title":"SerialSensorBackend","text":"<pre><code>SerialSensorBackend(\n    port: str, baudrate: int = 9600, timeout: float = 5.0, **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>Serial backend for sensor communication (placeholder).</p> <p>This backend will connect to sensors via serial/USB ports and send commands to read sensor data. It implements a pull-based pattern where we send commands and read responses on-demand.</p> <p>Future implementation will: - Connect to serial ports (e.g., /dev/ttyUSB0, COM3) - Send sensor commands and read responses - Parse sensor data (JSON, CSV, or custom formats) - Handle timeouts and communication errors</p> <p>Initialize Serial backend.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>str</code> <p>Serial port path (e.g., \"/dev/ttyUSB0\" or \"COM3\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baudrate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Communication timeout in seconds</p> <code>5.0</code> <code>**kwargs</code> <p>Additional serial parameters (parity, stopbits, etc.)</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorBackend.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Open serial port connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial backend not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorBackend.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close serial port connection.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorBackend.read_data","title":"read_data  <code>async</code>","text":"<pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Send command to sensor and read response.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Sensor command (e.g., \"READ_TEMP\", \"GET_HUMIDITY\")</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Parsed sensor response data, or None if command fails</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial backend not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorBackend.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if serial port is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager","title":"SensorManager","text":"<pre><code>SensorManager()\n</code></pre> <p>Simple manager for multiple sensors.</p> <p>This manager provides basic functionality: - Register sensors with different backends - Remove sensors by ID - Read from all sensors in parallel</p> <p>The manager keeps sensors in a registry and delegates operations to them.</p> <p>Initialize sensor manager.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.sensor_count","title":"sensor_count  <code>property</code>","text":"<pre><code>sensor_count: int\n</code></pre> <p>Get number of registered sensors.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.register_sensor","title":"register_sensor","text":"<pre><code>register_sensor(\n    sensor_id: str,\n    backend_type: str,\n    connection_params: Dict[str, Any],\n    address: str,\n) -&gt; AsyncSensor\n</code></pre> <p>Register a new sensor with the manager.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>connection_params</code> <code>Dict[str, Any]</code> <p>Backend-specific connection parameters</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command)</p> required <p>Returns:</p> Type Description <code>AsyncSensor</code> <p>The created AsyncSensor instance</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id already exists or parameters are invalid</p> <p>Examples:</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.register_sensor--register-mqtt-sensor","title":"Register MQTT sensor","text":"<p>sensor = manager.register_sensor(     \"temp001\",     \"mqtt\",     {\"broker_url\": \"mqtt://localhost:1883\"},     \"sensors/temperature\" )</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.register_sensor--register-http-sensor","title":"Register HTTP sensor","text":"<p>sensor = manager.register_sensor(     \"temp002\",     \"http\",     {\"base_url\": \"http://api.sensors.com\"},     \"/sensors/temperature\" )</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.remove_sensor","title":"remove_sensor","text":"<pre><code>remove_sensor(sensor_id: str) -&gt; None\n</code></pre> <p>Remove a sensor from the manager.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>ID of sensor to remove</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id doesn't exist</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.get_sensor","title":"get_sensor","text":"<pre><code>get_sensor(sensor_id: str) -&gt; Optional[AsyncSensor]\n</code></pre> <p>Get a sensor by ID.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>ID of sensor to get</p> required <p>Returns:</p> Type Description <code>Optional[AsyncSensor]</code> <p>AsyncSensor instance or None if not found</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.list_sensors","title":"list_sensors","text":"<pre><code>list_sensors() -&gt; List[str]\n</code></pre> <p>Get list of all registered sensor IDs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of sensor IDs</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.connect_all","title":"connect_all  <code>async</code>","text":"<pre><code>connect_all() -&gt; Dict[str, bool]\n</code></pre> <p>Connect all registered sensors.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping sensor IDs to connection success (True/False)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.disconnect_all","title":"disconnect_all  <code>async</code>","text":"<pre><code>disconnect_all() -&gt; None\n</code></pre> <p>Disconnect all registered sensors.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorManager.read_all","title":"read_all  <code>async</code>","text":"<pre><code>read_all() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read data from all registered sensors.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping sensor IDs to their data (or error info)</p> <p>Examples:</p> <p>{     \"temp001\": {\"temperature\": 23.5, \"unit\": \"C\"},     \"temp002\": {\"error\": \"Not connected\"},     \"humid001\": {\"humidity\": 65.2, \"unit\": \"%\"} }</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor","title":"AsyncSensor","text":"<pre><code>AsyncSensor(sensor_id: str, backend: SensorBackend, address: str)\n</code></pre> <p>Unified async sensor interface.</p> <p>This class provides a simple, consistent API for reading sensor data regardless of the underlying communication backend (MQTT, HTTP, Serial, etc.).</p> <p>The sensor abstracts different communication patterns: - MQTT: Push-based (messages are cached when received) - HTTP: Pull-based (requests made on-demand) - Serial: Pull-based (commands sent on-demand)</p> <p>All backends are hidden behind the same connect/disconnect/read interface.</p> <p>Initialize AsyncSensor with a backend.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for this sensor</p> required <code>backend</code> <code>SensorBackend</code> <p>Backend implementation (MQTT, HTTP, Serial, etc.)</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command, etc.)</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id or address is empty</p> <code>TypeError</code> <p>If backend is not a SensorBackend instance</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor.sensor_id","title":"sensor_id  <code>property</code>","text":"<pre><code>sensor_id: str\n</code></pre> <p>Get the sensor ID.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor.is_connected","title":"is_connected  <code>property</code>","text":"<pre><code>is_connected: bool\n</code></pre> <p>Check if sensor backend is connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if backend is connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect the sensor backend.</p> <p>This establishes the connection to the underlying communication system (MQTT broker, HTTP server, serial port, etc.).</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect the sensor backend.</p> <p>This closes the connection to the underlying communication system. Safe to call multiple times.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.AsyncSensor.read","title":"read  <code>async</code>","text":"<pre><code>read() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data.</p> <p>This method abstracts different communication patterns: - MQTT: Returns cached message from topic - HTTP: Makes GET request to endpoint - Serial: Sends command and reads response</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary with sensor data, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend is not connected</p> <code>TimeoutError</code> <p>If read operation times out</p> <code>ValueError</code> <p>If address is invalid</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator","title":"SensorSimulator","text":"<pre><code>SensorSimulator(\n    simulator_id: str, backend: SensorSimulatorBackend, address: str\n)\n</code></pre> <p>Unified sensor simulator interface.</p> <p>This class provides a simple, consistent API for publishing sensor data regardless of the underlying communication backend (MQTT, HTTP, Serial, etc.).</p> <p>The simulator abstracts different communication patterns: - MQTT: Publish messages to topics - HTTP: POST data to REST endpoints - Serial: Send data/commands to serial devices</p> <p>All backends are hidden behind the same connect/disconnect/publish interface. This is perfect for integration testing and sensor data simulation.</p> <p>Initialize SensorSimulator with a backend.</p> <p>Parameters:</p> Name Type Description Default <code>simulator_id</code> <code>str</code> <p>Unique identifier for this simulator</p> required <code>backend</code> <code>SensorSimulatorBackend</code> <p>Backend implementation (MQTT, HTTP, Serial, etc.)</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command, etc.)</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If simulator_id or address is empty</p> <code>TypeError</code> <p>If backend is not a SensorSimulatorBackend instance</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator.simulator_id","title":"simulator_id  <code>property</code>","text":"<pre><code>simulator_id: str\n</code></pre> <p>Get the simulator ID.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator.is_connected","title":"is_connected  <code>property</code>","text":"<pre><code>is_connected: bool\n</code></pre> <p>Check if simulator backend is connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if backend is connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect the simulator backend.</p> <p>This establishes the connection to the underlying communication system (MQTT broker, HTTP server, serial port, etc.).</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect the simulator backend.</p> <p>This closes the connection to the underlying communication system. Safe to call multiple times.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulator.publish","title":"publish  <code>async</code>","text":"<pre><code>publish(data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data.</p> <p>This method abstracts different communication patterns: - MQTT: Publishes message to topic - HTTP: Makes POST request to endpoint - Serial: Sends data to serial port</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (dict, primitive, or complex object)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend is not connected</p> <code>TimeoutError</code> <p>If publish operation times out</p> <code>ValueError</code> <p>If address is invalid or data cannot be serialized</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulatorBackend","title":"SensorSimulatorBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor simulator backends.</p> <p>This interface abstracts different communication patterns for publishing: - MQTT: Publish messages to topics - HTTP: POST data to endpoints - Serial: Send data/commands to serial ports - Modbus: Write to registers</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulatorBackend.connect","title":"connect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Establish connection to the backend.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulatorBackend.disconnect","title":"disconnect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close connection to the backend.</p> <p>Should be safe to call multiple times.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulatorBackend.publish_data","title":"publish_data  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to the specified address.</p> <p>For different backends, 'address' means: - MQTT: topic name to publish to - HTTP: endpoint path to POST to - Serial: sensor command or data format - Modbus: register address to write to</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Backend-specific address/identifier</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (dict, primitive, or complex object)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend not connected</p> <code>TimeoutError</code> <p>If publish operation times out</p> <code>ValueError</code> <p>If address is invalid or data cannot be serialized</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SensorSimulatorBackend.is_connected","title":"is_connected  <code>abstractmethod</code>","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if backend is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorSimulator","title":"HTTPSensorSimulator","text":"<pre><code>HTTPSensorSimulator(\n    base_url: str,\n    auth_token: Optional[str] = None,\n    timeout: float = 30.0,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>HTTP backend for sensor simulation (placeholder).</p> <p>This backend will connect to REST APIs and make HTTP POST requests to publish sensor data. It implements a push-based pattern where we send data to endpoints.</p> <p>Future implementation will: - Make HTTP POST requests to base_url + endpoint - Handle authentication headers - Send JSON payloads - Implement timeout and retry logic</p> <p>Initialize HTTP simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests (e.g., \"http://api.sensors.com\")</p> required <code>auth_token</code> <code>Optional[str]</code> <p>Optional authentication token</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds</p> <code>30.0</code> <code>**kwargs</code> <p>Additional HTTP client parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorSimulator.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Establish HTTP client connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorSimulator.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close HTTP client connection.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorSimulator.publish_data","title":"publish_data  <code>async</code>","text":"<pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data via HTTP POST request.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Endpoint path (e.g., \"/sensors/temperature/data\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.HTTPSensorSimulator.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if HTTP client is ready.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorSimulator","title":"MQTTSensorSimulator","text":"<pre><code>MQTTSensorSimulator(\n    broker_url: str,\n    identifier: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    keepalive: int = 60,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>MQTT backend for sensor simulation.</p> <p>This backend connects to an MQTT broker and publishes sensor data to topics. It's designed for testing and integration scenarios where you need to simulate sensor data streams that can be consumed by AsyncSensor instances.</p> <p>Initialize MQTT simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>Optional[str]</code> <p>MQTT client identifier (auto-generated if None)</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>MQTT username (optional)</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>MQTT password (optional)</p> <code>None</code> <code>keepalive</code> <code>int</code> <p>MQTT keepalive interval in seconds</p> <code>60</code> <code>**kwargs</code> <p>Additional MQTT client parameters</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorSimulator.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to MQTT broker.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection to broker fails</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorSimulator.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from MQTT broker.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorSimulator.publish_data","title":"publish_data  <code>async</code>","text":"<pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to MQTT topic.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>MQTT topic name to publish to</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded if dict/list)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected to broker</p> <code>ValueError</code> <p>If topic name is invalid</p> <code>TimeoutError</code> <p>If publish operation times out</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.MQTTSensorSimulator.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if connected to MQTT broker.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorSimulator","title":"SerialSensorSimulator","text":"<pre><code>SerialSensorSimulator(\n    port: str, baudrate: int = 9600, timeout: float = 5.0, **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>Serial backend for sensor simulation (placeholder).</p> <p>This backend will connect to serial/USB ports and send sensor data commands. It implements a push-based pattern where we send sensor data to simulate physical sensor devices.</p> <p>Future implementation will: - Connect to serial ports (e.g., /dev/ttyUSB0, COM3) - Send sensor data in various formats (JSON, CSV, custom protocols) - Simulate sensor response patterns and timing - Handle communication protocols and handshaking</p> <p>Initialize Serial simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>str</code> <p>Serial port path (e.g., \"/dev/ttyUSB0\" or \"COM3\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baudrate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Communication timeout in seconds</p> <code>5.0</code> <code>**kwargs</code> <p>Additional serial parameters (parity, stopbits, etc.)</p> <code>{}</code>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorSimulator.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Open serial port connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorSimulator.disconnect","title":"disconnect  <code>async</code>","text":"<pre><code>disconnect() -&gt; None\n</code></pre> <p>Close serial port connection.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorSimulator.publish_data","title":"publish_data  <code>async</code>","text":"<pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Send sensor data via serial port.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Command type or data format identifier (e.g., \"TEMP_DATA\", \"JSON_FORMAT\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to send (will be formatted according to address)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.SerialSensorSimulator.is_connected","title":"is_connected","text":"<pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if serial port is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_backend","title":"create_backend","text":"<pre><code>create_backend(backend_type: str, **params) -&gt; SensorBackend\n</code></pre> <p>Create a sensor backend of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>**params</code> <p>Backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>SensorBackend</code> <p>Instantiated backend</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If backend_type is unknown</p> <code>TypeError</code> <p>If required parameters are missing</p> <p>Examples:</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_backend--mqtt-backend","title":"MQTT backend","text":"<p>mqtt_backend = create_backend(\"mqtt\", broker_url=\"mqtt://localhost:1883\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_backend--http-backend","title":"HTTP backend","text":"<p>http_backend = create_backend(\"http\", base_url=\"http://api.sensors.com\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_backend--serial-backend","title":"Serial backend","text":"<p>serial_backend = create_backend(\"serial\", port=\"/dev/ttyUSB0\", baudrate=9600)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_simulator_backend","title":"create_simulator_backend","text":"<pre><code>create_simulator_backend(backend_type: str, **params) -&gt; SensorSimulatorBackend\n</code></pre> <p>Create a sensor simulator backend of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>**params</code> <p>Backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>SensorSimulatorBackend</code> <p>Instantiated simulator backend</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If backend_type is unknown</p> <code>TypeError</code> <p>If required parameters are missing</p> <p>Examples:</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_simulator_backend--mqtt-simulator-backend","title":"MQTT simulator backend","text":"<p>mqtt_sim = create_simulator_backend(\"mqtt\", broker_url=\"mqtt://localhost:1883\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_simulator_backend--http-simulator-backend","title":"HTTP simulator backend","text":"<p>http_sim = create_simulator_backend(\"http\", base_url=\"http://api.sensors.com\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.create_simulator_backend--serial-simulator-backend","title":"Serial simulator backend","text":"<p>serial_sim = create_simulator_backend(\"serial\", port=\"/dev/ttyUSB0\", baudrate=9600)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.backends","title":"backends","text":"<p>Sensor backends package.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.backends.base","title":"base","text":"<p>Base sensor backend interface.</p> <p>This module defines the abstract interface that all sensor backends must implement.</p> SensorBackend <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor backends.</p> <p>This interface abstracts different communication patterns: - MQTT: Push-based (subscribe to topics, cache messages) - HTTP: Pull-based (make requests on-demand) - Serial: Pull-based (send commands, read responses) - Modbus: Pull-based (read registers)</p> connect <code>abstractmethod</code> <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish connection to the backend.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> disconnect <code>abstractmethod</code> <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close connection to the backend.</p> <p>Should be safe to call multiple times.</p> read_data <code>abstractmethod</code> <code>async</code> <pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data from the specified address.</p> <p>For different backends, 'address' means: - MQTT: topic name (returns cached message) - HTTP: endpoint path (makes GET request) - Serial: sensor command (send command, read response) - Modbus: register address (read holding registers)</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Backend-specific address/identifier</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary with sensor data, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend not connected</p> <code>TimeoutError</code> <p>If read operation times out</p> <code>ValueError</code> <p>If address is invalid</p> is_connected <code>abstractmethod</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if backend is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.backends.http","title":"http","text":"<p>HTTP sensor backend implementation (placeholder).</p> <p>This module will implement the SensorBackend interface for HTTP/REST API communication. Currently this is a placeholder that raises NotImplementedError.</p> HTTPSensorBackend <pre><code>HTTPSensorBackend(\n    base_url: str,\n    auth_token: Optional[str] = None,\n    timeout: float = 30.0,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>HTTP backend for sensor communication (placeholder).</p> <p>This backend will connect to REST APIs and make HTTP GET requests to read sensor data. It implements a pull-based pattern where we request data on-demand.</p> <p>Future implementation will: - Make HTTP GET requests to base_url + endpoint - Handle authentication headers - Parse JSON responses - Implement timeout and retry logic</p> <p>Initialize HTTP backend.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests (e.g., \"http://api.sensors.com\")</p> required <code>auth_token</code> <code>Optional[str]</code> <p>Optional authentication token</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds</p> <code>30.0</code> <code>**kwargs</code> <p>Additional HTTP client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish HTTP client connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP backend not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close HTTP client connection.</p> read_data <code>async</code> <pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data via HTTP GET request.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Endpoint path (e.g., \"/sensors/temperature/current\")</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>JSON response data, or None if request fails</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP backend not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if HTTP client is ready.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.backends.mqtt","title":"mqtt","text":"<p>MQTT sensor backend implementation.</p> <p>This module implements the SensorBackend interface for MQTT communication. It uses a push-based model where messages are cached when received.</p> MQTTSensorBackend <pre><code>MQTTSensorBackend(\n    broker_url: str,\n    identifier: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    keepalive: int = 60,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>MQTT backend for sensor communication.</p> <p>This backend connects to an MQTT broker and subscribes to topics. Messages are cached when received, and read_data() returns the latest cached message.</p> <p>This implements a push-based pattern where data comes to us, unlike HTTP/Serial which are pull-based where we request data on-demand.</p> <p>Initialize MQTT backend.</p> <p>Parameters:</p> Name Type Description Default <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>Optional[str]</code> <p>MQTT client identifier (auto-generated if None)</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>MQTT username (optional)</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>MQTT password (optional)</p> <code>None</code> <code>keepalive</code> <code>int</code> <p>MQTT keepalive interval in seconds</p> <code>60</code> <code>**kwargs</code> <p>Additional MQTT client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Connect to MQTT broker.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection to broker fails</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from MQTT broker.</p> read_data <code>async</code> <pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read cached data from MQTT topic.</p> <p>For MQTT, the address is the topic name. If we haven't subscribed to this topic yet, we'll subscribe and wait briefly for a message.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>MQTT topic name</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Latest cached message for the topic, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected to broker</p> <code>ValueError</code> <p>If topic name is invalid</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if connected to MQTT broker.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.backends.serial","title":"serial","text":"<p>Serial sensor backend implementation (placeholder).</p> <p>This module will implement the SensorBackend interface for serial/USB communication. Currently this is a placeholder that raises NotImplementedError.</p> SerialSensorBackend <pre><code>SerialSensorBackend(\n    port: str, baudrate: int = 9600, timeout: float = 5.0, **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorBackend</code></p> <p>Serial backend for sensor communication (placeholder).</p> <p>This backend will connect to sensors via serial/USB ports and send commands to read sensor data. It implements a pull-based pattern where we send commands and read responses on-demand.</p> <p>Future implementation will: - Connect to serial ports (e.g., /dev/ttyUSB0, COM3) - Send sensor commands and read responses - Parse sensor data (JSON, CSV, or custom formats) - Handle timeouts and communication errors</p> <p>Initialize Serial backend.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>str</code> <p>Serial port path (e.g., \"/dev/ttyUSB0\" or \"COM3\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baudrate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Communication timeout in seconds</p> <code>5.0</code> <code>**kwargs</code> <p>Additional serial parameters (parity, stopbits, etc.)</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Open serial port connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial backend not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close serial port connection.</p> read_data <code>async</code> <pre><code>read_data(address: str) -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Send command to sensor and read response.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Sensor command (e.g., \"READ_TEMP\", \"GET_HUMIDITY\")</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Parsed sensor response data, or None if command fails</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial backend not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if serial port is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core","title":"core","text":"<p>Sensor core package.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory","title":"factory","text":"<p>Backend factory for creating sensor backends and simulators.</p> <p>This module provides factory functions to create different types of sensor backends and simulator backends based on type strings and parameters.</p> create_backend <pre><code>create_backend(backend_type: str, **params) -&gt; SensorBackend\n</code></pre> <p>Create a sensor backend of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>**params</code> <p>Backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>SensorBackend</code> <p>Instantiated backend</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If backend_type is unknown</p> <code>TypeError</code> <p>If required parameters are missing</p> <p>Examples:</p> register_backend <pre><code>register_backend(backend_type: str, backend_class: type) -&gt; None\n</code></pre> <p>Register a custom backend type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Name for the backend type</p> required <code>backend_class</code> <code>type</code> <p>Backend class that implements SensorBackend</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If backend_class doesn't inherit from SensorBackend</p> get_available_backends <pre><code>get_available_backends() -&gt; Dict[str, type]\n</code></pre> <p>Get all available backend types.</p> <p>Returns:</p> Type Description <code>Dict[str, type]</code> <p>Dictionary mapping backend names to classes</p> create_simulator_backend <pre><code>create_simulator_backend(backend_type: str, **params) -&gt; SensorSimulatorBackend\n</code></pre> <p>Create a sensor simulator backend of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>**params</code> <p>Backend-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>SensorSimulatorBackend</code> <p>Instantiated simulator backend</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If backend_type is unknown</p> <code>TypeError</code> <p>If required parameters are missing</p> <p>Examples:</p> register_simulator_backend <pre><code>register_simulator_backend(backend_type: str, backend_class: type) -&gt; None\n</code></pre> <p>Register a custom simulator backend type.</p> <p>Parameters:</p> Name Type Description Default <code>backend_type</code> <code>str</code> <p>Name for the backend type</p> required <code>backend_class</code> <code>type</code> <p>Backend class that implements SensorSimulatorBackend</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If backend_class doesn't inherit from SensorSimulatorBackend</p> get_available_simulator_backends <pre><code>get_available_simulator_backends() -&gt; Dict[str, type]\n</code></pre> <p>Get all available simulator backend types.</p> <p>Returns:</p> Type Description <code>Dict[str, type]</code> <p>Dictionary mapping simulator backend names to classes</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_backend--mqtt-backend","title":"MQTT backend","text":"<p>mqtt_backend = create_backend(\"mqtt\", broker_url=\"mqtt://localhost:1883\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_backend--http-backend","title":"HTTP backend","text":"<p>http_backend = create_backend(\"http\", base_url=\"http://api.sensors.com\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_backend--serial-backend","title":"Serial backend","text":"<p>serial_backend = create_backend(\"serial\", port=\"/dev/ttyUSB0\", baudrate=9600)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_simulator_backend--mqtt-simulator-backend","title":"MQTT simulator backend","text":"<p>mqtt_sim = create_simulator_backend(\"mqtt\", broker_url=\"mqtt://localhost:1883\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_simulator_backend--http-simulator-backend","title":"HTTP simulator backend","text":"<p>http_sim = create_simulator_backend(\"http\", base_url=\"http://api.sensors.com\")</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.factory.create_simulator_backend--serial-simulator-backend","title":"Serial simulator backend","text":"<p>serial_sim = create_simulator_backend(\"serial\", port=\"/dev/ttyUSB0\", baudrate=9600)</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.manager","title":"manager","text":"<p>Simple sensor manager implementation.</p> <p>This module implements a minimal SensorManager that can register/remove sensors and perform bulk read operations across multiple sensors.</p> SensorManager <pre><code>SensorManager()\n</code></pre> <p>Simple manager for multiple sensors.</p> <p>This manager provides basic functionality: - Register sensors with different backends - Remove sensors by ID - Read from all sensors in parallel</p> <p>The manager keeps sensors in a registry and delegates operations to them.</p> <p>Initialize sensor manager.</p> sensor_count <code>property</code> <pre><code>sensor_count: int\n</code></pre> <p>Get number of registered sensors.</p> register_sensor <pre><code>register_sensor(\n    sensor_id: str,\n    backend_type: str,\n    connection_params: Dict[str, Any],\n    address: str,\n) -&gt; AsyncSensor\n</code></pre> <p>Register a new sensor with the manager.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for the sensor</p> required <code>backend_type</code> <code>str</code> <p>Type of backend (\"mqtt\", \"http\", \"serial\")</p> required <code>connection_params</code> <code>Dict[str, Any]</code> <p>Backend-specific connection parameters</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command)</p> required <p>Returns:</p> Type Description <code>AsyncSensor</code> <p>The created AsyncSensor instance</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id already exists or parameters are invalid</p> <p>Examples:</p> remove_sensor <pre><code>remove_sensor(sensor_id: str) -&gt; None\n</code></pre> <p>Remove a sensor from the manager.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>ID of sensor to remove</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id doesn't exist</p> get_sensor <pre><code>get_sensor(sensor_id: str) -&gt; Optional[AsyncSensor]\n</code></pre> <p>Get a sensor by ID.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>ID of sensor to get</p> required <p>Returns:</p> Type Description <code>Optional[AsyncSensor]</code> <p>AsyncSensor instance or None if not found</p> list_sensors <pre><code>list_sensors() -&gt; List[str]\n</code></pre> <p>Get list of all registered sensor IDs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of sensor IDs</p> connect_all <code>async</code> <pre><code>connect_all() -&gt; Dict[str, bool]\n</code></pre> <p>Connect all registered sensors.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dictionary mapping sensor IDs to connection success (True/False)</p> disconnect_all <code>async</code> <pre><code>disconnect_all() -&gt; None\n</code></pre> <p>Disconnect all registered sensors.</p> read_all <code>async</code> <pre><code>read_all() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Read data from all registered sensors.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping sensor IDs to their data (or error info)</p> <p>Examples:</p> <p>{     \"temp001\": {\"temperature\": 23.5, \"unit\": \"C\"},     \"temp002\": {\"error\": \"Not connected\"},     \"humid001\": {\"humidity\": 65.2, \"unit\": \"%\"} }</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.manager.SensorManager.register_sensor--register-mqtt-sensor","title":"Register MQTT sensor","text":"<p>sensor = manager.register_sensor(     \"temp001\",     \"mqtt\",     {\"broker_url\": \"mqtt://localhost:1883\"},     \"sensors/temperature\" )</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.manager.SensorManager.register_sensor--register-http-sensor","title":"Register HTTP sensor","text":"<p>sensor = manager.register_sensor(     \"temp002\",     \"http\",     {\"base_url\": \"http://api.sensors.com\"},     \"/sensors/temperature\" )</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.sensor","title":"sensor","text":"<p>Unified AsyncSensor class.</p> <p>This module implements the main AsyncSensor class that provides a simple, unified interface for all sensor backends (MQTT, HTTP, Serial, etc.).</p> AsyncSensor <pre><code>AsyncSensor(sensor_id: str, backend: SensorBackend, address: str)\n</code></pre> <p>Unified async sensor interface.</p> <p>This class provides a simple, consistent API for reading sensor data regardless of the underlying communication backend (MQTT, HTTP, Serial, etc.).</p> <p>The sensor abstracts different communication patterns: - MQTT: Push-based (messages are cached when received) - HTTP: Pull-based (requests made on-demand) - Serial: Pull-based (commands sent on-demand)</p> <p>All backends are hidden behind the same connect/disconnect/read interface.</p> <p>Initialize AsyncSensor with a backend.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_id</code> <code>str</code> <p>Unique identifier for this sensor</p> required <code>backend</code> <code>SensorBackend</code> <p>Backend implementation (MQTT, HTTP, Serial, etc.)</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command, etc.)</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If sensor_id or address is empty</p> <code>TypeError</code> <p>If backend is not a SensorBackend instance</p> sensor_id <code>property</code> <pre><code>sensor_id: str\n</code></pre> <p>Get the sensor ID.</p> is_connected <code>property</code> <pre><code>is_connected: bool\n</code></pre> <p>Check if sensor backend is connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if backend is connected, False otherwise</p> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Connect the sensor backend.</p> <p>This establishes the connection to the underlying communication system (MQTT broker, HTTP server, serial port, etc.).</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect the sensor backend.</p> <p>This closes the connection to the underlying communication system. Safe to call multiple times.</p> read <code>async</code> <pre><code>read() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Read sensor data.</p> <p>This method abstracts different communication patterns: - MQTT: Returns cached message from topic - HTTP: Makes GET request to endpoint - Serial: Sends command and reads response</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary with sensor data, or None if no data available</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend is not connected</p> <code>TimeoutError</code> <p>If read operation times out</p> <code>ValueError</code> <p>If address is invalid</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.core.simulator","title":"simulator","text":"<p>SensorSimulator class for publishing sensor data.</p> <p>This module implements the main SensorSimulator class that provides a simple, unified interface for publishing sensor data to all simulator backends (MQTT, HTTP, Serial, etc.).</p> SensorSimulator <pre><code>SensorSimulator(\n    simulator_id: str, backend: SensorSimulatorBackend, address: str\n)\n</code></pre> <p>Unified sensor simulator interface.</p> <p>This class provides a simple, consistent API for publishing sensor data regardless of the underlying communication backend (MQTT, HTTP, Serial, etc.).</p> <p>The simulator abstracts different communication patterns: - MQTT: Publish messages to topics - HTTP: POST data to REST endpoints - Serial: Send data/commands to serial devices</p> <p>All backends are hidden behind the same connect/disconnect/publish interface. This is perfect for integration testing and sensor data simulation.</p> <p>Initialize SensorSimulator with a backend.</p> <p>Parameters:</p> Name Type Description Default <code>simulator_id</code> <code>str</code> <p>Unique identifier for this simulator</p> required <code>backend</code> <code>SensorSimulatorBackend</code> <p>Backend implementation (MQTT, HTTP, Serial, etc.)</p> required <code>address</code> <code>str</code> <p>Backend-specific address (topic, endpoint, command, etc.)</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If simulator_id or address is empty</p> <code>TypeError</code> <p>If backend is not a SensorSimulatorBackend instance</p> simulator_id <code>property</code> <pre><code>simulator_id: str\n</code></pre> <p>Get the simulator ID.</p> is_connected <code>property</code> <pre><code>is_connected: bool\n</code></pre> <p>Check if simulator backend is connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if backend is connected, False otherwise</p> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Connect the simulator backend.</p> <p>This establishes the connection to the underlying communication system (MQTT broker, HTTP server, serial port, etc.).</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect the simulator backend.</p> <p>This closes the connection to the underlying communication system. Safe to call multiple times.</p> publish <code>async</code> <pre><code>publish(data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data.</p> <p>This method abstracts different communication patterns: - MQTT: Publishes message to topic - HTTP: Makes POST request to endpoint - Serial: Sends data to serial port</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (dict, primitive, or complex object)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend is not connected</p> <code>TimeoutError</code> <p>If publish operation times out</p> <code>ValueError</code> <p>If address is invalid or data cannot be serialized</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators","title":"simulators","text":"<p>Sensor simulators for testing and integration purposes.</p> <p>This module provides SensorSimulator implementations that can publish data to various backends (MQTT, HTTP, Serial) for testing AsyncSensor functionality.</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.SensorSimulatorBackend","title":"SensorSimulatorBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor simulator backends.</p> <p>This interface abstracts different communication patterns for publishing: - MQTT: Publish messages to topics - HTTP: POST data to endpoints - Serial: Send data/commands to serial ports - Modbus: Write to registers</p> connect <code>abstractmethod</code> <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish connection to the backend.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> disconnect <code>abstractmethod</code> <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close connection to the backend.</p> <p>Should be safe to call multiple times.</p> publish_data <code>abstractmethod</code> <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to the specified address.</p> <p>For different backends, 'address' means: - MQTT: topic name to publish to - HTTP: endpoint path to POST to - Serial: sensor command or data format - Modbus: register address to write to</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Backend-specific address/identifier</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (dict, primitive, or complex object)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend not connected</p> <code>TimeoutError</code> <p>If publish operation times out</p> <code>ValueError</code> <p>If address is invalid or data cannot be serialized</p> is_connected <code>abstractmethod</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if backend is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.HTTPSensorSimulator","title":"HTTPSensorSimulator","text":"<pre><code>HTTPSensorSimulator(\n    base_url: str,\n    auth_token: Optional[str] = None,\n    timeout: float = 30.0,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>HTTP backend for sensor simulation (placeholder).</p> <p>This backend will connect to REST APIs and make HTTP POST requests to publish sensor data. It implements a push-based pattern where we send data to endpoints.</p> <p>Future implementation will: - Make HTTP POST requests to base_url + endpoint - Handle authentication headers - Send JSON payloads - Implement timeout and retry logic</p> <p>Initialize HTTP simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests (e.g., \"http://api.sensors.com\")</p> required <code>auth_token</code> <code>Optional[str]</code> <p>Optional authentication token</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds</p> <code>30.0</code> <code>**kwargs</code> <p>Additional HTTP client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish HTTP client connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close HTTP client connection.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data via HTTP POST request.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Endpoint path (e.g., \"/sensors/temperature/data\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if HTTP client is ready.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.MQTTSensorSimulator","title":"MQTTSensorSimulator","text":"<pre><code>MQTTSensorSimulator(\n    broker_url: str,\n    identifier: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    keepalive: int = 60,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>MQTT backend for sensor simulation.</p> <p>This backend connects to an MQTT broker and publishes sensor data to topics. It's designed for testing and integration scenarios where you need to simulate sensor data streams that can be consumed by AsyncSensor instances.</p> <p>Initialize MQTT simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>Optional[str]</code> <p>MQTT client identifier (auto-generated if None)</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>MQTT username (optional)</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>MQTT password (optional)</p> <code>None</code> <code>keepalive</code> <code>int</code> <p>MQTT keepalive interval in seconds</p> <code>60</code> <code>**kwargs</code> <p>Additional MQTT client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Connect to MQTT broker.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection to broker fails</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from MQTT broker.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to MQTT topic.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>MQTT topic name to publish to</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded if dict/list)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected to broker</p> <code>ValueError</code> <p>If topic name is invalid</p> <code>TimeoutError</code> <p>If publish operation times out</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if connected to MQTT broker.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.SerialSensorSimulator","title":"SerialSensorSimulator","text":"<pre><code>SerialSensorSimulator(\n    port: str, baudrate: int = 9600, timeout: float = 5.0, **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>Serial backend for sensor simulation (placeholder).</p> <p>This backend will connect to serial/USB ports and send sensor data commands. It implements a push-based pattern where we send sensor data to simulate physical sensor devices.</p> <p>Future implementation will: - Connect to serial ports (e.g., /dev/ttyUSB0, COM3) - Send sensor data in various formats (JSON, CSV, custom protocols) - Simulate sensor response patterns and timing - Handle communication protocols and handshaking</p> <p>Initialize Serial simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>str</code> <p>Serial port path (e.g., \"/dev/ttyUSB0\" or \"COM3\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baudrate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Communication timeout in seconds</p> <code>5.0</code> <code>**kwargs</code> <p>Additional serial parameters (parity, stopbits, etc.)</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Open serial port connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close serial port connection.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Send sensor data via serial port.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Command type or data format identifier (e.g., \"TEMP_DATA\", \"JSON_FORMAT\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to send (will be formatted according to address)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if serial port is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.base","title":"base","text":"<p>Base sensor simulator backend interface.</p> <p>This module defines the abstract interface that all sensor simulator backends must implement.</p> SensorSimulatorBackend <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all sensor simulator backends.</p> <p>This interface abstracts different communication patterns for publishing: - MQTT: Publish messages to topics - HTTP: POST data to endpoints - Serial: Send data/commands to serial ports - Modbus: Write to registers</p> connect <code>abstractmethod</code> <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish connection to the backend.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection fails</p> disconnect <code>abstractmethod</code> <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close connection to the backend.</p> <p>Should be safe to call multiple times.</p> publish_data <code>abstractmethod</code> <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to the specified address.</p> <p>For different backends, 'address' means: - MQTT: topic name to publish to - HTTP: endpoint path to POST to - Serial: sensor command or data format - Modbus: register address to write to</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Backend-specific address/identifier</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (dict, primitive, or complex object)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If backend not connected</p> <code>TimeoutError</code> <p>If publish operation times out</p> <code>ValueError</code> <p>If address is invalid or data cannot be serialized</p> is_connected <code>abstractmethod</code> <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if backend is currently connected.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.http","title":"http","text":"<p>HTTP sensor simulator backend implementation (placeholder).</p> <p>This module will implement the SensorSimulatorBackend interface for HTTP/REST API communication. Currently this is a placeholder that raises NotImplementedError.</p> HTTPSensorSimulator <pre><code>HTTPSensorSimulator(\n    base_url: str,\n    auth_token: Optional[str] = None,\n    timeout: float = 30.0,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>HTTP backend for sensor simulation (placeholder).</p> <p>This backend will connect to REST APIs and make HTTP POST requests to publish sensor data. It implements a push-based pattern where we send data to endpoints.</p> <p>Future implementation will: - Make HTTP POST requests to base_url + endpoint - Handle authentication headers - Send JSON payloads - Implement timeout and retry logic</p> <p>Initialize HTTP simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL for HTTP requests (e.g., \"http://api.sensors.com\")</p> required <code>auth_token</code> <code>Optional[str]</code> <p>Optional authentication token</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds</p> <code>30.0</code> <code>**kwargs</code> <p>Additional HTTP client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Establish HTTP client connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close HTTP client connection.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data via HTTP POST request.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Endpoint path (e.g., \"/sensors/temperature/data\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>HTTP simulator not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if HTTP client is ready.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.mqtt","title":"mqtt","text":"<p>MQTT sensor simulator backend implementation.</p> <p>This module implements the SensorSimulatorBackend interface for MQTT communication. It publishes sensor data to MQTT topics for testing and integration purposes.</p> MQTTSensorSimulator <pre><code>MQTTSensorSimulator(\n    broker_url: str,\n    identifier: Optional[str] = None,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    keepalive: int = 60,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>MQTT backend for sensor simulation.</p> <p>This backend connects to an MQTT broker and publishes sensor data to topics. It's designed for testing and integration scenarios where you need to simulate sensor data streams that can be consumed by AsyncSensor instances.</p> <p>Initialize MQTT simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>broker_url</code> <code>str</code> <p>MQTT broker URL (e.g., \"mqtt://localhost:1883\")</p> required <code>identifier</code> <code>Optional[str]</code> <p>MQTT client identifier (auto-generated if None)</p> <code>None</code> <code>username</code> <code>Optional[str]</code> <p>MQTT username (optional)</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>MQTT password (optional)</p> <code>None</code> <code>keepalive</code> <code>int</code> <p>MQTT keepalive interval in seconds</p> <code>60</code> <code>**kwargs</code> <p>Additional MQTT client parameters</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Connect to MQTT broker.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If connection to broker fails</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Disconnect from MQTT broker.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Publish sensor data to MQTT topic.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>MQTT topic name to publish to</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to publish (will be JSON-encoded if dict/list)</p> required <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If not connected to broker</p> <code>ValueError</code> <p>If topic name is invalid</p> <code>TimeoutError</code> <p>If publish operation times out</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if connected to MQTT broker.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if connected, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.sensors.simulators.serial","title":"serial","text":"<p>Serial sensor simulator backend implementation (placeholder).</p> <p>This module will implement the SensorSimulatorBackend interface for serial/USB communication. Currently this is a placeholder that raises NotImplementedError.</p> SerialSensorSimulator <pre><code>SerialSensorSimulator(\n    port: str, baudrate: int = 9600, timeout: float = 5.0, **kwargs\n)\n</code></pre> <p>               Bases: <code>SensorSimulatorBackend</code></p> <p>Serial backend for sensor simulation (placeholder).</p> <p>This backend will connect to serial/USB ports and send sensor data commands. It implements a push-based pattern where we send sensor data to simulate physical sensor devices.</p> <p>Future implementation will: - Connect to serial ports (e.g., /dev/ttyUSB0, COM3) - Send sensor data in various formats (JSON, CSV, custom protocols) - Simulate sensor response patterns and timing - Handle communication protocols and handshaking</p> <p>Initialize Serial simulator backend.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>str</code> <p>Serial port path (e.g., \"/dev/ttyUSB0\" or \"COM3\")</p> required <code>baudrate</code> <code>int</code> <p>Serial communication baudrate</p> <code>9600</code> <code>timeout</code> <code>float</code> <p>Communication timeout in seconds</p> <code>5.0</code> <code>**kwargs</code> <p>Additional serial parameters (parity, stopbits, etc.)</p> <code>{}</code> connect <code>async</code> <pre><code>connect() -&gt; None\n</code></pre> <p>Open serial port connection.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p> disconnect <code>async</code> <pre><code>disconnect() -&gt; None\n</code></pre> <p>Close serial port connection.</p> publish_data <code>async</code> <pre><code>publish_data(address: str, data: Union[Dict[str, Any], Any]) -&gt; None\n</code></pre> <p>Send sensor data via serial port.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>Command type or data format identifier (e.g., \"TEMP_DATA\", \"JSON_FORMAT\")</p> required <code>data</code> <code>Union[Dict[str, Any], Any]</code> <p>Data to send (will be formatted according to address)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Serial simulator not yet implemented</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Check if serial port is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Always False until implementation is complete</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras","title":"stereo_cameras","text":"<p>Stereo camera support for MindTrace hardware system.</p> <p>This module provides backends and utilities for stereo camera systems that output multi-component data (intensity, disparity, depth, point clouds).</p> Available components <ul> <li>backends: Stereo camera backend implementations</li> <li>core: Core stereo camera management classes</li> <li>setup: Installation scripts for stereo camera SDKs</li> </ul> Quick Start <p>from mindtrace.hardware.stereo_cameras import StereoCamera</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras--open-first-available-stereo-camera","title":"Open first available stereo camera","text":"<p>camera = StereoCamera()</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras--capture-multi-component-data","title":"Capture multi-component data","text":"<p>result = camera.capture() print(f\"Intensity: {result.intensity.shape}\") print(f\"Disparity: {result.disparity.shape}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras--generate-point-cloud","title":"Generate point cloud","text":"<p>point_cloud = camera.capture_point_cloud() point_cloud.save_ply(\"output.ply\")</p> <p>camera.close()</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend","title":"BaslerStereoAceBackend","text":"<pre><code>BaslerStereoAceBackend(serial_number: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Backend for Basler Stereo ace cameras using pypylon.</p> <p>The Stereo ace camera is accessed through a unified device interface (DeviceClass: BaslerGTC/Basler/basler_xw) that presents the stereo pair as a single camera with multi-component output.</p> <p>Initialize Basler Stereo ace backend.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>Optional[str]</code> <p>Serial number or user-defined name of specific camera.           If all digits, treated as serial number.           Otherwise, treated as user-defined name.           If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get camera name.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.is_open","title":"is_open  <code>property</code>","text":"<pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.calibration","title":"calibration  <code>property</code>","text":"<pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.discover","title":"discover  <code>staticmethod</code>","text":"<pre><code>discover() -&gt; List[str]\n</code></pre> <p>Discover available Stereo ace cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of serial numbers for available Stereo ace cameras</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.discover_detailed","title":"discover_detailed  <code>staticmethod</code>","text":"<pre><code>discover_detailed() -&gt; List[Dict[str, str]]\n</code></pre> <p>Discover Stereo ace cameras with detailed information.</p> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List of dictionaries containing camera information</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.initialize","title":"initialize  <code>async</code>","text":"<pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_calibration","title":"get_calibration  <code>async</code>","text":"<pre><code>get_calibration() -&gt; StereoCalibrationData\n</code></pre> <p>Get factory calibration parameters from camera.</p> <p>Returns:</p> Type Description <code>StereoCalibrationData</code> <p>StereoCalibrationData with factory calibration</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If calibration cannot be read</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.capture","title":"capture  <code>async</code>","text":"<pre><code>capture(\n    timeout_ms: int = 20000,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture stereo data with multiple components.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity data</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity data</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.configure","title":"configure  <code>async</code>","text":"<pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs to configure. Special parameters:      - trigger_mode: \"continuous\" or \"trigger\"      - depth_range: tuple of (min_depth, max_depth)      - illumination_mode: \"AlwaysActive\" or \"AlternateActive\"      - binning: tuple of (horizontal, vertical)      - depth_quality: \"Full\", \"High\", \"Normal\", or \"Low\"      - All other parameters passed directly to camera</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_depth_range","title":"set_depth_range  <code>async</code>","text":"<pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth in meters (e.g., 0.3)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth in meters (e.g., 5.0)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_illumination_mode","title":"set_illumination_mode  <code>async</code>","text":"<pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_binning","title":"set_binning  <code>async</code>","text":"<pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_depth_quality","title":"set_depth_quality  <code>async</code>","text":"<pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required Note <p>Setting quality to \"Full\" with binning reduces latency while maintaining depth quality. This is recommended for low-latency applications.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_depth_quality--low-latency-configuration","title":"Low latency configuration","text":"<p>await camera.set_binning(2, 2) await camera.set_depth_quality(\"Full\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_pixel_format","title":"set_pixel_format  <code>async</code>","text":"<pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> Example <p>await camera.set_pixel_format(\"Mono8\")  # Force grayscale</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_exposure_time","title":"set_exposure_time  <code>async</code>","text":"<pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_exposure_time(5000)  # 5ms exposure</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_gain","title":"set_gain  <code>async</code>","text":"<pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_gain(2.0)</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_exposure_time","title":"get_exposure_time  <code>async</code>","text":"<pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>exposure = await camera.get_exposure_time() print(f\"Current exposure: {exposure}\u03bcs\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_gain","title":"get_gain  <code>async</code>","text":"<pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>gain = await camera.get_gain() print(f\"Current gain: {gain}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_depth_quality","title":"get_depth_quality  <code>async</code>","text":"<pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>quality = await camera.get_depth_quality() print(f\"Depth quality: {quality}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_pixel_format","title":"get_pixel_format  <code>async</code>","text":"<pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>format = await camera.get_pixel_format() print(f\"Pixel format: {format}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_binning","title":"get_binning  <code>async</code>","text":"<pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>h_bin, v_bin = await camera.get_binning() print(f\"Binning: {h_bin}x{v_bin}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_illumination_mode","title":"get_illumination_mode  <code>async</code>","text":"<pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>mode = await camera.get_illumination_mode() print(f\"Illumination: {mode}\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_depth_range","title":"get_depth_range  <code>async</code>","text":"<pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>min_d, max_d = await camera.get_depth_range() print(f\"Depth range: {min_d}m - {max_d}m\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.set_trigger_mode","title":"set_trigger_mode  <code>async</code>","text":"<pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition (TriggerMode=Off)  - \"trigger\": Software-triggered acquisition (TriggerMode=On, TriggerSource=Software)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await backend.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await backend.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_trigger_mode","title":"get_trigger_mode  <code>async</code>","text":"<pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" if TriggerMode is Off, \"trigger\" if TriggerMode is On with Software source</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await backend.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.get_trigger_modes","title":"get_trigger_modes  <code>async</code>","text":"<pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> Note <p>This provides a simplified interface. The underlying camera supports additional modes (SingleFrame, MultiFrame, hardware triggers) accessible via direct configure() calls if needed.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.start_grabbing","title":"start_grabbing  <code>async</code>","text":"<pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>This must be called before execute_trigger() in software trigger mode.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.execute_trigger","title":"execute_trigger  <code>async</code>","text":"<pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Note: In software trigger mode, ensure start_grabbing() is called first, or call capture() once before the trigger loop to start grabbing.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.BaslerStereoAceBackend.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera","title":"AsyncStereoCamera","text":"<pre><code>AsyncStereoCamera(backend)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Async stereo camera interface.</p> <p>Provides high-level stereo camera operations including multi-component capture and 3D point cloud generation.</p> <p>Initialize async stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <p>Backend instance (e.g., BaslerStereoAceBackend)</p> required"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get camera name.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.calibration","title":"calibration  <code>property</code>","text":"<pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.is_open","title":"is_open  <code>property</code>","text":"<pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.open","title":"open  <code>async</code> <code>classmethod</code>","text":"<pre><code>open(name: Optional[str] = None) -&gt; 'AsyncStereoCamera'\n</code></pre> <p>Open and initialize a stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Returns:</p> Type Description <code>'AsyncStereoCamera'</code> <p>Initialized AsyncStereoCamera instance</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera not found</p> <code>CameraConnectionError</code> <p>If connection fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = await AsyncStereoCamera.open()\n&gt;&gt;&gt; camera = await AsyncStereoCamera.open(\"BaslerStereoAce:40644640\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.initialize","title":"initialize  <code>async</code>","text":"<pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera and load calibration.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful</p> Note <p>Usually not needed as open() handles initialization</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.capture","title":"capture  <code>async</code>","text":"<pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = await camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.capture_point_cloud","title":"capture_point_cloud  <code>async</code>","text":"<pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; point_cloud = await camera.capture_point_cloud()\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; pcd = point_cloud.to_open3d()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.configure","title":"configure  <code>async</code>","text":"<pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.configure(ExposureTime=15000, Gain=2.0)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_depth_range","title":"set_depth_range  <code>async</code>","text":"<pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_depth_range(0.5, 3.0)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_illumination_mode","title":"set_illumination_mode  <code>async</code>","text":"<pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_illumination_mode(\"AlternateActive\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_binning","title":"set_binning  <code>async</code>","text":"<pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")  # Recommended for low latency\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_depth_quality","title":"set_depth_quality  <code>async</code>","text":"<pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_pixel_format","title":"set_pixel_format  <code>async</code>","text":"<pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_pixel_format(\"Mono8\")  # Force grayscale\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_exposure_time","title":"set_exposure_time  <code>async</code>","text":"<pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_exposure_time(5000)  # 5ms exposure\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_gain","title":"set_gain  <code>async</code>","text":"<pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_gain(2.0)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_exposure_time","title":"get_exposure_time  <code>async</code>","text":"<pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; exposure = await camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_gain","title":"get_gain  <code>async</code>","text":"<pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gain = await camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_depth_quality","title":"get_depth_quality  <code>async</code>","text":"<pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quality = await camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_pixel_format","title":"get_pixel_format  <code>async</code>","text":"<pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = await camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_binning","title":"get_binning  <code>async</code>","text":"<pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; h_bin, v_bin = await camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_illumination_mode","title":"get_illumination_mode  <code>async</code>","text":"<pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_depth_range","title":"get_depth_range  <code>async</code>","text":"<pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; min_d, max_d = await camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.set_trigger_mode","title":"set_trigger_mode  <code>async</code>","text":"<pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition  - \"trigger\": Software-triggered acquisition</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await camera.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_trigger_mode","title":"get_trigger_mode  <code>async</code>","text":"<pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.get_trigger_modes","title":"get_trigger_modes  <code>async</code>","text":"<pre><code>get_trigger_modes() -&gt; list[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modes = await camera.get_trigger_modes()\n&gt;&gt;&gt; print(f\"Available modes: {modes}\")\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.start_grabbing","title":"start_grabbing  <code>async</code>","text":"<pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.AsyncStereoCamera.execute_trigger","title":"execute_trigger  <code>async</code>","text":"<pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.PointCloudData","title":"PointCloudData  <code>dataclass</code>","text":"<pre><code>PointCloudData(\n    points: ndarray,\n    colors: Optional[ndarray] = None,\n    num_points: int = 0,\n    has_colors: bool = False,\n)\n</code></pre> <p>3D point cloud data with optional color information.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>ndarray</code> <p>Array of 3D points (N, 3) - (x, y, z) in meters</p> <code>colors</code> <code>Optional[ndarray]</code> <p>Optional array of RGB colors (N, 3) - values in [0, 1]</p> <code>num_points</code> <code>int</code> <p>Number of valid points</p> <code>has_colors</code> <code>bool</code> <p>Flag indicating if color information is present</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.PointCloudData.save_ply","title":"save_ply","text":"<pre><code>save_ply(path: str, binary: bool = True) -&gt; None\n</code></pre> <p>Save point cloud as PLY file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output file path</p> required <code>binary</code> <code>bool</code> <p>If True, save in binary format; otherwise ASCII</p> <code>True</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If plyfile is not installed</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.PointCloudData.to_open3d","title":"to_open3d","text":"<pre><code>to_open3d()\n</code></pre> <p>Convert to Open3D PointCloud object.</p> <p>Returns:</p> Type Description <p>open3d.geometry.PointCloud instance</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.PointCloudData.downsample","title":"downsample","text":"<pre><code>downsample(factor: int) -&gt; 'PointCloudData'\n</code></pre> <p>Downsample point cloud by given factor.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>int</code> <p>Downsampling factor (e.g., 2 = keep every 2nd point)</p> required <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with downsampled points</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.PointCloudData.remove_statistical_outliers","title":"remove_statistical_outliers","text":"<pre><code>remove_statistical_outliers(\n    nb_neighbors: int = 20, std_ratio: float = 2.0\n) -&gt; \"PointCloudData\"\n</code></pre> <p>Remove statistical outliers from point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>nb_neighbors</code> <code>int</code> <p>Number of neighbors to consider</p> <code>20</code> <code>std_ratio</code> <code>float</code> <p>Standard deviation ratio threshold</p> <code>2.0</code> <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with outliers removed</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCalibrationData","title":"StereoCalibrationData  <code>dataclass</code>","text":"<pre><code>StereoCalibrationData(\n    baseline: float,\n    focal_length: float,\n    principal_point_u: float,\n    principal_point_v: float,\n    scale3d: float,\n    offset3d: float,\n    Q: ndarray,\n)\n</code></pre> <p>Factory calibration parameters for stereo camera.</p> <p>These parameters are provided by the camera manufacturer and used for 3D reconstruction from disparity maps.</p> <p>Attributes:</p> Name Type Description <code>baseline</code> <code>float</code> <p>Stereo baseline in meters (distance between camera pair)</p> <code>focal_length</code> <code>float</code> <p>Focal length in pixels</p> <code>principal_point_u</code> <code>float</code> <p>Principal point U coordinate in pixels</p> <code>principal_point_v</code> <code>float</code> <p>Principal point V coordinate in pixels</p> <code>scale3d</code> <code>float</code> <p>Scale factor for disparity conversion</p> <code>offset3d</code> <code>float</code> <p>Offset for disparity conversion</p> <code>Q</code> <code>ndarray</code> <p>4x4 reprojection matrix for point cloud generation</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCalibrationData.from_camera_params","title":"from_camera_params  <code>classmethod</code>","text":"<pre><code>from_camera_params(params: dict) -&gt; 'StereoCalibrationData'\n</code></pre> <p>Create calibration data from camera parameter dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Dictionary containing calibration parameters: - Scan3dBaseline: Baseline in meters - Scan3dFocalLength: Focal length in pixels - Scan3dPrincipalPointU: Principal point U in pixels - Scan3dPrincipalPointV: Principal point V in pixels - Scan3dCoordinateScale: Scale factor - Scan3dCoordinateOffset: Offset</p> required <p>Returns:</p> Type Description <code>'StereoCalibrationData'</code> <p>StereoCalibrationData instance</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCalibrationData.calibrate_disparity","title":"calibrate_disparity","text":"<pre><code>calibrate_disparity(disparity: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply calibration to raw disparity map.</p> <p>Parameters:</p> Name Type Description Default <code>disparity</code> <code>ndarray</code> <p>Raw disparity map (uint16)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Calibrated disparity map (float32)</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera","title":"StereoCamera","text":"<pre><code>StereoCamera(\n    async_camera: Optional[AsyncStereoCamera] = None,\n    loop: Optional[AbstractEventLoop] = None,\n    name: Optional[str] = None,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Synchronous wrapper around AsyncStereoCamera.</p> <p>All operations are executed on a background event loop. This provides a simple synchronous API for stereo camera operations.</p> <p>Create a synchronous stereo camera wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>async_camera</code> <code>Optional[AsyncStereoCamera]</code> <p>Existing AsyncStereoCamera instance</p> <code>None</code> <code>loop</code> <code>Optional[AbstractEventLoop]</code> <p>Event loop to use for async operations</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Mindtrace</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple usage - opens first available\n&gt;&gt;&gt; camera = StereoCamera()\n</code></pre> <pre><code>&gt;&gt;&gt; # Open specific camera\n&gt;&gt;&gt; camera = StereoCamera(name=\"BaslerStereoAce:40644640\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Use existing async camera\n&gt;&gt;&gt; async_cam = await AsyncStereoCamera.open()\n&gt;&gt;&gt; sync_cam = StereoCamera(async_camera=async_cam, loop=loop)\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get camera name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Camera name in format \"Backend:serial_number\"</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.calibration","title":"calibration  <code>property</code>","text":"<pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> <p>Returns:</p> Type Description <code>Optional[StereoCalibrationData]</code> <p>StereoCalibrationData if available, None otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.is_open","title":"is_open  <code>property</code>","text":"<pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if camera is open, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # ... use camera ...\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.capture","title":"capture","text":"<pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.capture_point_cloud","title":"capture_point_cloud","text":"<pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; point_cloud = camera.capture_point_cloud()\n&gt;&gt;&gt; print(f\"Points: {point_cloud.num_points}\")\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.configure","title":"configure","text":"<pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.configure(ExposureTime=15000, Gain=2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_depth_range","title":"set_depth_range","text":"<pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_depth_range(0.5, 3.0)\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_illumination_mode","title":"set_illumination_mode","text":"<pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_illumination_mode(\"AlternateActive\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_binning","title":"set_binning","text":"<pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")  # Recommended for low latency\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_depth_quality","title":"set_depth_quality","text":"<pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_pixel_format","title":"set_pixel_format","text":"<pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_pixel_format(\"Mono8\")  # Force grayscale\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_exposure_time","title":"set_exposure_time","text":"<pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_exposure_time(5000)  # 5ms exposure\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.set_gain","title":"set_gain","text":"<pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_gain(2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_exposure_time","title":"get_exposure_time","text":"<pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; exposure = camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_gain","title":"get_gain","text":"<pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; gain = camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_depth_quality","title":"get_depth_quality","text":"<pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; quality = camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_pixel_format","title":"get_pixel_format","text":"<pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; format = camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_binning","title":"get_binning","text":"<pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; h_bin, v_bin = camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_illumination_mode","title":"get_illumination_mode","text":"<pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; mode = camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.get_depth_range","title":"get_depth_range","text":"<pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; min_d, max_d = camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.enable_software_trigger","title":"enable_software_trigger","text":"<pre><code>enable_software_trigger() -&gt; None\n</code></pre> <p>Enable software triggering mode.</p> <p>After enabling, use start_grabbing(), then execute_trigger() to capture frames on demand.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()  # Start grabbing first!\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.start_grabbing","title":"start_grabbing","text":"<pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoCamera.execute_trigger","title":"execute_trigger","text":"<pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; camera.execute_trigger()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoGrabResult","title":"StereoGrabResult  <code>dataclass</code>","text":"<pre><code>StereoGrabResult(\n    intensity: Optional[ndarray],\n    disparity: Optional[ndarray],\n    timestamp: float,\n    frame_number: int,\n    disparity_calibrated: Optional[ndarray] = None,\n    has_intensity: bool = True,\n    has_disparity: bool = True,\n)\n</code></pre> <p>Result from stereo camera capture containing multi-component data.</p> <p>Attributes:</p> Name Type Description <code>intensity</code> <code>Optional[ndarray]</code> <p>Intensity image - RGB8 (H, W, 3) or Mono8 (H, W)</p> <code>disparity</code> <code>Optional[ndarray]</code> <p>Disparity map - uint16 (H, W)</p> <code>timestamp</code> <code>float</code> <p>Capture timestamp in seconds</p> <code>frame_number</code> <code>int</code> <p>Sequential frame number</p> <code>disparity_calibrated</code> <code>Optional[ndarray]</code> <p>Calibrated disparity map - float32 (H, W), optional</p> <code>has_intensity</code> <code>bool</code> <p>Flag indicating if intensity data is present</p> <code>has_disparity</code> <code>bool</code> <p>Flag indicating if disparity data is present</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoGrabResult.intensity_shape","title":"intensity_shape  <code>property</code>","text":"<pre><code>intensity_shape: tuple\n</code></pre> <p>Get shape of intensity image.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoGrabResult.disparity_shape","title":"disparity_shape  <code>property</code>","text":"<pre><code>disparity_shape: tuple\n</code></pre> <p>Get shape of disparity map.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.StereoGrabResult.is_color_intensity","title":"is_color_intensity  <code>property</code>","text":"<pre><code>is_color_intensity: bool\n</code></pre> <p>Check if intensity is color (RGB) vs grayscale.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends","title":"backends","text":"<p>Stereo camera backends.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends.BaslerStereoAceBackend","title":"BaslerStereoAceBackend","text":"<pre><code>BaslerStereoAceBackend(serial_number: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Backend for Basler Stereo ace cameras using pypylon.</p> <p>The Stereo ace camera is accessed through a unified device interface (DeviceClass: BaslerGTC/Basler/basler_xw) that presents the stereo pair as a single camera with multi-component output.</p> <p>Initialize Basler Stereo ace backend.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>Optional[str]</code> <p>Serial number or user-defined name of specific camera.           If all digits, treated as serial number.           Otherwise, treated as user-defined name.           If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> discover <code>staticmethod</code> <pre><code>discover() -&gt; List[str]\n</code></pre> <p>Discover available Stereo ace cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of serial numbers for available Stereo ace cameras</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> discover_detailed <code>staticmethod</code> <pre><code>discover_detailed() -&gt; List[Dict[str, str]]\n</code></pre> <p>Discover Stereo ace cameras with detailed information.</p> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List of dictionaries containing camera information</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> initialize <code>async</code> <pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful, False otherwise</p> get_calibration <code>async</code> <pre><code>get_calibration() -&gt; StereoCalibrationData\n</code></pre> <p>Get factory calibration parameters from camera.</p> <p>Returns:</p> Type Description <code>StereoCalibrationData</code> <p>StereoCalibrationData with factory calibration</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If calibration cannot be read</p> capture <code>async</code> <pre><code>capture(\n    timeout_ms: int = 20000,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture stereo data with multiple components.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity data</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity data</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> configure <code>async</code> <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs to configure. Special parameters:      - trigger_mode: \"continuous\" or \"trigger\"      - depth_range: tuple of (min_depth, max_depth)      - illumination_mode: \"AlwaysActive\" or \"AlternateActive\"      - binning: tuple of (horizontal, vertical)      - depth_quality: \"Full\", \"High\", \"Normal\", or \"Low\"      - All other parameters passed directly to camera</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_range <code>async</code> <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth in meters (e.g., 0.3)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth in meters (e.g., 5.0)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_illumination_mode <code>async</code> <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_binning <code>async</code> <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_quality <code>async</code> <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required Note <p>Setting quality to \"Full\" with binning reduces latency while maintaining depth quality. This is recommended for low-latency applications.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example set_pixel_format <code>async</code> <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> Example <p>await camera.set_pixel_format(\"Mono8\")  # Force grayscale</p> set_exposure_time <code>async</code> <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_exposure_time(5000)  # 5ms exposure</p> set_gain <code>async</code> <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_gain(2.0)</p> get_exposure_time <code>async</code> <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>exposure = await camera.get_exposure_time() print(f\"Current exposure: {exposure}\u03bcs\")</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>gain = await camera.get_gain() print(f\"Current gain: {gain}\")</p> get_depth_quality <code>async</code> <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>quality = await camera.get_depth_quality() print(f\"Depth quality: {quality}\")</p> get_pixel_format <code>async</code> <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>format = await camera.get_pixel_format() print(f\"Pixel format: {format}\")</p> get_binning <code>async</code> <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>h_bin, v_bin = await camera.get_binning() print(f\"Binning: {h_bin}x{v_bin}\")</p> get_illumination_mode <code>async</code> <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>mode = await camera.get_illumination_mode() print(f\"Illumination: {mode}\")</p> get_depth_range <code>async</code> <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>min_d, max_d = await camera.get_depth_range() print(f\"Depth range: {min_d}m - {max_d}m\")</p> set_trigger_mode <code>async</code> <pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition (TriggerMode=Off)  - \"trigger\": Software-triggered acquisition (TriggerMode=On, TriggerSource=Software)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await backend.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await backend.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre> get_trigger_mode <code>async</code> <pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" if TriggerMode is Off, \"trigger\" if TriggerMode is On with Software source</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await backend.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> Note <p>This provides a simplified interface. The underlying camera supports additional modes (SingleFrame, MultiFrame, hardware triggers) accessible via direct configure() calls if needed.</p> start_grabbing <code>async</code> <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>This must be called before execute_trigger() in software trigger mode.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> execute_trigger <code>async</code> <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Note: In software trigger mode, ensure start_grabbing() is called first, or call capture() once before the trigger loop to start grabbing.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends.BaslerStereoAceBackend.set_depth_quality--low-latency-configuration","title":"Low latency configuration","text":"<p>await camera.set_binning(2, 2) await camera.set_depth_quality(\"Full\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends.basler","title":"basler","text":"<p>Basler Stereo ace backend.</p> BaslerStereoAceBackend <pre><code>BaslerStereoAceBackend(serial_number: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Backend for Basler Stereo ace cameras using pypylon.</p> <p>The Stereo ace camera is accessed through a unified device interface (DeviceClass: BaslerGTC/Basler/basler_xw) that presents the stereo pair as a single camera with multi-component output.</p> <p>Initialize Basler Stereo ace backend.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>Optional[str]</code> <p>Serial number or user-defined name of specific camera.           If all digits, treated as serial number.           Otherwise, treated as user-defined name.           If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> discover <code>staticmethod</code> <pre><code>discover() -&gt; List[str]\n</code></pre> <p>Discover available Stereo ace cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of serial numbers for available Stereo ace cameras</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> discover_detailed <code>staticmethod</code> <pre><code>discover_detailed() -&gt; List[Dict[str, str]]\n</code></pre> <p>Discover Stereo ace cameras with detailed information.</p> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List of dictionaries containing camera information</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> initialize <code>async</code> <pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful, False otherwise</p> get_calibration <code>async</code> <pre><code>get_calibration() -&gt; StereoCalibrationData\n</code></pre> <p>Get factory calibration parameters from camera.</p> <p>Returns:</p> Type Description <code>StereoCalibrationData</code> <p>StereoCalibrationData with factory calibration</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If calibration cannot be read</p> capture <code>async</code> <pre><code>capture(\n    timeout_ms: int = 20000,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture stereo data with multiple components.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity data</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity data</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> configure <code>async</code> <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs to configure. Special parameters:      - trigger_mode: \"continuous\" or \"trigger\"      - depth_range: tuple of (min_depth, max_depth)      - illumination_mode: \"AlwaysActive\" or \"AlternateActive\"      - binning: tuple of (horizontal, vertical)      - depth_quality: \"Full\", \"High\", \"Normal\", or \"Low\"      - All other parameters passed directly to camera</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_range <code>async</code> <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth in meters (e.g., 0.3)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth in meters (e.g., 5.0)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_illumination_mode <code>async</code> <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_binning <code>async</code> <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_quality <code>async</code> <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required Note <p>Setting quality to \"Full\" with binning reduces latency while maintaining depth quality. This is recommended for low-latency applications.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example set_pixel_format <code>async</code> <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> Example <p>await camera.set_pixel_format(\"Mono8\")  # Force grayscale</p> set_exposure_time <code>async</code> <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_exposure_time(5000)  # 5ms exposure</p> set_gain <code>async</code> <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_gain(2.0)</p> get_exposure_time <code>async</code> <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>exposure = await camera.get_exposure_time() print(f\"Current exposure: {exposure}\u03bcs\")</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>gain = await camera.get_gain() print(f\"Current gain: {gain}\")</p> get_depth_quality <code>async</code> <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>quality = await camera.get_depth_quality() print(f\"Depth quality: {quality}\")</p> get_pixel_format <code>async</code> <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>format = await camera.get_pixel_format() print(f\"Pixel format: {format}\")</p> get_binning <code>async</code> <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>h_bin, v_bin = await camera.get_binning() print(f\"Binning: {h_bin}x{v_bin}\")</p> get_illumination_mode <code>async</code> <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>mode = await camera.get_illumination_mode() print(f\"Illumination: {mode}\")</p> get_depth_range <code>async</code> <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>min_d, max_d = await camera.get_depth_range() print(f\"Depth range: {min_d}m - {max_d}m\")</p> set_trigger_mode <code>async</code> <pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition (TriggerMode=Off)  - \"trigger\": Software-triggered acquisition (TriggerMode=On, TriggerSource=Software)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await backend.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await backend.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre> get_trigger_mode <code>async</code> <pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" if TriggerMode is Off, \"trigger\" if TriggerMode is On with Software source</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await backend.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> Note <p>This provides a simplified interface. The underlying camera supports additional modes (SingleFrame, MultiFrame, hardware triggers) accessible via direct configure() calls if needed.</p> start_grabbing <code>async</code> <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>This must be called before execute_trigger() in software trigger mode.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> execute_trigger <code>async</code> <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Note: In software trigger mode, ensure start_grabbing() is called first, or call capture() once before the trigger loop to start grabbing.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> basler_stereo_ace <p>Basler Stereo ace camera backend using pypylon.</p> <p>This backend provides access to Basler Stereo ace cameras which combine two ace2 Pro cameras with a pattern projector into a unified stereo vision system.</p> BaslerStereoAceBackend <pre><code>BaslerStereoAceBackend(serial_number: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Backend for Basler Stereo ace cameras using pypylon.</p> <p>The Stereo ace camera is accessed through a unified device interface (DeviceClass: BaslerGTC/Basler/basler_xw) that presents the stereo pair as a single camera with multi-component output.</p> <p>Initialize Basler Stereo ace backend.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>Optional[str]</code> <p>Serial number or user-defined name of specific camera.           If all digits, treated as serial number.           Otherwise, treated as user-defined name.           If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> discover <code>staticmethod</code> <pre><code>discover() -&gt; List[str]\n</code></pre> <p>Discover available Stereo ace cameras.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of serial numbers for available Stereo ace cameras</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> discover_detailed <code>staticmethod</code> <pre><code>discover_detailed() -&gt; List[Dict[str, str]]\n</code></pre> <p>Discover Stereo ace cameras with detailed information.</p> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List of dictionaries containing camera information</p> <p>Raises:</p> Type Description <code>SDKNotAvailableError</code> <p>If pypylon is not available</p> initialize <code>async</code> <pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful, False otherwise</p> get_calibration <code>async</code> <pre><code>get_calibration() -&gt; StereoCalibrationData\n</code></pre> <p>Get factory calibration parameters from camera.</p> <p>Returns:</p> Type Description <code>StereoCalibrationData</code> <p>StereoCalibrationData with factory calibration</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If calibration cannot be read</p> capture <code>async</code> <pre><code>capture(\n    timeout_ms: int = 20000,\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture stereo data with multiple components.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity data</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity data</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> configure <code>async</code> <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs to configure. Special parameters:      - trigger_mode: \"continuous\" or \"trigger\"      - depth_range: tuple of (min_depth, max_depth)      - illumination_mode: \"AlwaysActive\" or \"AlternateActive\"      - binning: tuple of (horizontal, vertical)      - depth_quality: \"Full\", \"High\", \"Normal\", or \"Low\"      - All other parameters passed directly to camera</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_range <code>async</code> <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth in meters (e.g., 0.3)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth in meters (e.g., 5.0)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_illumination_mode <code>async</code> <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_binning <code>async</code> <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> set_depth_quality <code>async</code> <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required Note <p>Setting quality to \"Full\" with binning reduces latency while maintaining depth quality. This is recommended for low-latency applications.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example set_pixel_format <code>async</code> <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> Example <p>await camera.set_pixel_format(\"Mono8\")  # Force grayscale</p> set_exposure_time <code>async</code> <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_exposure_time(5000)  # 5ms exposure</p> set_gain <code>async</code> <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> Example <p>await camera.set_gain(2.0)</p> get_exposure_time <code>async</code> <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>exposure = await camera.get_exposure_time() print(f\"Current exposure: {exposure}\u03bcs\")</p> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>gain = await camera.get_gain() print(f\"Current gain: {gain}\")</p> get_depth_quality <code>async</code> <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>quality = await camera.get_depth_quality() print(f\"Depth quality: {quality}\")</p> get_pixel_format <code>async</code> <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>format = await camera.get_pixel_format() print(f\"Pixel format: {format}\")</p> get_binning <code>async</code> <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>h_bin, v_bin = await camera.get_binning() print(f\"Binning: {h_bin}x{v_bin}\")</p> get_illumination_mode <code>async</code> <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>mode = await camera.get_illumination_mode() print(f\"Illumination: {mode}\")</p> get_depth_range <code>async</code> <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> Example <p>min_d, max_d = await camera.get_depth_range() print(f\"Depth range: {min_d}m - {max_d}m\")</p> set_trigger_mode <code>async</code> <pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition (TriggerMode=Off)  - \"trigger\": Software-triggered acquisition (TriggerMode=On, TriggerSource=Software)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await backend.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await backend.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre> get_trigger_mode <code>async</code> <pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" if TriggerMode is Off, \"trigger\" if TriggerMode is On with Software source</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await backend.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; List[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> Note <p>This provides a simplified interface. The underlying camera supports additional modes (SingleFrame, MultiFrame, hardware triggers) accessible via direct configure() calls if needed.</p> start_grabbing <code>async</code> <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>This must be called before execute_trigger() in software trigger mode.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> execute_trigger <code>async</code> <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Note: In software trigger mode, ensure start_grabbing() is called first, or call capture() once before the trigger loop to start grabbing.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends.basler.BaslerStereoAceBackend.set_depth_quality--low-latency-configuration","title":"Low latency configuration","text":"<p>await camera.set_binning(2, 2) await camera.set_depth_quality(\"Full\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.backends.basler.basler_stereo_ace.BaslerStereoAceBackend.set_depth_quality--low-latency-configuration","title":"Low latency configuration","text":"<p>await camera.set_binning(2, 2) await camera.set_depth_quality(\"Full\")</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core","title":"core","text":"<p>Core stereo camera interfaces and data models.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.AsyncStereoCamera","title":"AsyncStereoCamera","text":"<pre><code>AsyncStereoCamera(backend)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Async stereo camera interface.</p> <p>Provides high-level stereo camera operations including multi-component capture and 3D point cloud generation.</p> <p>Initialize async stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <p>Backend instance (e.g., BaslerStereoAceBackend)</p> required name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> open <code>async</code> <code>classmethod</code> <pre><code>open(name: Optional[str] = None) -&gt; 'AsyncStereoCamera'\n</code></pre> <p>Open and initialize a stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Returns:</p> Type Description <code>'AsyncStereoCamera'</code> <p>Initialized AsyncStereoCamera instance</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera not found</p> <code>CameraConnectionError</code> <p>If connection fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = await AsyncStereoCamera.open()\n&gt;&gt;&gt; camera = await AsyncStereoCamera.open(\"BaslerStereoAce:40644640\")\n</code></pre> initialize <code>async</code> <pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera and load calibration.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful</p> Note <p>Usually not needed as open() handles initialization</p> close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> capture <code>async</code> <pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = await camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n</code></pre> capture_point_cloud <code>async</code> <pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; point_cloud = await camera.capture_point_cloud()\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; pcd = point_cloud.to_open3d()\n</code></pre> configure <code>async</code> <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.configure(ExposureTime=15000, Gain=2.0)\n</code></pre> set_depth_range <code>async</code> <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_depth_range(0.5, 3.0)\n</code></pre> set_illumination_mode <code>async</code> <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_illumination_mode(\"AlternateActive\")\n</code></pre> set_binning <code>async</code> <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")  # Recommended for low latency\n</code></pre> set_depth_quality <code>async</code> <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")\n</code></pre> set_pixel_format <code>async</code> <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_pixel_format(\"Mono8\")  # Force grayscale\n</code></pre> set_exposure_time <code>async</code> <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_exposure_time(5000)  # 5ms exposure\n</code></pre> set_gain <code>async</code> <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_gain(2.0)\n</code></pre> get_exposure_time <code>async</code> <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; exposure = await camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n</code></pre> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gain = await camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n</code></pre> get_depth_quality <code>async</code> <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quality = await camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n</code></pre> get_pixel_format <code>async</code> <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = await camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n</code></pre> get_binning <code>async</code> <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; h_bin, v_bin = await camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n</code></pre> get_illumination_mode <code>async</code> <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n</code></pre> get_depth_range <code>async</code> <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; min_d, max_d = await camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n</code></pre> set_trigger_mode <code>async</code> <pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition  - \"trigger\": Software-triggered acquisition</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await camera.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre> get_trigger_mode <code>async</code> <pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; list[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modes = await camera.get_trigger_modes()\n&gt;&gt;&gt; print(f\"Available modes: {modes}\")\n</code></pre> start_grabbing <code>async</code> <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre> execute_trigger <code>async</code> <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.PointCloudData","title":"PointCloudData  <code>dataclass</code>","text":"<pre><code>PointCloudData(\n    points: ndarray,\n    colors: Optional[ndarray] = None,\n    num_points: int = 0,\n    has_colors: bool = False,\n)\n</code></pre> <p>3D point cloud data with optional color information.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>ndarray</code> <p>Array of 3D points (N, 3) - (x, y, z) in meters</p> <code>colors</code> <code>Optional[ndarray]</code> <p>Optional array of RGB colors (N, 3) - values in [0, 1]</p> <code>num_points</code> <code>int</code> <p>Number of valid points</p> <code>has_colors</code> <code>bool</code> <p>Flag indicating if color information is present</p> save_ply <pre><code>save_ply(path: str, binary: bool = True) -&gt; None\n</code></pre> <p>Save point cloud as PLY file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output file path</p> required <code>binary</code> <code>bool</code> <p>If True, save in binary format; otherwise ASCII</p> <code>True</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If plyfile is not installed</p> to_open3d <pre><code>to_open3d()\n</code></pre> <p>Convert to Open3D PointCloud object.</p> <p>Returns:</p> Type Description <p>open3d.geometry.PointCloud instance</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p> downsample <pre><code>downsample(factor: int) -&gt; 'PointCloudData'\n</code></pre> <p>Downsample point cloud by given factor.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>int</code> <p>Downsampling factor (e.g., 2 = keep every 2nd point)</p> required <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with downsampled points</p> remove_statistical_outliers <pre><code>remove_statistical_outliers(\n    nb_neighbors: int = 20, std_ratio: float = 2.0\n) -&gt; \"PointCloudData\"\n</code></pre> <p>Remove statistical outliers from point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>nb_neighbors</code> <code>int</code> <p>Number of neighbors to consider</p> <code>20</code> <code>std_ratio</code> <code>float</code> <p>Standard deviation ratio threshold</p> <code>2.0</code> <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with outliers removed</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.StereoCalibrationData","title":"StereoCalibrationData  <code>dataclass</code>","text":"<pre><code>StereoCalibrationData(\n    baseline: float,\n    focal_length: float,\n    principal_point_u: float,\n    principal_point_v: float,\n    scale3d: float,\n    offset3d: float,\n    Q: ndarray,\n)\n</code></pre> <p>Factory calibration parameters for stereo camera.</p> <p>These parameters are provided by the camera manufacturer and used for 3D reconstruction from disparity maps.</p> <p>Attributes:</p> Name Type Description <code>baseline</code> <code>float</code> <p>Stereo baseline in meters (distance between camera pair)</p> <code>focal_length</code> <code>float</code> <p>Focal length in pixels</p> <code>principal_point_u</code> <code>float</code> <p>Principal point U coordinate in pixels</p> <code>principal_point_v</code> <code>float</code> <p>Principal point V coordinate in pixels</p> <code>scale3d</code> <code>float</code> <p>Scale factor for disparity conversion</p> <code>offset3d</code> <code>float</code> <p>Offset for disparity conversion</p> <code>Q</code> <code>ndarray</code> <p>4x4 reprojection matrix for point cloud generation</p> from_camera_params <code>classmethod</code> <pre><code>from_camera_params(params: dict) -&gt; 'StereoCalibrationData'\n</code></pre> <p>Create calibration data from camera parameter dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Dictionary containing calibration parameters: - Scan3dBaseline: Baseline in meters - Scan3dFocalLength: Focal length in pixels - Scan3dPrincipalPointU: Principal point U in pixels - Scan3dPrincipalPointV: Principal point V in pixels - Scan3dCoordinateScale: Scale factor - Scan3dCoordinateOffset: Offset</p> required <p>Returns:</p> Type Description <code>'StereoCalibrationData'</code> <p>StereoCalibrationData instance</p> calibrate_disparity <pre><code>calibrate_disparity(disparity: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply calibration to raw disparity map.</p> <p>Parameters:</p> Name Type Description Default <code>disparity</code> <code>ndarray</code> <p>Raw disparity map (uint16)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Calibrated disparity map (float32)</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.StereoGrabResult","title":"StereoGrabResult  <code>dataclass</code>","text":"<pre><code>StereoGrabResult(\n    intensity: Optional[ndarray],\n    disparity: Optional[ndarray],\n    timestamp: float,\n    frame_number: int,\n    disparity_calibrated: Optional[ndarray] = None,\n    has_intensity: bool = True,\n    has_disparity: bool = True,\n)\n</code></pre> <p>Result from stereo camera capture containing multi-component data.</p> <p>Attributes:</p> Name Type Description <code>intensity</code> <code>Optional[ndarray]</code> <p>Intensity image - RGB8 (H, W, 3) or Mono8 (H, W)</p> <code>disparity</code> <code>Optional[ndarray]</code> <p>Disparity map - uint16 (H, W)</p> <code>timestamp</code> <code>float</code> <p>Capture timestamp in seconds</p> <code>frame_number</code> <code>int</code> <p>Sequential frame number</p> <code>disparity_calibrated</code> <code>Optional[ndarray]</code> <p>Calibrated disparity map - float32 (H, W), optional</p> <code>has_intensity</code> <code>bool</code> <p>Flag indicating if intensity data is present</p> <code>has_disparity</code> <code>bool</code> <p>Flag indicating if disparity data is present</p> intensity_shape <code>property</code> <pre><code>intensity_shape: tuple\n</code></pre> <p>Get shape of intensity image.</p> disparity_shape <code>property</code> <pre><code>disparity_shape: tuple\n</code></pre> <p>Get shape of disparity map.</p> is_color_intensity <code>property</code> <pre><code>is_color_intensity: bool\n</code></pre> <p>Check if intensity is color (RGB) vs grayscale.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.StereoCamera","title":"StereoCamera","text":"<pre><code>StereoCamera(\n    async_camera: Optional[AsyncStereoCamera] = None,\n    loop: Optional[AbstractEventLoop] = None,\n    name: Optional[str] = None,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Synchronous wrapper around AsyncStereoCamera.</p> <p>All operations are executed on a background event loop. This provides a simple synchronous API for stereo camera operations.</p> <p>Create a synchronous stereo camera wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>async_camera</code> <code>Optional[AsyncStereoCamera]</code> <p>Existing AsyncStereoCamera instance</p> <code>None</code> <code>loop</code> <code>Optional[AbstractEventLoop]</code> <p>Event loop to use for async operations</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Mindtrace</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple usage - opens first available\n&gt;&gt;&gt; camera = StereoCamera()\n</code></pre> <pre><code>&gt;&gt;&gt; # Open specific camera\n&gt;&gt;&gt; camera = StereoCamera(name=\"BaslerStereoAce:40644640\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Use existing async camera\n&gt;&gt;&gt; async_cam = await AsyncStereoCamera.open()\n&gt;&gt;&gt; sync_cam = StereoCamera(async_camera=async_cam, loop=loop)\n</code></pre> name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Camera name in format \"Backend:serial_number\"</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> <p>Returns:</p> Type Description <code>Optional[StereoCalibrationData]</code> <p>StereoCalibrationData if available, None otherwise</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if camera is open, False otherwise</p> close <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # ... use camera ...\n&gt;&gt;&gt; camera.close()\n</code></pre> capture <pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> capture_point_cloud <pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; point_cloud = camera.capture_point_cloud()\n&gt;&gt;&gt; print(f\"Points: {point_cloud.num_points}\")\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; camera.close()\n</code></pre> configure <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.configure(ExposureTime=15000, Gain=2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> set_depth_range <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_depth_range(0.5, 3.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> set_illumination_mode <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_illumination_mode(\"AlternateActive\")\n&gt;&gt;&gt; camera.close()\n</code></pre> set_binning <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")  # Recommended for low latency\n&gt;&gt;&gt; camera.close()\n</code></pre> set_depth_quality <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")\n&gt;&gt;&gt; camera.close()\n</code></pre> set_pixel_format <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_pixel_format(\"Mono8\")  # Force grayscale\n&gt;&gt;&gt; camera.close()\n</code></pre> set_exposure_time <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_exposure_time(5000)  # 5ms exposure\n&gt;&gt;&gt; camera.close()\n</code></pre> set_gain <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_gain(2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> get_exposure_time <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; exposure = camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_gain <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; gain = camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_depth_quality <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; quality = camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_pixel_format <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; format = camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_binning <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; h_bin, v_bin = camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_illumination_mode <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; mode = camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_depth_range <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; min_d, max_d = camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n&gt;&gt;&gt; camera.close()\n</code></pre> enable_software_trigger <pre><code>enable_software_trigger() -&gt; None\n</code></pre> <p>Enable software triggering mode.</p> <p>After enabling, use start_grabbing(), then execute_trigger() to capture frames on demand.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()  # Start grabbing first!\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre> start_grabbing <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre> execute_trigger <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; camera.execute_trigger()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.async_stereo_camera","title":"async_stereo_camera","text":"<p>Async stereo camera interface providing high-level stereo capture operations.</p> AsyncStereoCamera <pre><code>AsyncStereoCamera(backend)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Async stereo camera interface.</p> <p>Provides high-level stereo camera operations including multi-component capture and 3D point cloud generation.</p> <p>Initialize async stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <p>Backend instance (e.g., BaslerStereoAceBackend)</p> required name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> open <code>async</code> <code>classmethod</code> <pre><code>open(name: Optional[str] = None) -&gt; 'AsyncStereoCamera'\n</code></pre> <p>Open and initialize a stereo camera.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <p>Returns:</p> Type Description <code>'AsyncStereoCamera'</code> <p>Initialized AsyncStereoCamera instance</p> <p>Raises:</p> Type Description <code>CameraNotFoundError</code> <p>If camera not found</p> <code>CameraConnectionError</code> <p>If connection fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = await AsyncStereoCamera.open()\n&gt;&gt;&gt; camera = await AsyncStereoCamera.open(\"BaslerStereoAce:40644640\")\n</code></pre> initialize <code>async</code> <pre><code>initialize() -&gt; bool\n</code></pre> <p>Initialize camera and load calibration.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if initialization successful</p> Note <p>Usually not needed as open() handles initialization</p> close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> capture <code>async</code> <pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = await camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n</code></pre> capture_point_cloud <code>async</code> <pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; point_cloud = await camera.capture_point_cloud()\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; pcd = point_cloud.to_open3d()\n</code></pre> configure <code>async</code> <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.configure(ExposureTime=15000, Gain=2.0)\n</code></pre> set_depth_range <code>async</code> <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_depth_range(0.5, 3.0)\n</code></pre> set_illumination_mode <code>async</code> <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_illumination_mode(\"AlternateActive\")\n</code></pre> set_binning <code>async</code> <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")  # Recommended for low latency\n</code></pre> set_depth_quality <code>async</code> <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; await camera.set_binning(2, 2)\n&gt;&gt;&gt; await camera.set_depth_quality(\"Full\")\n</code></pre> set_pixel_format <code>async</code> <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_pixel_format(\"Mono8\")  # Force grayscale\n</code></pre> set_exposure_time <code>async</code> <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_exposure_time(5000)  # 5ms exposure\n</code></pre> set_gain <code>async</code> <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_gain(2.0)\n</code></pre> get_exposure_time <code>async</code> <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; exposure = await camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n</code></pre> get_gain <code>async</code> <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gain = await camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n</code></pre> get_depth_quality <code>async</code> <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quality = await camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n</code></pre> get_pixel_format <code>async</code> <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = await camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n</code></pre> get_binning <code>async</code> <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; h_bin, v_bin = await camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n</code></pre> get_illumination_mode <code>async</code> <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n</code></pre> get_depth_range <code>async</code> <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; min_d, max_d = await camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n</code></pre> set_trigger_mode <code>async</code> <pre><code>set_trigger_mode(mode: str) -&gt; None\n</code></pre> <p>Set trigger mode (simplified interface).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Trigger mode (\"continuous\" or \"trigger\")  - \"continuous\": Free-running continuous acquisition  - \"trigger\": Software-triggered acquisition</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.set_trigger_mode(\"continuous\")  # Free running\n&gt;&gt;&gt; await camera.set_trigger_mode(\"trigger\")     # Software triggered\n</code></pre> get_trigger_mode <code>async</code> <pre><code>get_trigger_mode() -&gt; str\n</code></pre> <p>Get current trigger mode (simplified interface).</p> <p>Returns:</p> Type Description <code>str</code> <p>\"continuous\" or \"trigger\"</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mode = await camera.get_trigger_mode()\n&gt;&gt;&gt; print(f\"Current mode: {mode}\")\n</code></pre> get_trigger_modes <code>async</code> <pre><code>get_trigger_modes() -&gt; list[str]\n</code></pre> <p>Get available trigger modes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported trigger modes: [\"continuous\", \"trigger\"]</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modes = await camera.get_trigger_modes()\n&gt;&gt;&gt; print(f\"Available modes: {modes}\")\n</code></pre> start_grabbing <code>async</code> <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre> execute_trigger <code>async</code> <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await camera.enable_software_trigger()\n&gt;&gt;&gt; await camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     await camera.execute_trigger()\n...     result = await camera.capture()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.models","title":"models","text":"<p>Data models for stereo camera operations.</p> <p>This module provides data structures for handling stereo camera data including multi-component capture results, calibration parameters, and 3D point clouds.</p> StereoGrabResult <code>dataclass</code> <pre><code>StereoGrabResult(\n    intensity: Optional[ndarray],\n    disparity: Optional[ndarray],\n    timestamp: float,\n    frame_number: int,\n    disparity_calibrated: Optional[ndarray] = None,\n    has_intensity: bool = True,\n    has_disparity: bool = True,\n)\n</code></pre> <p>Result from stereo camera capture containing multi-component data.</p> <p>Attributes:</p> Name Type Description <code>intensity</code> <code>Optional[ndarray]</code> <p>Intensity image - RGB8 (H, W, 3) or Mono8 (H, W)</p> <code>disparity</code> <code>Optional[ndarray]</code> <p>Disparity map - uint16 (H, W)</p> <code>timestamp</code> <code>float</code> <p>Capture timestamp in seconds</p> <code>frame_number</code> <code>int</code> <p>Sequential frame number</p> <code>disparity_calibrated</code> <code>Optional[ndarray]</code> <p>Calibrated disparity map - float32 (H, W), optional</p> <code>has_intensity</code> <code>bool</code> <p>Flag indicating if intensity data is present</p> <code>has_disparity</code> <code>bool</code> <p>Flag indicating if disparity data is present</p> intensity_shape <code>property</code> <pre><code>intensity_shape: tuple\n</code></pre> <p>Get shape of intensity image.</p> disparity_shape <code>property</code> <pre><code>disparity_shape: tuple\n</code></pre> <p>Get shape of disparity map.</p> is_color_intensity <code>property</code> <pre><code>is_color_intensity: bool\n</code></pre> <p>Check if intensity is color (RGB) vs grayscale.</p> StereoCalibrationData <code>dataclass</code> <pre><code>StereoCalibrationData(\n    baseline: float,\n    focal_length: float,\n    principal_point_u: float,\n    principal_point_v: float,\n    scale3d: float,\n    offset3d: float,\n    Q: ndarray,\n)\n</code></pre> <p>Factory calibration parameters for stereo camera.</p> <p>These parameters are provided by the camera manufacturer and used for 3D reconstruction from disparity maps.</p> <p>Attributes:</p> Name Type Description <code>baseline</code> <code>float</code> <p>Stereo baseline in meters (distance between camera pair)</p> <code>focal_length</code> <code>float</code> <p>Focal length in pixels</p> <code>principal_point_u</code> <code>float</code> <p>Principal point U coordinate in pixels</p> <code>principal_point_v</code> <code>float</code> <p>Principal point V coordinate in pixels</p> <code>scale3d</code> <code>float</code> <p>Scale factor for disparity conversion</p> <code>offset3d</code> <code>float</code> <p>Offset for disparity conversion</p> <code>Q</code> <code>ndarray</code> <p>4x4 reprojection matrix for point cloud generation</p> from_camera_params <code>classmethod</code> <pre><code>from_camera_params(params: dict) -&gt; 'StereoCalibrationData'\n</code></pre> <p>Create calibration data from camera parameter dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Dictionary containing calibration parameters: - Scan3dBaseline: Baseline in meters - Scan3dFocalLength: Focal length in pixels - Scan3dPrincipalPointU: Principal point U in pixels - Scan3dPrincipalPointV: Principal point V in pixels - Scan3dCoordinateScale: Scale factor - Scan3dCoordinateOffset: Offset</p> required <p>Returns:</p> Type Description <code>'StereoCalibrationData'</code> <p>StereoCalibrationData instance</p> calibrate_disparity <pre><code>calibrate_disparity(disparity: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply calibration to raw disparity map.</p> <p>Parameters:</p> Name Type Description Default <code>disparity</code> <code>ndarray</code> <p>Raw disparity map (uint16)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Calibrated disparity map (float32)</p> PointCloudData <code>dataclass</code> <pre><code>PointCloudData(\n    points: ndarray,\n    colors: Optional[ndarray] = None,\n    num_points: int = 0,\n    has_colors: bool = False,\n)\n</code></pre> <p>3D point cloud data with optional color information.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>ndarray</code> <p>Array of 3D points (N, 3) - (x, y, z) in meters</p> <code>colors</code> <code>Optional[ndarray]</code> <p>Optional array of RGB colors (N, 3) - values in [0, 1]</p> <code>num_points</code> <code>int</code> <p>Number of valid points</p> <code>has_colors</code> <code>bool</code> <p>Flag indicating if color information is present</p> save_ply <pre><code>save_ply(path: str, binary: bool = True) -&gt; None\n</code></pre> <p>Save point cloud as PLY file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output file path</p> required <code>binary</code> <code>bool</code> <p>If True, save in binary format; otherwise ASCII</p> <code>True</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If plyfile is not installed</p> to_open3d <pre><code>to_open3d()\n</code></pre> <p>Convert to Open3D PointCloud object.</p> <p>Returns:</p> Type Description <p>open3d.geometry.PointCloud instance</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p> downsample <pre><code>downsample(factor: int) -&gt; 'PointCloudData'\n</code></pre> <p>Downsample point cloud by given factor.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>int</code> <p>Downsampling factor (e.g., 2 = keep every 2nd point)</p> required <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with downsampled points</p> remove_statistical_outliers <pre><code>remove_statistical_outliers(\n    nb_neighbors: int = 20, std_ratio: float = 2.0\n) -&gt; \"PointCloudData\"\n</code></pre> <p>Remove statistical outliers from point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>nb_neighbors</code> <code>int</code> <p>Number of neighbors to consider</p> <code>20</code> <code>std_ratio</code> <code>float</code> <p>Standard deviation ratio threshold</p> <code>2.0</code> <p>Returns:</p> Type Description <code>'PointCloudData'</code> <p>New PointCloudData with outliers removed</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If open3d is not installed</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.core.stereo_camera","title":"stereo_camera","text":"<p>Synchronous stereo camera interface.</p> <p>This module provides a synchronous wrapper around AsyncStereoCamera, following the same pattern as the regular Camera class.</p> StereoCamera <pre><code>StereoCamera(\n    async_camera: Optional[AsyncStereoCamera] = None,\n    loop: Optional[AbstractEventLoop] = None,\n    name: Optional[str] = None,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Synchronous wrapper around AsyncStereoCamera.</p> <p>All operations are executed on a background event loop. This provides a simple synchronous API for stereo camera operations.</p> <p>Create a synchronous stereo camera wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>async_camera</code> <code>Optional[AsyncStereoCamera]</code> <p>Existing AsyncStereoCamera instance</p> <code>None</code> <code>loop</code> <code>Optional[AbstractEventLoop]</code> <p>Event loop to use for async operations</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Camera identifier. Format: \"BaslerStereoAce:serial_number\"  If None, opens first available Stereo ace camera.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Mindtrace</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple usage - opens first available\n&gt;&gt;&gt; camera = StereoCamera()\n</code></pre> <pre><code>&gt;&gt;&gt; # Open specific camera\n&gt;&gt;&gt; camera = StereoCamera(name=\"BaslerStereoAce:40644640\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Use existing async camera\n&gt;&gt;&gt; async_cam = await AsyncStereoCamera.open()\n&gt;&gt;&gt; sync_cam = StereoCamera(async_camera=async_cam, loop=loop)\n</code></pre> name <code>property</code> <pre><code>name: str\n</code></pre> <p>Get camera name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Camera name in format \"Backend:serial_number\"</p> calibration <code>property</code> <pre><code>calibration: Optional[StereoCalibrationData]\n</code></pre> <p>Get calibration data.</p> <p>Returns:</p> Type Description <code>Optional[StereoCalibrationData]</code> <p>StereoCalibrationData if available, None otherwise</p> is_open <code>property</code> <pre><code>is_open: bool\n</code></pre> <p>Check if camera is open.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if camera is open, False otherwise</p> close <pre><code>close() -&gt; None\n</code></pre> <p>Close camera and release resources.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # ... use camera ...\n&gt;&gt;&gt; camera.close()\n</code></pre> capture <pre><code>capture(\n    enable_intensity: bool = True,\n    enable_disparity: bool = True,\n    calibrate_disparity: bool = True,\n    timeout_ms: int = 20000,\n) -&gt; StereoGrabResult\n</code></pre> <p>Capture multi-component stereo data.</p> <p>Parameters:</p> Name Type Description Default <code>enable_intensity</code> <code>bool</code> <p>Whether to capture intensity image</p> <code>True</code> <code>enable_disparity</code> <code>bool</code> <p>Whether to capture disparity map</p> <code>True</code> <code>calibrate_disparity</code> <code>bool</code> <p>Whether to apply calibration to disparity</p> <code>True</code> <code>timeout_ms</code> <code>int</code> <p>Capture timeout in milliseconds</p> <code>20000</code> <p>Returns:</p> Type Description <code>StereoGrabResult</code> <p>StereoGrabResult containing captured data</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; print(f\"Intensity: {result.intensity.shape}\")\n&gt;&gt;&gt; print(f\"Disparity: {result.disparity.shape}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> capture_point_cloud <pre><code>capture_point_cloud(\n    include_colors: bool = True,\n    remove_outliers: bool = False,\n    downsample_factor: int = 1,\n) -&gt; PointCloudData\n</code></pre> <p>Capture and generate 3D point cloud.</p> <p>Parameters:</p> Name Type Description Default <code>include_colors</code> <code>bool</code> <p>Whether to include color information from intensity</p> <code>True</code> <code>remove_outliers</code> <code>bool</code> <p>Whether to remove statistical outliers</p> <code>False</code> <code>downsample_factor</code> <code>int</code> <p>Downsampling factor (1 = no downsampling)</p> <code>1</code> <p>Returns:</p> Type Description <code>PointCloudData</code> <p>PointCloudData with 3D points and optional colors</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraCaptureError</code> <p>If capture fails</p> <code>CameraConfigurationError</code> <p>If calibration not available</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; point_cloud = camera.capture_point_cloud()\n&gt;&gt;&gt; print(f\"Points: {point_cloud.num_points}\")\n&gt;&gt;&gt; point_cloud.save_ply(\"output.ply\")\n&gt;&gt;&gt; camera.close()\n</code></pre> configure <pre><code>configure(**params) -&gt; None\n</code></pre> <p>Configure camera parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**params</code> <p>Parameter name-value pairs</p> <code>{}</code> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.configure(ExposureTime=15000, Gain=2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> set_depth_range <pre><code>set_depth_range(min_depth: float, max_depth: float) -&gt; None\n</code></pre> <p>Set depth measurement range in meters.</p> <p>Parameters:</p> Name Type Description Default <code>min_depth</code> <code>float</code> <p>Minimum depth (e.g., 0.3 meters)</p> required <code>max_depth</code> <code>float</code> <p>Maximum depth (e.g., 5.0 meters)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_depth_range(0.5, 3.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> set_illumination_mode <pre><code>set_illumination_mode(mode: str) -&gt; None\n</code></pre> <p>Set illumination mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>'AlwaysActive' (low latency) or 'AlternateActive' (clean intensity)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If invalid mode or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_illumination_mode(\"AlternateActive\")\n&gt;&gt;&gt; camera.close()\n</code></pre> set_binning <pre><code>set_binning(horizontal: int = 2, vertical: int = 2) -&gt; None\n</code></pre> <p>Enable binning for latency reduction.</p> <p>Binning reduces network transfer and computation.</p> <p>Parameters:</p> Name Type Description Default <code>horizontal</code> <code>int</code> <p>Horizontal binning factor (typically 2)</p> <code>2</code> <code>vertical</code> <code>int</code> <p>Vertical binning factor (typically 2)</p> <code>2</code> Note <p>When using binning for low latency, consider also setting depth quality to \"Full\" using set_depth_quality(\"Full\").</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")  # Recommended for low latency\n&gt;&gt;&gt; camera.close()\n</code></pre> set_depth_quality <pre><code>set_depth_quality(quality: str) -&gt; None\n</code></pre> <p>Set depth quality level.</p> <p>Parameters:</p> Name Type Description Default <code>quality</code> <code>str</code> <p>Depth quality setting. Common values:     - \"Full\": Highest quality, recommended with binning     - \"Normal\": Standard quality     - \"Low\": Lower quality, faster processing</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; # Low latency configuration\n&gt;&gt;&gt; camera.set_binning(2, 2)\n&gt;&gt;&gt; camera.set_depth_quality(\"Full\")\n&gt;&gt;&gt; camera.close()\n</code></pre> set_pixel_format <pre><code>set_pixel_format(format: str) -&gt; None\n</code></pre> <p>Set pixel format for intensity component.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Pixel format (\"RGB8\", \"Mono8\", etc.)</p> required <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If format not available or configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_pixel_format(\"Mono8\")  # Force grayscale\n&gt;&gt;&gt; camera.close()\n</code></pre> set_exposure_time <pre><code>set_exposure_time(microseconds: float) -&gt; None\n</code></pre> <p>Set exposure time in microseconds.</p> <p>Parameters:</p> Name Type Description Default <code>microseconds</code> <code>float</code> <p>Exposure time in microseconds (e.g., 5000 = 5ms)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_exposure_time(5000)  # 5ms exposure\n&gt;&gt;&gt; camera.close()\n</code></pre> set_gain <pre><code>set_gain(gain: float) -&gt; None\n</code></pre> <p>Set camera gain.</p> <p>Parameters:</p> Name Type Description Default <code>gain</code> <code>float</code> <p>Gain value (typically 0.0 to 24.0, camera-dependent)</p> required <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.set_gain(2.0)\n&gt;&gt;&gt; camera.close()\n</code></pre> get_exposure_time <pre><code>get_exposure_time() -&gt; float\n</code></pre> <p>Get current exposure time in microseconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current exposure time in microseconds</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; exposure = camera.get_exposure_time()\n&gt;&gt;&gt; print(f\"Exposure: {exposure}\u03bcs\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_gain <pre><code>get_gain() -&gt; float\n</code></pre> <p>Get current camera gain.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current gain value</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; gain = camera.get_gain()\n&gt;&gt;&gt; print(f\"Gain: {gain}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_depth_quality <pre><code>get_depth_quality() -&gt; str\n</code></pre> <p>Get current depth quality setting.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current depth quality level (e.g., \"Full\", \"Normal\", \"Low\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; quality = camera.get_depth_quality()\n&gt;&gt;&gt; print(f\"Quality: {quality}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_pixel_format <pre><code>get_pixel_format() -&gt; str\n</code></pre> <p>Get current pixel format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current pixel format (e.g., \"RGB8\", \"Mono8\", \"Coord3D_C16\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; format = camera.get_pixel_format()\n&gt;&gt;&gt; print(f\"Format: {format}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_binning <pre><code>get_binning() -&gt; tuple[int, int]\n</code></pre> <p>Get current binning settings.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Tuple of (horizontal_binning, vertical_binning)</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; h_bin, v_bin = camera.get_binning()\n&gt;&gt;&gt; print(f\"Binning: {h_bin}x{v_bin}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_illumination_mode <pre><code>get_illumination_mode() -&gt; str\n</code></pre> <p>Get current illumination mode.</p> <p>Returns:</p> Type Description <code>str</code> <p>Current illumination mode (\"AlwaysActive\" or \"AlternateActive\")</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; mode = camera.get_illumination_mode()\n&gt;&gt;&gt; print(f\"Illumination: {mode}\")\n&gt;&gt;&gt; camera.close()\n</code></pre> get_depth_range <pre><code>get_depth_range() -&gt; tuple[float, float]\n</code></pre> <p>Get current depth measurement range in meters.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (min_depth, max_depth) in meters</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; min_d, max_d = camera.get_depth_range()\n&gt;&gt;&gt; print(f\"Range: {min_d}m - {max_d}m\")\n&gt;&gt;&gt; camera.close()\n</code></pre> enable_software_trigger <pre><code>enable_software_trigger() -&gt; None\n</code></pre> <p>Enable software triggering mode.</p> <p>After enabling, use start_grabbing(), then execute_trigger() to capture frames on demand.</p> <p>Raises:</p> Type Description <code>CameraConfigurationError</code> <p>If configuration fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()  # Start grabbing first!\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre> start_grabbing <pre><code>start_grabbing() -&gt; None\n</code></pre> <p>Start grabbing frames.</p> <p>Must be called after enable_software_trigger() and before execute_trigger().</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; for i in range(10):\n...     camera.execute_trigger()\n...     result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre> execute_trigger <pre><code>execute_trigger() -&gt; None\n</code></pre> <p>Execute software trigger.</p> <p>Triggers a frame capture when in software trigger mode. Note: start_grabbing() must be called first after enabling software trigger.</p> <p>Raises:</p> Type Description <code>CameraConnectionError</code> <p>If camera not opened</p> <code>CameraConfigurationError</code> <p>If trigger execution fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; camera = StereoCamera()\n&gt;&gt;&gt; camera.enable_software_trigger()\n&gt;&gt;&gt; camera.start_grabbing()\n&gt;&gt;&gt; camera.execute_trigger()\n&gt;&gt;&gt; result = camera.capture()\n&gt;&gt;&gt; camera.close()\n</code></pre>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.setup","title":"setup","text":"<p>Setup scripts for stereo camera SDKs.</p> <p>This module provides installation scripts for stereo camera systems.</p> <p>Available CLI commands (after package installation):     mindtrace-stereo-basler install     # Install Stereo ace package     mindtrace-stereo-basler uninstall   # Uninstall Stereo ace package</p> <p>Each setup script uses Typer for CLI and can be run independently.</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.setup.StereoAceInstaller","title":"StereoAceInstaller","text":"<pre><code>StereoAceInstaller(\n    installation_method: str = \"tarball\",\n    install_dir: Optional[str] = None,\n    package_path: Optional[str] = None,\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Basler Stereo ace Supplementary Package installer with guided wizard.</p> <p>This class provides an interactive installation wizard that guides users through downloading and installing the Stereo ace package from the official Basler website.</p> <p>Initialize the Stereo ace installer.</p> <p>Parameters:</p> Name Type Description Default <code>installation_method</code> <code>str</code> <p>Installation method (\"deb\" or \"tarball\")</p> <code>'tarball'</code> <code>install_dir</code> <code>Optional[str]</code> <p>Custom installation directory (for tarball method)</p> <code>None</code> <code>package_path</code> <code>Optional[str]</code> <p>Path to pre-downloaded package file (optional)</p> <code>None</code> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Stereo ace Supplementary Package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Stereo ace Supplementary Package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p>"},{"location":"hardware/api/#mindtrace.hardware.stereo_cameras.setup.setup_stereo_ace","title":"setup_stereo_ace","text":"<p>Basler Stereo ace Setup Script</p> <p>This script provides a guided installation wizard for the Basler pylon Supplementary Package for Stereo ace cameras on Linux systems. The package provides the GenTL Producer needed to connect and use Stereo ace camera systems.</p> <p>Features: - Interactive guided wizard with browser integration - Supports both Debian package (.deb) and tar.gz archive installation - Custom installation path support (default: ~/.local/share/pylon_stereo) - Environment variable setup for GenTL Producer - Shell environment script generation - Support for pre-downloaded packages (--package flag) - Comprehensive logging and error handling - Uninstallation support</p> Installation Methods <ol> <li>Debian Package (Recommended - requires sudo):</li> <li>Installs to /opt/pylon</li> <li>Automatic environment configuration</li> <li> <p>System-wide availability</p> </li> <li> <p>tar.gz Archive (Portable - no sudo):</p> </li> <li>Installs to user-specified or default directory</li> <li>Requires manual environment setup</li> <li>Per-user installation</li> </ol> Usage <p>python setup_stereo_ace.py                           # Interactive wizard python setup_stereo_ace.py --method deb              # Use Debian package python setup_stereo_ace.py --method tarball          # Use tar.gz archive python setup_stereo_ace.py --package /path/to/file   # Use pre-downloaded file python setup_stereo_ace.py --install-dir ~/pylon     # Custom install location python setup_stereo_ace.py --uninstall               # Uninstall mindtrace-stereo-basler-install                      # Console script (install) mindtrace-stereo-basler-uninstall                    # Console script (uninstall)</p> Environment Setup <p>After installation, you must set environment variables:</p> <p>For Debian package:     source /opt/pylon/bin/pylon-setup-env.sh /opt/pylon</p> <p>For tar.gz archive:     source /setup_stereo_env.sh <p>Or add to ~/.bashrc for persistence:     echo \"source /setup_stereo_env.sh\" &gt;&gt; ~/.bashrc StereoAceInstaller <pre><code>StereoAceInstaller(\n    installation_method: str = \"tarball\",\n    install_dir: Optional[str] = None,\n    package_path: Optional[str] = None,\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Basler Stereo ace Supplementary Package installer with guided wizard.</p> <p>This class provides an interactive installation wizard that guides users through downloading and installing the Stereo ace package from the official Basler website.</p> <p>Initialize the Stereo ace installer.</p> <p>Parameters:</p> Name Type Description Default <code>installation_method</code> <code>str</code> <p>Installation method (\"deb\" or \"tarball\")</p> <code>'tarball'</code> <code>install_dir</code> <code>Optional[str]</code> <p>Custom installation directory (for tarball method)</p> <code>None</code> <code>package_path</code> <code>Optional[str]</code> <p>Path to pre-downloaded package file (optional)</p> <code>None</code> install <pre><code>install() -&gt; bool\n</code></pre> <p>Install the Stereo ace Supplementary Package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if installation successful, False otherwise</p> uninstall <pre><code>uninstall() -&gt; bool\n</code></pre> <p>Uninstall the Stereo ace Supplementary Package.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if uninstallation successful, False otherwise</p> install <pre><code>install(\n    method: str = typer.Option(\n        \"tarball\",\n        \"--method\",\n        \"-m\",\n        help=\"Installation method: 'deb' (requires sudo) or 'tarball' (portable)\",\n    ),\n    package: Optional[Path] = typer.Option(\n        None,\n        \"--package\",\n        \"-p\",\n        help=\"Path to pre-downloaded package file (.deb or .tar.gz)\",\n        exists=True,\n        dir_okay=False,\n    ),\n    install_dir: Optional[Path] = typer.Option(\n        None,\n        \"--install-dir\",\n        \"-d\",\n        help=\"Custom installation directory (for tarball method)\",\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Install the Basler Stereo ace Supplementary Package using an interactive wizard.</p> <p>The wizard will guide you through downloading and installing the package from Basler's official website where you'll accept their EULA.</p> <p>For CI/automation, use --package to provide a pre-downloaded file.</p> uninstall <pre><code>uninstall(\n    method: str = typer.Option(\n        \"tarball\",\n        \"--method\",\n        \"-m\",\n        help=\"Installation method used: 'deb' or 'tarball'\",\n    ),\n    install_dir: Optional[Path] = typer.Option(\n        None,\n        \"--install-dir\",\n        \"-d\",\n        help=\"Custom installation directory (for tarball method)\",\n    ),\n    verbose: bool = typer.Option(\n        False, \"--verbose\", \"-v\", help=\"Enable verbose logging\"\n    ),\n) -&gt; None\n</code></pre> <p>Uninstall the Basler Stereo ace Supplementary Package.</p> main <pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the script.</p>"},{"location":"jobs/","title":"Jobs","text":""},{"location":"jobs/#mindtrace-jobs","title":"Mindtrace Jobs","text":"<p>A job queue system that works with different backends (local, Redis, RabbitMQ).</p>"},{"location":"jobs/#backends","title":"Backends","text":"<ul> <li>Local</li> <li>Redis</li> <li>RabbitMQ</li> </ul> <p>Setup Redis: <pre><code># Local installation\nredis-server\n\n# Using Docker\ndocker run -d --name redis -p 6379:6379 redis:latest\n\n# Test connection\nredis-cli ping \n</code></pre></p>"},{"location":"jobs/#rabbitmq-backend","title":"RabbitMQ Backend","text":"<p>Setup RabbitMQ: <pre><code># Using Docker (recommended)\ndocker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password rabbitmq:3-management\n</code></pre></p> <p>Core Components: - <code>Consumer</code> - Base class for processing jobs - <code>Orchestrator</code> - Manages job queues and routing - <code>Job</code>, <code>JobSchema</code> - Job data structures - <code>LocalClient</code>, <code>RedisClient</code>, <code>RabbitMQClient</code> - Backend implementations</p>"},{"location":"jobs/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    Consumer[\"Your Consumer&lt;br/&gt;MathsConsumer('maths_operations')\"] \n    Orchestrator[\"Orchestrator\"]\n    Schema[\"Job Schema&lt;br/&gt;(maths_operations)\"]\n    Job[\"Job Instance\"]\n    Queue[\"Queue&lt;br/&gt;(maths_operations)\"]\n\n    LocalClient[\"LocalClient\"]\n    RedisClient[\"RedisClient&lt;br/&gt;(requires Redis server)\"] \n    RabbitMQClient[\"RabbitMQClient&lt;br/&gt;(requires RabbitMQ server)\"]\n\n    Consumer --&gt; Orchestrator\n    Schema --&gt; Orchestrator\n    Job --&gt; Orchestrator\n    Orchestrator --&gt; Queue\n\n    Orchestrator -.-&gt; LocalClient\n    Orchestrator -.-&gt; RedisClient\n    Orchestrator -.-&gt; RabbitMQClient\n\n    Queue --&gt; Consumer</code></pre>"},{"location":"jobs/#basic-example","title":"Basic Example","text":"<pre><code>from mindtrace.jobs import Orchestrator, LocalClient, Consumer, JobSchema, job_from_schema\nfrom pydantic import BaseModel\n\n# Set up the orchestrator with local backend\norchestrator = Orchestrator(LocalClient())\n\n# Define your job input/output models (inherit from BaseModel directly)\nclass MathsInput(BaseModel):\n    operation: str = \"add\"\n    a: float = 2.0\n    b: float = 1.0\n\nclass MathsOutput(BaseModel):\n    result: float = 0.0\n    operation_performed: str = \"\"\n\nschema = JobSchema(name=\"maths_operations\", input_schema=MathsInput, output_schema=MathsOutput)\norchestrator.register(schema)\n\n# Create a consumer\nclass MathsConsumer(Consumer):\n    def run(self, job_dict: dict) -&gt; dict:\n        # Access input data from the dict\n        input_data = job_dict.get('input_data', {})\n        operation = input_data.get('operation', 'add')\n        a = input_data.get('a')\n        b = input_data.get('b')\n\n        # Your processing logic here\n        if operation == \"add\":\n            result = a + b\n        elif operation == \"multiply\":\n            result = a * b\n        elif operation == \"power\":\n            result = a ** b\n        else:\n            raise ValueError(f\"Unknown operation: {operation}\")\n\n        return {\n            \"result\": result,\n            \"operation_performed\": f\"{operation}({a}, {b}) = {result}\"\n        }\n\n# Connect and consume jobs\nconsumer = MathsConsumer(\"maths_operations\")\nconsumer.connect(orchestrator)\n\n# Add a job to the queue\njob = job_from_schema(schema, MathsInput(\n    operation=\"multiply\",\n    a=7.0,\n    b=3.0\n))\norchestrator.publish(\"maths_operations\", job)\n\n# Process jobs\nconsumer.consume(num_messages=1)\n</code></pre>"},{"location":"jobs/#using-different-backends","title":"Using Different Backends","text":""},{"location":"jobs/#redis-backend","title":"Redis Backend","text":"<pre><code>from mindtrace.jobs import RedisClient\n\nredis_backend = RedisClient(host=\"localhost\", port=6379, db=0)\norchestrator = Orchestrator(redis_backend)\n\nconsumer = MathsConsumer(\"maths_operations\")\nconsumer.connect(orchestrator)\nconsumer.consume()\n</code></pre>"},{"location":"jobs/#rabbitmq-backend_1","title":"RabbitMQ Backend","text":"<pre><code>from mindtrace.jobs import RabbitMQClient\n\nrabbitmq_backend = RabbitMQClient(\n    host=\"localhost\", \n    port=5672, \n    username=\"user\", \n    password=\"password\"\n)\norchestrator = Orchestrator(rabbitmq_backend)\n\nconsumer = MathsConsumer(\"maths_operations\")\nconsumer.connect(orchestrator)\nconsumer.consume()\n</code></pre>"},{"location":"jobs/#backend-switching","title":"Backend Switching","text":"<p>The job system supports seamless switching between backends without changing your consumer code:</p> <pre><code># Development: Use local backend\nbackend = LocalClient()\n\n# Testing: Switch to Redis\nbackend = RedisClient(host=\"localhost\", port=6379, db=0)\n\n# Production: Switch to RabbitMQ  \nbackend = RabbitMQClient(host=\"localhost\", port=5672, username=\"user\", password=\"password\")\n\n# Same orchestrator and consumer code works with any backend\norchestrator = Orchestrator(backend)\nconsumer = MathsConsumer(\"maths_operations\")\nconsumer.connect(orchestrator)\nconsumer.consume()\n</code></pre>"},{"location":"jobs/#automatic-backend-detection","title":"Automatic Backend Detection","text":"<p>When you connect a consumer, the orchestrator automatically detects the backend type and creates the appropriate consumer backend:</p> <pre><code>consumer = MathsConsumer(\"maths_operations\")\nconsumer.connect(orchestrator)  # Automatically detects backend type\n</code></pre> <p>Implementation:</p> <ol> <li>The <code>Orchestrator</code> detects its backend type using <code>type(self.backend).__name__</code></li> <li>Creates the corresponding consumer backend:</li> <li><code>LocalClient</code> \u2192 <code>LocalConsumerBackend</code></li> <li><code>RedisClient</code> \u2192 <code>RedisConsumerBackend</code> </li> <li><code>RabbitMQClient</code> \u2192 <code>RabbitMQConsumerBackend</code></li> </ol> <pre><code>def create_consumer_backend_for_schema(self, schema: JobSchema) -&gt; ConsumerBackendBase:\n    backend_type = type(self.backend).__name__\n    if backend_type == \"LocalClient\":\n        return LocalConsumerBackend(queue_name, self)\n    elif backend_type == \"RedisClient\":\n        return RedisConsumerBackend(queue_name, self, poll_timeout=5)\n    elif backend_type == \"RabbitMQClient\":\n        return RabbitMQConsumerBackend(queue_name, self, prefetch_count=1)\n</code></pre>"},{"location":"jobs/#priority-queues","title":"Priority Queues","text":""},{"location":"jobs/#local-priority-queue","title":"Local Priority Queue","text":"<pre><code># Declare priority queue\nbackend = LocalClient()\norchestrator = Orchestrator(backend)\nbackend.declare_queue(\"priority_tasks\", queue_type=\"priority\")\n\n# Publish with different priorities (higher numbers = higher priority)\norchestrator.publish(\"priority_tasks\", urgent_job, priority=10)\norchestrator.publish(\"priority_tasks\", normal_job, priority=5)\norchestrator.publish(\"priority_tasks\", background_job, priority=1)\n</code></pre>"},{"location":"jobs/#redis-priority-queue","title":"Redis Priority Queue","text":"<pre><code># REQUIRES: Redis server running\nredis_backend = RedisClient(host=\"localhost\", port=6379, db=0)\norchestrator = Orchestrator(redis_backend)\nredis_backend.declare_queue(\"redis_priority\", queue_type=\"priority\")\n\n# Higher priority jobs processed first\norchestrator.publish(\"redis_priority\", critical_job, priority=100)\norchestrator.publish(\"redis_priority\", normal_job, priority=50)\n</code></pre>"},{"location":"jobs/#rabbitmq-priority-queue","title":"RabbitMQ Priority Queue","text":"<pre><code># REQUIRES: RabbitMQ server running\nrabbitmq_backend = RabbitMQClient(host=\"localhost\", port=5672, username=\"user\", password=\"password\")\norchestrator = Orchestrator(rabbitmq_backend)\n# RabbitMQ supports max priority 0-255\nrabbitmq_backend.declare_queue(\"rabbitmq_priority\", max_priority=255)\n\norchestrator.publish(\"rabbitmq_priority\", critical_job, priority=255)\norchestrator.publish(\"rabbitmq_priority\", normal_job, priority=128)\n</code></pre>"},{"location":"jobs/#api-reference","title":"API Reference","text":""},{"location":"jobs/#consumer","title":"Consumer","text":"<pre><code>class Consumer:\n    def __init__(self, job_type_name: str)\n    def connect(self, orchestrator: Orchestrator)\n    def consume(self, num_messages: Optional[int] = None)\n    def run(self, job_dict: dict) -&gt; dict  # Implement this method\n</code></pre>"},{"location":"jobs/#orchestrator","title":"Orchestrator","text":"<pre><code>class Orchestrator:\n    def __init__(self, backend)\n    def register(self, schema: JobSchema) -&gt; str\n    def publish(self, queue_name: str, job: Job, **kwargs) -&gt; str\n    def receive_message(self, queue_name: str) -&gt; Optional[dict]\n    def count_queue_messages(self, queue_name: str) -&gt; int\n</code></pre>"},{"location":"jobs/api/","title":"Jobs Package API Reference","text":""},{"location":"jobs/api/#mindtrace.jobs.LocalClient","title":"LocalClient","text":"<pre><code>LocalClient(\n    client_dir: str | Path | None = None,\n    broker_id: str | None = None,\n    backend: Registry | None = None,\n)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>A registry-backed local job client.</p> <p>The client maintains a registry of declared queues and a store for job results. Queues are stored in a registry. Job results can be stored to a separate internal registry as well.</p> <p>Initialize the LocalClient.</p> <p>Parameters:</p> Name Type Description Default <code>client_dir</code> <code>str | Path | None</code> <p>The directory to store the client. If None, uses the default from config.</p> <code>None</code> <code>broker_id</code> <code>str | None</code> <p>The ID of the broker.</p> <code>None</code> <code>backend</code> <code>Registry | None</code> <p>The backend to use for storage. If None, uses the default from config.</p> <code>None</code>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.declare_queue","title":"declare_queue","text":"<pre><code>declare_queue(\n    queue_name: str, queue_type: str = \"fifo\", **kwargs\n) -&gt; dict[str, str]\n</code></pre> <p>Declare a queue of type 'fifo', 'stack', or 'priority'.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.publish","title":"publish","text":"<pre><code>publish(queue_name: str, message: BaseModel, **kwargs)\n</code></pre> <p>Publish a message (as a pydantic model) to the specified queue. If the target queue is a priority queue, accepts an extra 'priority' parameter.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.receive_message","title":"receive_message","text":"<pre><code>receive_message(queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from the specified queue.</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>The name of the queue to receive a message from.</p> required <code>**kwargs</code> <p>Additional parameters passed to the queue instance.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[dict]</code> <p>The message as a dict or None if queue is empty.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.clean_queue","title":"clean_queue","text":"<pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Remove all messages from the specified queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.count_queue_messages","title":"count_queue_messages","text":"<pre><code>count_queue_messages(queue_name: str, **kwargs) -&gt; int\n</code></pre> <p>Return the number of messages in the specified queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.store_job_result","title":"store_job_result","text":"<pre><code>store_job_result(job_id: str, result: Any)\n</code></pre> <p>Save the job result (JSON-serializable) keyed by job_id.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.get_job_result","title":"get_job_result","text":"<pre><code>get_job_result(job_id: str) -&gt; Any\n</code></pre> <p>Retrieve the stored result for the given job_id.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalClient.move_to_dlq","title":"move_to_dlq","text":"<pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalConsumerBackend","title":"LocalConsumerBackend","text":"<pre><code>LocalConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    orchestrator: LocalClient,\n    poll_timeout: float = 1,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>Local in-memory consumer backend.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalConsumerBackend.consume","title":"consume","text":"<pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the local queue(s).</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalConsumerBackend.consume_until_empty","title":"consume_until_empty","text":"<pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalConsumerBackend.process_message","title":"process_message","text":"<pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalQueue","title":"LocalQueue","text":"<pre><code>LocalQueue()\n</code></pre>"},{"location":"jobs/api/#mindtrace.jobs.LocalQueue.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert queue contents to a JSON-serializable dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalQueue.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Create a LocalQueue from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalPriorityQueue","title":"LocalPriorityQueue","text":"<pre><code>LocalPriorityQueue()\n</code></pre>"},{"location":"jobs/api/#mindtrace.jobs.LocalPriorityQueue.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert priority queue contents to a JSON-serializable dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalPriorityQueue.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Create a LocalPriorityQueue from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalStack","title":"LocalStack","text":"<pre><code>LocalStack()\n</code></pre>"},{"location":"jobs/api/#mindtrace.jobs.LocalStack.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert stack contents to a JSON-serializable dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.LocalStack.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Create a LocalStack from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient","title":"RabbitMQClient","text":"<pre><code>RabbitMQClient(\n    host: str | None = None,\n    port: int | None = None,\n    username: str | None = None,\n    password: str | None = None,\n)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>Initialize the RabbitMQ client with connection parameters. Args:     host: RabbitMQ server hostname.     port: RabbitMQ server port.     username: Username for RabbitMQ authentication.     password: Password for RabbitMQ authentication.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.declare_exchange","title":"declare_exchange","text":"<pre><code>declare_exchange(\n    *,\n    exchange: str,\n    exchange_type: str = \"direct\",\n    durable: bool = True,\n    auto_delete: bool = False,\n    **kwargs\n)\n</code></pre> <p>Declare a RabbitMQ exchange. Args:     exchange: Name of the exchange to declare.     exchange_type: Type of the exchange (e.g., 'direct', 'topic', 'fanout').     durable: Make the exchange durable.     auto_delete: Automatically delete the exchange when no queues are bound.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.declare_queue","title":"declare_queue","text":"<pre><code>declare_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Declare a RabbitMQ queue. Args:     queue: Name of the queue to declare.     exchange: Name of the exchange to bind the queue to.     durable: Make the queue durable.     exclusive: Make the queue exclusive to the connection.     auto_delete: Automatically delete the queue when no consumers are connected.     routing_key: Routing key for binding the queue to the exchange.     force: Force exchange creation if it doesn't exist.     max_priority: Maximum priority for priority queue (0-255).</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.publish","title":"publish","text":"<pre><code>publish(queue_name: str, message: BaseModel, **kwargs)\n</code></pre> <p>Publish a message to the specified exchange using RabbitMQ. Args:     queue_name: The queue name to use as default routing key.     message: A Pydantic BaseModel payload.     exchange: The RabbitMQ exchange to use (from kwargs).     routing_key: The routing key to use (from kwargs, defaults to queue_name).     durable: Messages that are not durable are discarded if they cannot be routed to an existing consumer (from kwargs).     delivery_mode: Use DeliveryMode.Persistent to save messages to disk (from kwargs).     mandatory: If True, unroutable messages are returned (from kwargs). Returns:     str: The generated job ID for the message.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.clean_queue","title":"clean_queue","text":"<pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Remove all messages from a queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.delete_queue","title":"delete_queue","text":"<pre><code>delete_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Delete a queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.count_exchanges","title":"count_exchanges","text":"<pre><code>count_exchanges(*, exchange: str, **kwargs)\n</code></pre> <p>Get the number of exchanges in the RabbitMQ server. Args:     exchange: Name of the exchange to check.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.delete_exchange","title":"delete_exchange","text":"<pre><code>delete_exchange(*, exchange: str, **kwargs)\n</code></pre> <p>Delete an exchange.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQClient.move_to_dlq","title":"move_to_dlq","text":"<pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQConsumerBackend","title":"RabbitMQConsumerBackend","text":"<pre><code>RabbitMQConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    prefetch_count: int = 1,\n    auto_ack: bool = False,\n    durable: bool = True,\n    host: str | None = None,\n    port: int | None = None,\n    username: str | None = None,\n    password: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>RabbitMQ consumer backend with improved consumption logic.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQConsumerBackend.consume","title":"consume","text":"<pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from RabbitMQ queue(s) with robust error handling.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQConsumerBackend.process_message","title":"process_message","text":"<pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message and return success status.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQConsumerBackend.consume_until_empty","title":"consume_until_empty","text":"<pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p>"},{"location":"jobs/api/#mindtrace.jobs.RabbitMQConsumerBackend.receive_message","title":"receive_message","text":"<pre><code>receive_message(channel, queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from a specified RabbitMQ queue. This method uses RabbitMQ's basic_get method to fetch a message. It supports blocking behavior by polling until a message is available or the timeout is reached. Args:     queue_name: The name of the queue from which to receive the message.     block: Whether to block until a message is available.     timeout: Maximum time in seconds to block if no message is available.     auto_ack: Whether to automatically acknowledge the message upon retrieval.     **kwargs: Additional keyword arguments to pass to basic_get (if any). Returns:     dict: The message content as a dictionary, or None if no message is available.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient","title":"RedisClient","text":"<pre><code>RedisClient(host: str = 'localhost', port: int = 6379, db: int = 0)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>Initialize the Redis client and connect to the Redis server. Args:     host: Redis server hostname.     port: Redis server port.     db: Redis database number.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.declare_queue","title":"declare_queue","text":"<pre><code>declare_queue(\n    queue_name: str, queue_type: str = \"fifo\", **kwargs\n) -&gt; dict[str, str]\n</code></pre> <p>Declare a Redis-backed queue of type 'fifo', 'stack', or 'priority'.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.delete_queue","title":"delete_queue","text":"<pre><code>delete_queue(queue_name: str, **kwargs) -&gt; dict\n</code></pre> <p>Delete a declared queue. Uses distributed locking and transactions to remove the queue from the centralized metadata, and publishes an event to notify other clients.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.publish","title":"publish","text":"<pre><code>publish(queue_name: str, message: BaseModel, **kwargs) -&gt; str\n</code></pre> <p>Publish a message (a pydantic model) to the specified Redis queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.clean_queue","title":"clean_queue","text":"<pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Clean (purge) a specified Redis queue by deleting its underlying key.</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>The name of the declared queue to be cleaned.</p> required"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.move_to_dlq","title":"move_to_dlq","text":"<pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisClient.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the Redis connection and clean up resources.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend","title":"RedisConsumerBackend","text":"<pre><code>RedisConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    host: str,\n    port: int,\n    db: int,\n    poll_timeout: int = 5,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>Redis consumer backend with blocking operations.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.consume","title":"consume","text":"<pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from Redis queue(s).</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.process_message","title":"process_message","text":"<pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.consume_until_empty","title":"consume_until_empty","text":"<pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the Redis connection and clean up resources.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.set_poll_timeout","title":"set_poll_timeout","text":"<pre><code>set_poll_timeout(timeout: int) -&gt; None\n</code></pre> <p>Set the polling timeout for Redis operations.</p>"},{"location":"jobs/api/#mindtrace.jobs.RedisConsumerBackend.receive_message","title":"receive_message","text":"<pre><code>receive_message(queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from a specified Redis queue.</p> <p>Returns the message as a dict.</p>"},{"location":"jobs/api/#mindtrace.jobs.Job","title":"Job","text":"<p>               Bases: <code>BaseModel</code></p> <p>A job instance ready for execution - system routes based on schema_name.</p>"},{"location":"jobs/api/#mindtrace.jobs.job_from_schema","title":"job_from_schema","text":"<pre><code>job_from_schema(schema: JobSchema, input_data) -&gt; Job\n</code></pre> <p>Create a Job from a JobSchema and input data.</p> <p>This function automatically adds metadata like job ID and creation timestamp. Args:     schema: The JobSchema to use for the job     input_data: The input data for the job Returns:     Job: A complete Job instance ready for submission</p>"},{"location":"jobs/api/#mindtrace.jobs.base","title":"base","text":""},{"location":"jobs/api/#mindtrace.jobs.base.connection_base","title":"connection_base","text":""},{"location":"jobs/api/#mindtrace.jobs.base.connection_base.BrokerConnectionBase","title":"BrokerConnectionBase","text":"<pre><code>BrokerConnectionBase(*args, **kwargs)\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for broker connections.</p>"},{"location":"jobs/api/#mindtrace.jobs.base.consumer_base","title":"consumer_base","text":""},{"location":"jobs/api/#mindtrace.jobs.base.consumer_base.ConsumerBackendBase","title":"ConsumerBackendBase","text":"<pre><code>ConsumerBackendBase(queue_name: str, consumer_frontend: 'Consumer')\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Base class for consumer backends that handle message consumption.</p> consume <code>abstractmethod</code> <pre><code>consume(num_messages: int = 0, **kwargs) -&gt; None\n</code></pre> <p>Consume messages from the queue and process them.</p> consume_until_empty <code>abstractmethod</code> <pre><code>consume_until_empty(**kwargs) -&gt; None\n</code></pre> <p>Consume messages until the queue is empty and process them.</p> process_message <code>abstractmethod</code> <pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message using the stored run method.</p>"},{"location":"jobs/api/#mindtrace.jobs.base.orchestrator_backend","title":"orchestrator_backend","text":""},{"location":"jobs/api/#mindtrace.jobs.base.orchestrator_backend.OrchestratorBackend","title":"OrchestratorBackend","text":"<pre><code>OrchestratorBackend()\n</code></pre> <p>               Bases: <code>MindtraceABC</code></p> <p>Abstract base class for orchestrator backends.</p> <p>Defines the interface that all backend implementations must follow for queue management operations.</p> create_consumer_backend <pre><code>create_consumer_backend(\n    consumer_frontend: Consumer, queue_name: str\n) -&gt; ConsumerBackendBase\n</code></pre> <p>Create a consumer backend for the given schema and consumer frontend.</p> declare_queue <code>abstractmethod</code> <pre><code>declare_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Declare a queue</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>Name of the queue to declare</p> required publish <code>abstractmethod</code> <pre><code>publish(queue_name: str, message: BaseModel, **kwargs) -&gt; str\n</code></pre> <p>Publish a message to the specified queue</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>Name of the queue to publish to</p> required <code>message</code> <code>BaseModel</code> <p>Pydantic model to publish</p> required clean_queue <code>abstractmethod</code> <pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Remove all messages from the specified queue</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>Name of the queue to clean</p> required delete_queue <code>abstractmethod</code> <pre><code>delete_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Delete the specified queue</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>Name of the queue to delete</p> required count_queue_messages <code>abstractmethod</code> <pre><code>count_queue_messages(queue_name: str, **kwargs) -&gt; int\n</code></pre> <p>Count the number of messages in the specified queue</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>Name of the queue to count</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of messages in the queue</p> move_to_dlq <code>abstractmethod</code> <pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p> declare_exchange <pre><code>declare_exchange(**kwargs)\n</code></pre> <p>Declare an exchange. Only implemented in RabbitMQ backend.</p> delete_exchange <pre><code>delete_exchange(**kwargs)\n</code></pre> <p>Delete an exchange. Only implemented in RabbitMQ backend.</p> count_exchanges <pre><code>count_exchanges(**kwargs)\n</code></pre> <p>Count the number of exchanges. Only implemented in RabbitMQ backend.</p>"},{"location":"jobs/api/#mindtrace.jobs.local","title":"local","text":""},{"location":"jobs/api/#mindtrace.jobs.local.client","title":"client","text":""},{"location":"jobs/api/#mindtrace.jobs.local.client.LocalClient","title":"LocalClient","text":"<pre><code>LocalClient(\n    client_dir: str | Path | None = None,\n    broker_id: str | None = None,\n    backend: Registry | None = None,\n)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>A registry-backed local job client.</p> <p>The client maintains a registry of declared queues and a store for job results. Queues are stored in a registry. Job results can be stored to a separate internal registry as well.</p> <p>Initialize the LocalClient.</p> <p>Parameters:</p> Name Type Description Default <code>client_dir</code> <code>str | Path | None</code> <p>The directory to store the client. If None, uses the default from config.</p> <code>None</code> <code>broker_id</code> <code>str | None</code> <p>The ID of the broker.</p> <code>None</code> <code>backend</code> <code>Registry | None</code> <p>The backend to use for storage. If None, uses the default from config.</p> <code>None</code> declare_queue <pre><code>declare_queue(\n    queue_name: str, queue_type: str = \"fifo\", **kwargs\n) -&gt; dict[str, str]\n</code></pre> <p>Declare a queue of type 'fifo', 'stack', or 'priority'.</p> publish <pre><code>publish(queue_name: str, message: BaseModel, **kwargs)\n</code></pre> <p>Publish a message (as a pydantic model) to the specified queue. If the target queue is a priority queue, accepts an extra 'priority' parameter.</p> receive_message <pre><code>receive_message(queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from the specified queue.</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>The name of the queue to receive a message from.</p> required <code>**kwargs</code> <p>Additional parameters passed to the queue instance.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[dict]</code> <p>The message as a dict or None if queue is empty.</p> clean_queue <pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Remove all messages from the specified queue.</p> count_queue_messages <pre><code>count_queue_messages(queue_name: str, **kwargs) -&gt; int\n</code></pre> <p>Return the number of messages in the specified queue.</p> store_job_result <pre><code>store_job_result(job_id: str, result: Any)\n</code></pre> <p>Save the job result (JSON-serializable) keyed by job_id.</p> get_job_result <pre><code>get_job_result(job_id: str) -&gt; Any\n</code></pre> <p>Retrieve the stored result for the given job_id.</p> move_to_dlq <pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p>"},{"location":"jobs/api/#mindtrace.jobs.local.consumer_backend","title":"consumer_backend","text":""},{"location":"jobs/api/#mindtrace.jobs.local.consumer_backend.LocalConsumerBackend","title":"LocalConsumerBackend","text":"<pre><code>LocalConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    orchestrator: LocalClient,\n    poll_timeout: float = 1,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>Local in-memory consumer backend.</p> consume <pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the local queue(s).</p> consume_until_empty <pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p> process_message <pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.fifo_queue","title":"fifo_queue","text":""},{"location":"jobs/api/#mindtrace.jobs.local.fifo_queue.LocalQueue","title":"LocalQueue","text":"<pre><code>LocalQueue()\n</code></pre> to_dict <pre><code>to_dict()\n</code></pre> <p>Convert queue contents to a JSON-serializable dictionary.</p> from_dict <code>classmethod</code> <pre><code>from_dict(data)\n</code></pre> <p>Create a LocalQueue from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.fifo_queue.LocalQueueArchiver","title":"LocalQueueArchiver","text":"<pre><code>LocalQueueArchiver(uri: str, **kwargs)\n</code></pre> <p>               Bases: <code>Archiver</code></p> <p>Archiver for LocalQueue objects using JSON serialization.</p> save <pre><code>save(item: LocalQueue)\n</code></pre> <p>Save a LocalQueue object to JSON.</p> load <pre><code>load(data_type: Type[Any]) -&gt; LocalQueue\n</code></pre> <p>Load a LocalQueue object from JSON.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.priority_queue","title":"priority_queue","text":""},{"location":"jobs/api/#mindtrace.jobs.local.priority_queue.LocalPriorityQueue","title":"LocalPriorityQueue","text":"<pre><code>LocalPriorityQueue()\n</code></pre> to_dict <pre><code>to_dict()\n</code></pre> <p>Convert priority queue contents to a JSON-serializable dictionary.</p> from_dict <code>classmethod</code> <pre><code>from_dict(data)\n</code></pre> <p>Create a LocalPriorityQueue from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.priority_queue.PriorityQueueArchiver","title":"PriorityQueueArchiver","text":"<pre><code>PriorityQueueArchiver(uri: str, **kwargs)\n</code></pre> <p>               Bases: <code>Archiver</code></p> <p>Archiver for LocalPriorityQueue objects using JSON serialization.</p> save <pre><code>save(item: LocalPriorityQueue)\n</code></pre> <p>Save a LocalPriorityQueue object to JSON.</p> load <pre><code>load(data_type: Type[Any]) -&gt; LocalPriorityQueue\n</code></pre> <p>Load a LocalPriorityQueue object from JSON.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.stack","title":"stack","text":""},{"location":"jobs/api/#mindtrace.jobs.local.stack.LocalStack","title":"LocalStack","text":"<pre><code>LocalStack()\n</code></pre> to_dict <pre><code>to_dict()\n</code></pre> <p>Convert stack contents to a JSON-serializable dictionary.</p> from_dict <code>classmethod</code> <pre><code>from_dict(data)\n</code></pre> <p>Create a LocalStack from a dictionary.</p>"},{"location":"jobs/api/#mindtrace.jobs.local.stack.StackArchiver","title":"StackArchiver","text":"<pre><code>StackArchiver(uri: str, **kwargs)\n</code></pre> <p>               Bases: <code>Archiver</code></p> <p>Archiver for LocalStack objects using JSON serialization.</p> save <pre><code>save(item: LocalStack)\n</code></pre> <p>Save a LocalStack object to JSON.</p> load <pre><code>load(data_type: Type[Any]) -&gt; LocalStack\n</code></pre> <p>Load a LocalStack object from JSON.</p>"},{"location":"jobs/api/#mindtrace.jobs.rabbitmq","title":"rabbitmq","text":""},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.client","title":"client","text":""},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.client.RabbitMQClient","title":"RabbitMQClient","text":"<pre><code>RabbitMQClient(\n    host: str | None = None,\n    port: int | None = None,\n    username: str | None = None,\n    password: str | None = None,\n)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>Initialize the RabbitMQ client with connection parameters. Args:     host: RabbitMQ server hostname.     port: RabbitMQ server port.     username: Username for RabbitMQ authentication.     password: Password for RabbitMQ authentication.</p> declare_exchange <pre><code>declare_exchange(\n    *,\n    exchange: str,\n    exchange_type: str = \"direct\",\n    durable: bool = True,\n    auto_delete: bool = False,\n    **kwargs\n)\n</code></pre> <p>Declare a RabbitMQ exchange. Args:     exchange: Name of the exchange to declare.     exchange_type: Type of the exchange (e.g., 'direct', 'topic', 'fanout').     durable: Make the exchange durable.     auto_delete: Automatically delete the exchange when no queues are bound.</p> declare_queue <pre><code>declare_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Declare a RabbitMQ queue. Args:     queue: Name of the queue to declare.     exchange: Name of the exchange to bind the queue to.     durable: Make the queue durable.     exclusive: Make the queue exclusive to the connection.     auto_delete: Automatically delete the queue when no consumers are connected.     routing_key: Routing key for binding the queue to the exchange.     force: Force exchange creation if it doesn't exist.     max_priority: Maximum priority for priority queue (0-255).</p> publish <pre><code>publish(queue_name: str, message: BaseModel, **kwargs)\n</code></pre> <p>Publish a message to the specified exchange using RabbitMQ. Args:     queue_name: The queue name to use as default routing key.     message: A Pydantic BaseModel payload.     exchange: The RabbitMQ exchange to use (from kwargs).     routing_key: The routing key to use (from kwargs, defaults to queue_name).     durable: Messages that are not durable are discarded if they cannot be routed to an existing consumer (from kwargs).     delivery_mode: Use DeliveryMode.Persistent to save messages to disk (from kwargs).     mandatory: If True, unroutable messages are returned (from kwargs). Returns:     str: The generated job ID for the message.</p> clean_queue <pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Remove all messages from a queue.</p> delete_queue <pre><code>delete_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Delete a queue.</p> count_exchanges <pre><code>count_exchanges(*, exchange: str, **kwargs)\n</code></pre> <p>Get the number of exchanges in the RabbitMQ server. Args:     exchange: Name of the exchange to check.</p> delete_exchange <pre><code>delete_exchange(*, exchange: str, **kwargs)\n</code></pre> <p>Delete an exchange.</p> move_to_dlq <pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p>"},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.connection","title":"connection","text":""},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.connection.RabbitMQConnection","title":"RabbitMQConnection","text":"<pre><code>RabbitMQConnection(\n    host: str | None = None,\n    port: int | None = None,\n    username: str | None = None,\n    password: str | None = None,\n)\n</code></pre> <p>               Bases: <code>BrokerConnectionBase</code></p> <p>Singleton class for RabbitMQ connection. The use of a singleton class ensures that only one connection is established throughout an application.</p> <p>Initialize the RabbitMQ connection. Args:     host: The host address of the RabbitMQ server.     port: The port number of the RabbitMQ server.     username: The username for the RabbitMQ server.     password: The password for the RabbitMQ server.</p> connect <pre><code>connect()\n</code></pre> <p>Connect to the RabbitMQ server.</p> is_connected <pre><code>is_connected()\n</code></pre> <p>Check if the connection to the RabbitMQ server is open.</p> close <pre><code>close()\n</code></pre> <p>Close the connection to the RabbitMQ server.</p> get_channel <pre><code>get_channel() -&gt; BlockingChannel\n</code></pre> <p>Get a channel from the RabbitMQ connection.</p> count_queue_messages <pre><code>count_queue_messages(queue_name: str, **kwargs) -&gt; int\n</code></pre> <p>Get the number of messages in a queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.consumer_backend","title":"consumer_backend","text":""},{"location":"jobs/api/#mindtrace.jobs.rabbitmq.consumer_backend.RabbitMQConsumerBackend","title":"RabbitMQConsumerBackend","text":"<pre><code>RabbitMQConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    prefetch_count: int = 1,\n    auto_ack: bool = False,\n    durable: bool = True,\n    host: str | None = None,\n    port: int | None = None,\n    username: str | None = None,\n    password: str | None = None,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>RabbitMQ consumer backend with improved consumption logic.</p> consume <pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from RabbitMQ queue(s) with robust error handling.</p> process_message <pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message and return success status.</p> consume_until_empty <pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p> receive_message <pre><code>receive_message(channel, queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from a specified RabbitMQ queue. This method uses RabbitMQ's basic_get method to fetch a message. It supports blocking behavior by polling until a message is available or the timeout is reached. Args:     queue_name: The name of the queue from which to receive the message.     block: Whether to block until a message is available.     timeout: Maximum time in seconds to block if no message is available.     auto_ack: Whether to automatically acknowledge the message upon retrieval.     **kwargs: Additional keyword arguments to pass to basic_get (if any). Returns:     dict: The message content as a dictionary, or None if no message is available.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis","title":"redis","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.client","title":"client","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.client.RedisClient","title":"RedisClient","text":"<pre><code>RedisClient(host: str = 'localhost', port: int = 6379, db: int = 0)\n</code></pre> <p>               Bases: <code>OrchestratorBackend</code></p> <p>Initialize the Redis client and connect to the Redis server. Args:     host: Redis server hostname.     port: Redis server port.     db: Redis database number.</p> declare_queue <pre><code>declare_queue(\n    queue_name: str, queue_type: str = \"fifo\", **kwargs\n) -&gt; dict[str, str]\n</code></pre> <p>Declare a Redis-backed queue of type 'fifo', 'stack', or 'priority'.</p> delete_queue <pre><code>delete_queue(queue_name: str, **kwargs) -&gt; dict\n</code></pre> <p>Delete a declared queue. Uses distributed locking and transactions to remove the queue from the centralized metadata, and publishes an event to notify other clients.</p> publish <pre><code>publish(queue_name: str, message: BaseModel, **kwargs) -&gt; str\n</code></pre> <p>Publish a message (a pydantic model) to the specified Redis queue.</p> clean_queue <pre><code>clean_queue(queue_name: str, **kwargs) -&gt; dict[str, str]\n</code></pre> <p>Clean (purge) a specified Redis queue by deleting its underlying key.</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>The name of the declared queue to be cleaned.</p> required move_to_dlq <pre><code>move_to_dlq(\n    source_queue: str,\n    dlq_name: str,\n    message: BaseModel,\n    error_details: str,\n    **kwargs\n)\n</code></pre> <p>Move a failed message to a dead letter queue</p> close <pre><code>close()\n</code></pre> <p>Close the Redis connection and clean up resources.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis.connection","title":"connection","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.connection.RedisConnection","title":"RedisConnection","text":"<pre><code>RedisConnection(\n    host: str | None = None,\n    port: int | None = None,\n    db: int | None = None,\n    password: str | None = None,\n    socket_timeout: float | None = None,\n    socket_connect_timeout: float | None = None,\n)\n</code></pre> <p>               Bases: <code>BrokerConnectionBase</code></p> <p>Initialize the Redis connection. Args:     host: The Redis server host address.     port: The Redis server port.     db: The Redis database number.     password: The password for the Redis server (if any).     socket_timeout: Timeout for socket operations (in seconds).     socket_connect_timeout: Timeout for socket connect (in seconds).</p> EVENTS_CHANNEL <code>class-attribute</code> <code>instance-attribute</code> <pre><code>EVENTS_CHANNEL = 'mindtrace:queue_events'\n</code></pre> <p>Singleton class for Redis connection. This class establishes and maintains a connection to the Redis server. It uses a retry loop and a PING command to verify connectivity.</p> connect <pre><code>connect(max_tries: int = 10)\n</code></pre> <p>Connect to the Redis server using a retry loop.</p> is_connected <pre><code>is_connected() -&gt; bool\n</code></pre> <p>Return True if the connection to Redis is active (verified via PING).</p> close <pre><code>close()\n</code></pre> <p>Close the connection to the Redis server and shutdown background thread.</p> count_queue_messages <pre><code>count_queue_messages(queue_name: str, **kwargs) -&gt; int\n</code></pre> <p>Count the number of messages in a specified Redis queue.</p> <p>Parameters:</p> Name Type Description Default <code>queue_name</code> <code>str</code> <p>The name of the declared queue.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of messages in the given queue.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis.consumer_backend","title":"consumer_backend","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.consumer_backend.RedisConsumerBackend","title":"RedisConsumerBackend","text":"<pre><code>RedisConsumerBackend(\n    queue_name: str,\n    consumer_frontend,\n    host: str,\n    port: int,\n    db: int,\n    poll_timeout: int = 5,\n)\n</code></pre> <p>               Bases: <code>ConsumerBackendBase</code></p> <p>Redis consumer backend with blocking operations.</p> consume <pre><code>consume(\n    num_messages: int = 0,\n    *,\n    queues: str | list[str] | None = None,\n    block: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from Redis queue(s).</p> process_message <pre><code>process_message(message) -&gt; bool\n</code></pre> <p>Process a single message.</p> consume_until_empty <pre><code>consume_until_empty(\n    *, queues: str | list[str] | None = None, block: bool = True, **kwargs\n) -&gt; None\n</code></pre> <p>Consume messages from the queue(s) until empty.</p> close <pre><code>close()\n</code></pre> <p>Close the Redis connection and clean up resources.</p> set_poll_timeout <pre><code>set_poll_timeout(timeout: int) -&gt; None\n</code></pre> <p>Set the polling timeout for Redis operations.</p> receive_message <pre><code>receive_message(queue_name: str, **kwargs) -&gt; Optional[dict]\n</code></pre> <p>Retrieve a message from a specified Redis queue.</p> <p>Returns the message as a dict.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis.fifo_queue","title":"fifo_queue","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.fifo_queue.RedisQueue","title":"RedisQueue","text":"<pre><code>RedisQueue(name, namespace='queue', **redis_kwargs)\n</code></pre> <p>A FIFO (first-in, first-out) message queue backed by Redis. This class uses a Redis list to store serialized messages. The <code>put</code> method pushes items to the tail of the list, while the <code>get</code> method pops from the head. Blocking retrieval is implemented using Redis' BLPOP command.</p> <p>Initialize a RedisQueue object. Args:     name: Name of the queue.     namespace: Namespace prefix for the Redis key.     redis_kwargs: Additional keyword arguments for redis.Redis.</p> push <pre><code>push(item)\n</code></pre> <p>Serialize and add an item to the queue.</p> pop <pre><code>pop(block=True, timeout=None)\n</code></pre> <p>Remove and return an item from the queue. Args:     block: If True, block until an item is available.     timeout: Maximum time to block in seconds (if block=True). Raises:     queue.Empty: If no item is available (in non-blocking mode or if the timeout expires).</p> qsize <pre><code>qsize()\n</code></pre> <p>Return the approximate size of the queue.</p> empty <pre><code>empty()\n</code></pre> <p>Return True if the queue is empty, False otherwise.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis.priority","title":"priority","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.priority.RedisPriorityQueue","title":"RedisPriorityQueue","text":"<pre><code>RedisPriorityQueue(name, namespace='priority_queue', **redis_kwargs)\n</code></pre> <p>A priority message queue backed by Redis. This class uses a Redis sorted set to store messages with priorities. Higher numerical priority values are retrieved first (higher priority).</p> push <pre><code>push(item, priority=0)\n</code></pre> <p>Serialize and add an item to the priority queue. Args:     item: The item to add to the queue.     priority: Priority value (higher numbers = higher priority).</p> pop <pre><code>pop(block=True, timeout=None)\n</code></pre> <p>Remove and return the highest priority item from the queue. Args:     block: If True, block until an item is available.     timeout: Maximum time to block in seconds (if block=True). Raises:     queue.Empty: If no item is available (in non-blocking mode or if the timeout expires).</p> qsize <pre><code>qsize()\n</code></pre> <p>Return the approximate size of the priority queue.</p> empty <pre><code>empty()\n</code></pre> <p>Return True if the priority queue is empty, False otherwise.</p>"},{"location":"jobs/api/#mindtrace.jobs.redis.stack","title":"stack","text":""},{"location":"jobs/api/#mindtrace.jobs.redis.stack.RedisStack","title":"RedisStack","text":"<pre><code>RedisStack(name, namespace='stack', **redis_kwargs)\n</code></pre> <p>A LIFO (last-in, first-out) message stack backed by Redis. This class uses a Redis list to store serialized messages. The <code>push</code> method pushes items to the head of the list, while the <code>pop</code> method pops from the head. Blocking retrieval is implemented using Redis' BLPOP command.</p> push <pre><code>push(item)\n</code></pre> <p>Serialize and add an item to the stack.</p> pop <pre><code>pop(block=True, timeout=None)\n</code></pre> <p>Remove and return the top item from the stack. Args:     block: If True, block until an item is available.     timeout: Maximum time to block in seconds (if block=True). Raises:      queue.Empty: If no item is available (non-blocking or timeout reached).</p> qsize <pre><code>qsize()\n</code></pre> <p>Return the approximate size of the stack.</p> empty <pre><code>empty()\n</code></pre> <p>Return True if the stack is empty, False otherwise.</p>"},{"location":"jobs/api/#mindtrace.jobs.types","title":"types","text":""},{"location":"jobs/api/#mindtrace.jobs.types.job_specs","title":"job_specs","text":""},{"location":"jobs/api/#mindtrace.jobs.types.job_specs.Job","title":"Job","text":"<p>               Bases: <code>BaseModel</code></p> <p>A job instance ready for execution - system routes based on schema_name.</p>"},{"location":"jobs/api/#mindtrace.jobs.utils","title":"utils","text":""},{"location":"jobs/api/#mindtrace.jobs.utils.schemas","title":"schemas","text":""},{"location":"jobs/api/#mindtrace.jobs.utils.schemas.job_from_schema","title":"job_from_schema","text":"<pre><code>job_from_schema(schema: JobSchema, input_data) -&gt; Job\n</code></pre> <p>Create a Job from a JobSchema and input data.</p> <p>This function automatically adds metadata like job ID and creation timestamp. Args:     schema: The JobSchema to use for the job     input_data: The input data for the job Returns:     Job: A complete Job instance ready for submission</p>"},{"location":"services/","title":"Services","text":""},{"location":"services/#mindtrace-services","title":"Mindtrace Services","text":"<p>Purpose Installation Architecture Auto-generation for Connection Managers Usage Example Testing &amp; Coverage API Reference MCP Integration: Exposing Service Endpoints as Tools Remote MCP Server Usage with Cursor</p> <p>The <code>mindtrace-services</code> module provides the core microservice framework for the Mindtrace ecosystem. It enables rapid development, deployment, and management of distributed services with robust and auto generated connection management, and comprehensive testing support.</p>"},{"location":"services/#purpose","title":"Purpose","text":"<ul> <li>Service Class: Unified base for all Mindtrace microservices, inspired by the ServerBase component from the mtrix package (now renamed to <code>Service</code>).</li> <li>Auto-Generated Connection Managers: Connect to services with auto-generated client interfaces.</li> <li>Endpoint Management: Strongly-typed, schema-driven endpoint registration and validation.</li> <li>Stress Testing: Built-in support for stress, integration, and unit testing.</li> </ul>"},{"location":"services/#installation","title":"Installation","text":"<pre><code>uv add mindtrace-services\n</code></pre>"},{"location":"services/#architecture","title":"Architecture","text":"<ul> <li>Service (<code>Service</code>): Base class for all services, providing endpoint registration, FastAPI integration, and lifecycle management.</li> <li>ConnectionManager: Client-side helper for communicating with any Mindtrace service. Auto-generated if not explicitly registered.</li> <li>Endpoint Schemas: All endpoints require a <code>TaskSchema</code> for input/output validation.</li> <li>Launcher: Gunicorn-based launcher for production deployment.</li> </ul>"},{"location":"services/#auto-generation-for-connection-managers","title":"Auto-generation for Connection Managers","text":"<p>When calling a service's <code>connect</code> method, the following logic is used:</p> <pre><code>if cls._client_interface is None:\n    return generate_connection_manager(cls)(url=url)\nelse:\n    return cls._client_interface(url=url)\n</code></pre> <ul> <li>If a <code>ConnectionManager</code> is not explicitly registered, one is auto-generated for the service, exposing all endpoints as methods.</li> <li>If a <code>ConnectionManager</code> is registered, it is used as before.</li> </ul>"},{"location":"services/#updated-add_endpoint-method","title":"Updated <code>add_endpoint</code> Method","text":"<ul> <li><code>Service.add_endpoint()</code> now requires a <code>schema: TaskSchema</code>, which is stored in the service's <code>endpoints</code> dictionary.</li> <li>The auto-generator uses these schemas to add type validation and define the returned ConnectionManager's methods with the correct arguments.</li> <li>All endpoints (except <code>shutdown</code>) are exposed as methods on the connection manager.</li> </ul>"},{"location":"services/#both-get-and-post-requests-default-to-connection-manager-methods","title":"Both <code>GET</code> and <code>POST</code> Requests Default to Connection Manager Methods","text":"<p>All generated endpoints are now methods in the returned connection manager. Naked properties are not currently supported:</p> <pre><code>from mindtrace.services import Service\ncm = Service.launch()\ncm.status  # no longer supported\ncm.status()  # now generated as a method\n</code></pre>"},{"location":"services/#usage-example","title":"Usage Example","text":"<p>See <code>mindtrace/services/sample/echo_service.py</code> for a full example. Basic usage:</p> <pre><code>from mindtrace.services import Service\n\ncm = Service.launch()\n\ncm.status()      # StatusOutput(status=&lt;ServerStatus.Available: 'Available'&gt;)\ncm.heartbeat()   # HeartbeatOutput(...)\ncm.endpoints()   # EndpointsOutput(endpoints=[...])\ncm.server_id()   # ServerIDOutput(...)\ncm.pid_file()    # PIDFileOutput(...)\ncm.shutdown(block=True)  # ShutdownOutput(shutdown=True)\n</code></pre>"},{"location":"services/#defining-a-custom-service","title":"Defining a Custom Service","text":"<pre><code>from pydantic import BaseModel\nfrom mindtrace.core import TaskSchema\nfrom mindtrace.services import Service\n\nclass EchoInput(BaseModel):\n    message: str\n    delay: float = 0.0\n\nclass EchoOutput(BaseModel):\n    echoed: str\n\necho_task = TaskSchema(\n    name=\"echo\",\n    input_schema=EchoInput,\n    output_schema=EchoOutput,\n)\n\nclass EchoService(Service):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.add_endpoint(\"echo\", self.echo, schema=echo_task)\n\n    def echo(self, payload: EchoInput) -&gt; EchoOutput:\n        if payload.delay &gt; 0:\n            time.sleep(payload.delay)\n        return EchoOutput(echoed=payload.message)\n</code></pre>"},{"location":"services/#testing-and-coverage","title":"Testing and Coverage","text":"<p>The test runner supports unit, integration, and stress tests:</p> <pre><code># Run all test suites\nds test\n\n# Run specific suites\nds test --unit --stress\n</code></pre> <ul> <li>Test suites are run individually, but coverage is appended for later suites.</li> <li>The stress test suite provides verbose output (e.g., tqdm progress bars).</li> <li>Example suite times:</li> </ul> <pre><code>unit:        522 passed, 5 skipped in 4.56s\nunit+torch:  527 passed in 9.69s\nintegration: 58 passed in 41.78s\nstress:      7 passed in 208.89s (0:03:28)\n</code></pre> <ul> <li>All test suites should pass, with <code>ds test --unit</code> yielding ~97% coverage, and <code>ds test --unit --integration</code> yielding 100%.</li> </ul>"},{"location":"services/#api-reference","title":"API Reference","text":""},{"location":"services/#service","title":"Service","text":"<ul> <li>Base class for all Mindtrace services. Provides endpoint registration, FastAPI app, and lifecycle management.</li> </ul>"},{"location":"services/#connectionmanager","title":"ConnectionManager","text":"<ul> <li>Client-side helper for communicating with Mindtrace services. Auto-generated if not registered.</li> </ul>"},{"location":"services/#generate_connection_manager","title":"generate_connection_manager","text":"<ul> <li>Dynamically creates a ConnectionManager for a given Service, exposing all endpoints as methods.</li> </ul>"},{"location":"services/#add_endpoint","title":"add_endpoint","text":"<ul> <li>Register a new endpoint with a schema for input/output validation. Set <code>as_tool = true</code> for MCP tool registration.</li> </ul>"},{"location":"services/#add_tool","title":"add_tool","text":"<ul> <li>Register a new tool to the MCP HTTP app mounted on FastAPI app.</li> </ul>"},{"location":"services/#taskschema","title":"TaskSchema","text":"<ul> <li>Used to define input/output types for endpoints.</li> </ul>"},{"location":"services/#mcp-integration-exposing-service-endpoints-as-tools","title":"MCP Integration: Exposing Service Endpoints as Tools","text":""},{"location":"services/#what-is-mcp","title":"What is MCP?","text":"<p>The Model Context Protocol (MCP) is a protocol for exposing service functionality as callable tools, enabling both programmatic and interactive access to service endpoints. MCP allows you to interact with your microservices not only via HTTP endpoints but also as tools that can be listed and invoked through a unified client interface.</p>"},{"location":"services/#how-mcp-is-integrated","title":"How MCP is Integrated","text":"<ul> <li>FastMCP SDK is used to create a MCP compliant server: FastMCP automatically handles a standard Python function to be used as a tool:<ul> <li>Tool Name: It uses the function name (add) as the tool\u2019s name.</li> <li>Description: It uses the function\u2019s docstring as the tool\u2019s description for the LLM.</li> <li>Schema: It inspects the type hints (a: int, b: int) to generate a JSON schema for the inputs.</li> </ul> </li> <li>Mounting MCP on FastAPI:   Each <code>Service</code> instance mounts an MCP server on the FastAPI app. This allows the same service to be accessed both via REST endpoints and as MCP tools.</li> <li>Exposing Endpoints as Tools:   When adding an endpoint using <code>add_endpoint</code>, you can set <code>as_tool=True</code> to expose that endpoint as an MCP tool:   <pre><code>self.add_endpoint(\"echo\", self.echo, schema=echo_task, as_tool=True)\n</code></pre>   This makes the <code>echo</code> function available both as a REST endpoint and as an MCP tool.</li> </ul>"},{"location":"services/#example-echoservice-with-mcp","title":"Example: EchoService with MCP","text":"<p>See <code>mindtrace/services/sample/echo_mcp.py</code>: <pre><code>from mindtrace.services.samples.echo_mcp import EchoService\n\n# Launch the service\nconnection_manager = EchoService.launch(port=8080, host=\"localhost\", wait_for_launch=True, timeout=30)\n\n# Synchronous call via connection manager\nresult = connection_manager.echo(message=\"Hello, World!\")\nprint(result.echoed)\n</code></pre></p>"},{"location":"services/#adding-tools-directly-with-add_tool","title":"Adding Tools Directly with <code>add_tool</code>","text":"<p>In addition to exposing same class methods as endpoints and tools, you can register standalone functions as MCP tools using <code>self.add_tool</code>. These tools will be available via the MCP interface but not as HTTP endpoints.</p> <p>Example: <pre><code># Define a tool function\ndef reverse_message(payload: EchoInput) -&gt; EchoOutput:\n    \"\"\"A demo tool that reverses the input message.\"\"\"\n    reversed_msg = payload.message[::-1]\n    return EchoOutput(echoed=reversed_msg)\n\nclass EchoService(Service):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.add_endpoint(\"echo\", self.echo, schema=echo_task, as_tool=True)\n        # Register the reverse_message tool directly\n        self.add_tool(\"reverse_message\", reverse_message)\n</code></pre></p> <p>Now, both <code>echo</code> and <code>reverse_message</code> are available as MCP tools.</p>"},{"location":"services/#mcp-client-manager-servicemcp","title":"MCP Client Manager (Service.mcp)","text":"<p>Each <code>Service</code> subclass automatically receives a class-level <code>mcp</code> helper (MCPClientManager) for creating FastMCP clients:</p> <ul> <li>Connect to an existing service instance</li> <li>Launch a new service instance and return a connected client</li> <li>Access a cached client from a running connection manager instance</li> </ul> <p>Connect to a running service:</p> <pre><code>from mindtrace.services.samples.echo_mcp import EchoService\nimport asyncio\n\nasync def main():\n    # Explicit URL (trailing slash optional)\n    client = EchoService.mcp.connect(\"http://localhost:8080/\")\n    async with client:\n        tools = await client.list_tools()\n        print([t.name for t in tools])\n        result = await client.call_tool(\"echo\", {\"payload\": {\"message\": \"Hello\"}})\n        print(result)\n\nasyncio.run(main())\n</code></pre> <p>Launch a new service and get a connected client:</p> <pre><code>from mindtrace.services.samples.echo_mcp import EchoService\nimport asyncio\n\nasync def main():\n    client = EchoService.mcp.launch(\n        host=\"localhost\",\n        port=8080,\n        wait_for_launch=True,\n        timeout=30,\n    )\n    async with client:\n        tools = await client.list_tools()\n        print([t.name for t in tools])\n        result = await client.call_tool(\"echo\", {\"payload\": {\"message\": \"Launched\"}})\n        print(result)\n\nasyncio.run(main())\n</code></pre> <p>Get the MCP client from a connection manager instance:</p> <pre><code>from mindtrace.services.samples.echo_mcp import EchoService\nimport asyncio\n\nasync def main():\n    cm = EchoService.launch(host=\"localhost\", port=8081, wait_for_launch=True, timeout=30)\n    client = cm.mcp_client  # lazily created and cached per manager instance\n    async with client:\n        tools = await client.list_tools()\n        print([t.name for t in tools])\n        result = await client.call_tool(\"echo\", {\"payload\": {\"message\": \"From manager\"}})\n        print(result)\n\nasyncio.run(main())\n</code></pre>"},{"location":"services/#key-points","title":"Key Points","text":"<ul> <li>Endpoints added with <code>as_tool=True</code> are available as both HTTP endpoints and MCP tools.</li> <li>The sample EchoService demonstrates both REST and MCP tool usage.</li> <li>The MCP client allows you to list and call tools programmatically.</li> </ul> <p>For trial purposes, see the sample files: - <code>mindtrace/services/sample/echo_mcp.py</code> - <code>samples/services/echo_mcp_service.py</code> - <code>samples/services/mcp/mcp_client.py</code></p>"},{"location":"services/#remote-mcp-server-usage-with-cursor","title":"Remote MCP Server Usage with Cursor","text":"<p>You can use Cursor's UI to interact directly with any Mindtrace service that exposes its endpoints as MCP tools. This allows you to call your service's functions from within Cursor chat, making development and testing seamless.</p>"},{"location":"services/#how-to-connect-cursor-to-a-remote-mcp-server","title":"How to Connect Cursor to a Remote MCP Server","text":"<p>Follow these steps to set up and use a remote MCP server with Cursor:</p> <ol> <li>Launch the MCP Server</li> </ol> <p>Start your Mindtrace service with MCP enabled. For example, to launch the EchoService:</p> <pre><code>from mindtrace.services.samples.echo_mcp import EchoService\nconnection_manager = EchoService.launch(port=8080, host=\"localhost\")\n</code></pre> <ol> <li> <p>Configure Cursor to Use the MCP Server</p> </li> <li> <p>Open Cursor settings: Press <code>Ctrl+Shift+J</code> (or open the Command Palette and search for \"Settings\").</p> </li> <li>Navigate to Tools &amp; Integrations.</li> <li>Find and select Add Custom MCP.</li> <li> <p>In the configuration, add your MCP server details. For example, in your <code>mcp.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mindtrace_echo\": {\n      \"url\": \"http://localhost:8080/mcp-server/mcp/\"\n    }\n  }\n}\n</code></pre> </li> <li> <p>Save the configuration. Cursor will now recognize your MCP server and list its available tools.</p> </li> <li> <p>Interact with Your Service via Cursor Chat</p> </li> <li> <p>Start a new chat session in Cursor.</p> </li> <li>You can now use natural language prompts to call your service's MCP tools. For example:<ul> <li><code>Could you reverse the message 'POP' using mindtrace_echo tool?</code></li> <li><code>Can you check the status of echo service using mindtrace_echo tool?</code></li> </ul> </li> <li>Cursor will route these requests to your MCP server and display the results in the chat.</li> </ol>"},{"location":"services/api/","title":"Services Package API Reference","text":""},{"location":"services/api/#mindtrace.services.ConnectionManager","title":"ConnectionManager","text":"<pre><code>ConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Client-side helper class for communicating with Mindtrace servers.</p>"},{"location":"services/api/#mindtrace.services.ConnectionManager.mcp_url","title":"mcp_url  <code>property</code>","text":"<pre><code>mcp_url: str\n</code></pre> <p>Return the MCP endpoint URL for this service instance using config paths.</p>"},{"location":"services/api/#mindtrace.services.ConnectionManager.mcp_client","title":"mcp_client  <code>property</code>","text":"<pre><code>mcp_client: Client\n</code></pre> <p>Get an MCP client for this service.</p> <p>Returns a FastMCP Client instance that can be used to interact with the service through the MCP protocol. The client connects to the service's MCP endpoint.</p> <p>Returns:</p> Type Description <code>Client</code> <p>FastMCP Client instance for MCP protocol communication</p> <p>Example::     cm = MyService.launch()     client = cm.mcp_client     # Use client for MCP protocol interactions</p>"},{"location":"services/api/#mindtrace.services.ConnectionManager.shutdown","title":"shutdown","text":"<pre><code>shutdown(block: bool = True)\n</code></pre> <p>Shutdown the server.</p> <p>This method sends a shutdown request to the server. If block=True, it will also poll the server until it becomes unavailable, ensuring the shutdown process is complete.</p> <p>Parameters:</p> Name Type Description Default <code>block</code> <code>bool</code> <p>If True, waits for the server to actually shut down. If False, returns immediately after sending</p> <code>True</code> <p>Example::</p> <pre><code>from mindtrace.services import Service, ServerStatus\n\ncm = Service.launch()\nassert cm.status == ServerStatus.Available\n\n# Wait for shutdown to complete\ncm.shutdown(block=True)\nassert cm.status == ServerStatus.Down\n\n# Or send shutdown command and return immediately\ncm.shutdown(block=False)\n</code></pre>"},{"location":"services/api/#mindtrace.services.ConnectionManager.ashutdown","title":"ashutdown  <code>async</code>","text":"<pre><code>ashutdown(block: bool = True)\n</code></pre> <p>Async shutdown of the server.</p>"},{"location":"services/api/#mindtrace.services.ConnectionManager.status","title":"status","text":"<pre><code>status()\n</code></pre> <p>Get the status of the server.</p> <p>Returns ServerStatus.DOWN if the server is unreachable, otherwise returns the actual status.</p> <p>Returns:</p> Type Description <p>StatusOutput with the current server status.</p>"},{"location":"services/api/#mindtrace.services.ConnectionManager.astatus","title":"astatus  <code>async</code>","text":"<pre><code>astatus()\n</code></pre> <p>Async get the status of the server.</p> <p>Returns ServerStatus.DOWN if the server is unreachable, otherwise returns the actual status.</p> <p>Returns:</p> Type Description <p>StatusOutput with the current server status.</p>"},{"location":"services/api/#mindtrace.services.Service","title":"Service","text":"<pre><code>Service(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    terms_of_service: str | None = None,\n    license_info: Dict[str, str | Any] | None = None,\n    live_service: bool = True,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Base class for all Mindtrace services.</p> <p>Initialize server instance. This is for internal use by the launch() method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (e.g. \"localhost\" or \"192.168.1.100\")</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number</p> <code>None</code> <code>summary</code> <code>str | None</code> <p>Summary of the server</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Description of the server</p> <code>None</code> <code>terms_of_service</code> <code>str | None</code> <p>Terms of service for the server</p> <code>None</code> <code>license_info</code> <code>Dict[str, str | Any] | None</code> <p>License information for the server</p> <code>None</code> <code>live_service</code> <code>bool</code> <p>bool: set to True when launching via .launch(), set to False when querying endpoints in mindtrace.services.core.utils.py::generate_connection_manager Used to allow Service subclasses to have expensive init() methods without making .connect() slow</p> <code>True</code> <p>Warning: Services should be created via the ServiceClass.launch() method. The init method here should be considered private internal use.</p>"},{"location":"services/api/#mindtrace.services.Service.endpoints","title":"endpoints  <code>property</code>","text":"<pre><code>endpoints: dict[str, TaskSchema]\n</code></pre> <p>Return the available commands for the service.</p>"},{"location":"services/api/#mindtrace.services.Service.status","title":"status  <code>property</code>","text":"<pre><code>status: ServerStatus\n</code></pre> <p>Returns the current status of this service.</p>"},{"location":"services/api/#mindtrace.services.Service.endpoints_func","title":"endpoints_func","text":"<pre><code>endpoints_func()\n</code></pre> <p>List all available endpoints for the service.</p>"},{"location":"services/api/#mindtrace.services.Service.status_func","title":"status_func","text":"<pre><code>status_func()\n</code></pre> <p>Get the current status of the service.</p>"},{"location":"services/api/#mindtrace.services.Service.heartbeat_func","title":"heartbeat_func","text":"<pre><code>heartbeat_func()\n</code></pre> <p>Perform a heartbeat check for the service.</p>"},{"location":"services/api/#mindtrace.services.Service.status_at_host","title":"status_at_host  <code>classmethod</code>","text":"<pre><code>status_at_host(url: str | Url, timeout: int = 60) -&gt; ServerStatus\n</code></pre> <p>Check the status of the service at the given host url.</p> <p>This command may be used to check if a service (including this one) is available at a given host, useful for determining when a service has been successfully launched.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url</code> <p>The host URL of the service.</p> required"},{"location":"services/api/#mindtrace.services.Service.connect","title":"connect  <code>classmethod</code>","text":"<pre><code>connect(url: str | Url | None = None, timeout: int = 60) -&gt; Any\n</code></pre> <p>Connect to an existing service.</p> <p>The returned connection manager is determined by the registered connection manager for the service. If one has not explicitly been registered, the default connection manager (ConnectionManagerBase) will be used.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>The host URL of the service.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>A connection manager for the service.</p> <p>Raises:</p> Type Description <code>HTTPException</code> <p>If the server fails to connect, an HTTPException will be raised with status code 503.</p>"},{"location":"services/api/#mindtrace.services.Service.launch","title":"launch  <code>classmethod</code>","text":"<pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: Literal[False],\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre><pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: Literal[True] | bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n) -&gt; Any\n</code></pre> <pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n)\n</code></pre> <p>Launch a new server instance.</p> <p>The server can be configured through either explicit URL parameters or through kwargs. All kwargs are passed directly to the server instance's init method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object (highest priority)</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (used if url not provided)</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number (used if url not provided)</p> <code>None</code> <code>block</code> <code>bool</code> <p>If True, blocks the calling process and keeps the server running</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Number of worker processes</p> <code>1</code> <code>wait_for_launch</code> <code>bool</code> <p>Whether to wait for server startup</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for server startup in seconds</p> <code>60</code> <code>progress_bar</code> <code>bool</code> <p>Show progress bar during startup</p> <code>True</code> <code>**kwargs</code> <p>Additional parameters passed to the server's init method</p> <code>{}</code>"},{"location":"services/api/#mindtrace.services.Service.heartbeat","title":"heartbeat","text":"<pre><code>heartbeat() -&gt; Heartbeat\n</code></pre> <p>Request the server to do a complete heartbeat check.</p>"},{"location":"services/api/#mindtrace.services.Service.shutdown","title":"shutdown  <code>staticmethod</code>","text":"<pre><code>shutdown() -&gt; fastapi.Response\n</code></pre> <p>HTTP endpoint to shut down the server.</p>"},{"location":"services/api/#mindtrace.services.Service.shutdown_cleanup","title":"shutdown_cleanup  <code>async</code>","text":"<pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup the server.</p> <p>Override this method in subclasses to shut down any additional resources (e.g. db connections) as necessary.</p>"},{"location":"services/api/#mindtrace.services.Service.default_url","title":"default_url  <code>classmethod</code>","text":"<pre><code>default_url() -&gt; Url\n</code></pre> <p>Get the default URL for this server type from config.</p> <p>Priority:</p> <ol> <li>Server-specific URL from config</li> <li>Default ServerBase URL from config</li> <li>Fallback to localhost:8000</li> </ol>"},{"location":"services/api/#mindtrace.services.Service.build_url","title":"build_url  <code>classmethod</code>","text":"<pre><code>build_url(\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n) -&gt; Url\n</code></pre> <p>Build a URL with consistent priority logic.</p> <p>Priority:</p> <ol> <li>Explicit URL parameter</li> <li>Host/port parameters</li> <li>Default URL from config</li> </ol> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (e.g. \"localhost\" or \"192.168.1.100\")</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number</p> <code>None</code> <p>Returns:</p> Type Description <code>Url</code> <p>Parsed URL object</p>"},{"location":"services/api/#mindtrace.services.Service.get_mcp_paths","title":"get_mcp_paths  <code>classmethod</code>","text":"<pre><code>get_mcp_paths() -&gt; tuple[str, str]\n</code></pre> <p>Return (mount_path, http_app_path) for MCP based on config defaults.</p> <p>Defaults: - mount_path: \"/mcp-server\" - http_app_path: \"/mcp\"</p>"},{"location":"services/api/#mindtrace.services.Service.register_connection_manager","title":"register_connection_manager  <code>classmethod</code>","text":"<pre><code>register_connection_manager(connection_manager: Type[ConnectionManager])\n</code></pre> <p>Register a connection manager for this server.</p>"},{"location":"services/api/#mindtrace.services.Service.default_log_file","title":"default_log_file  <code>classmethod</code>","text":"<pre><code>default_log_file() -&gt; str\n</code></pre> <p>Get the default log file for this server type.</p>"},{"location":"services/api/#mindtrace.services.Service.add_endpoint","title":"add_endpoint","text":"<pre><code>add_endpoint(\n    path,\n    func,\n    schema: TaskSchema,\n    api_route_kwargs=None,\n    autolog_kwargs=None,\n    methods: list[str] | None = None,\n    scope: str = \"public\",\n    as_tool: bool = False,\n)\n</code></pre> <p>Register a new endpoint with optional role.</p>"},{"location":"services/api/#mindtrace.services.Service.add_tool","title":"add_tool","text":"<pre><code>add_tool(tool_name, func)\n</code></pre> <p>Add a tool to the MCP server, with an informative description including the tool and service name.</p>"},{"location":"services/api/#mindtrace.services.Heartbeat","title":"Heartbeat  <code>dataclass</code>","text":"<pre><code>Heartbeat(\n    status: ServerStatus = ServerStatus.DOWN,\n    server_id: UUID | None = None,\n    message: str | None = None,\n    details: Any = None,\n)\n</code></pre> <p>Heartbeat status of a server.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>ServerStatus</code> <p>The current status of the server.</p> <code>server_id</code> <code>UUID | None</code> <p>The unique identifier of the server.</p> <code>message</code> <code>str | None</code> <p>Human-readable message describing the status of the server.</p> <code>details</code> <code>Any</code> <p>Additional details about the server status. Individual server subclasses may define their own specific protocol for this field (though always a dict). A GatewayServer, for instance, will return a dict[UUID, Heartbeat], containing the Heartbeats of all connected services, keyed by their unique server IDs.</p>"},{"location":"services/api/#mindtrace.services.Gateway","title":"Gateway","text":"<pre><code>Gateway(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p>"},{"location":"services/api/#mindtrace.services.Gateway.register_app","title":"register_app","text":"<pre><code>register_app(payload: AppConfig)\n</code></pre> <p>Register a FastAPI app with the gateway.</p>"},{"location":"services/api/#mindtrace.services.Gateway.forward_request","title":"forward_request  <code>async</code>","text":"<pre><code>forward_request(request: Request, app_name: str, path: str)\n</code></pre> <p>Forward the request to the registered app.</p>"},{"location":"services/api/#mindtrace.services.Gateway.connect","title":"connect  <code>classmethod</code>","text":"<pre><code>connect(url: str | Url | None = None, timeout: int = 60) -&gt; Any\n</code></pre> <p>Connect to an existing Gateway service with enhanced connection manager.</p>"},{"location":"services/api/#mindtrace.services.ProxyConnectionManager","title":"ProxyConnectionManager","text":"<pre><code>ProxyConnectionManager(\n    gateway_url: str | Url, app_name: str, original_cm: ConnectionManager\n)\n</code></pre> <p>A schema-aware proxy that forwards requests through the gateway instead of directly through the wrapped connection manager.</p> <p>Initializes the ProxyConnectionManager.</p> <p>Parameters:</p> Name Type Description Default <code>gateway_url</code> <code>str | Url</code> <p>The base URL of the gateway.</p> required <code>app_name</code> <code>str</code> <p>The registered app name.</p> required <code>original_cm</code> <code>ConnectionManager</code> <p>The original connection manager.</p> required"},{"location":"services/api/#mindtrace.services.generate_connection_manager","title":"generate_connection_manager","text":"<pre><code>generate_connection_manager(\n    service_cls,\n    protected_methods: list[str] = [\n        \"shutdown\",\n        \"ashutdown\",\n        \"status\",\n        \"astatus\",\n    ],\n) -&gt; type\n</code></pre> <p>Generates a dedicated ConnectionManager class with one method per endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>service_cls</code> <p>The service class to generate a connection manager for.</p> required <code>protected_methods</code> <code>list[str]</code> <p>A list of methods that should not be overridden by dynamic methods.</p> <code>['shutdown', 'ashutdown', 'status', 'astatus']</code> <p>Returns:</p> Type Description <code>type</code> <p>A ConnectionManager class with one method per endpoint.</p>"},{"location":"services/api/#mindtrace.services.core","title":"core","text":""},{"location":"services/api/#mindtrace.services.core.connection_manager","title":"connection_manager","text":"<p>Client-side helper class for communicating with any ServerBase server.</p>"},{"location":"services/api/#mindtrace.services.core.connection_manager.ConnectionManager","title":"ConnectionManager","text":"<pre><code>ConnectionManager(\n    url: Url | None = None,\n    server_id: UUID | None = None,\n    server_pid_file: str | None = None,\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Client-side helper class for communicating with Mindtrace servers.</p> mcp_url <code>property</code> <pre><code>mcp_url: str\n</code></pre> <p>Return the MCP endpoint URL for this service instance using config paths.</p> mcp_client <code>property</code> <pre><code>mcp_client: Client\n</code></pre> <p>Get an MCP client for this service.</p> <p>Returns a FastMCP Client instance that can be used to interact with the service through the MCP protocol. The client connects to the service's MCP endpoint.</p> <p>Returns:</p> Type Description <code>Client</code> <p>FastMCP Client instance for MCP protocol communication</p> <p>Example::     cm = MyService.launch()     client = cm.mcp_client     # Use client for MCP protocol interactions</p> shutdown <pre><code>shutdown(block: bool = True)\n</code></pre> <p>Shutdown the server.</p> <p>This method sends a shutdown request to the server. If block=True, it will also poll the server until it becomes unavailable, ensuring the shutdown process is complete.</p> <p>Parameters:</p> Name Type Description Default <code>block</code> <code>bool</code> <p>If True, waits for the server to actually shut down. If False, returns immediately after sending</p> <code>True</code> <p>Example::</p> <pre><code>from mindtrace.services import Service, ServerStatus\n\ncm = Service.launch()\nassert cm.status == ServerStatus.Available\n\n# Wait for shutdown to complete\ncm.shutdown(block=True)\nassert cm.status == ServerStatus.Down\n\n# Or send shutdown command and return immediately\ncm.shutdown(block=False)\n</code></pre> ashutdown <code>async</code> <pre><code>ashutdown(block: bool = True)\n</code></pre> <p>Async shutdown of the server.</p> status <pre><code>status()\n</code></pre> <p>Get the status of the server.</p> <p>Returns ServerStatus.DOWN if the server is unreachable, otherwise returns the actual status.</p> <p>Returns:</p> Type Description <p>StatusOutput with the current server status.</p> astatus <code>async</code> <pre><code>astatus()\n</code></pre> <p>Async get the status of the server.</p> <p>Returns ServerStatus.DOWN if the server is unreachable, otherwise returns the actual status.</p> <p>Returns:</p> Type Description <p>StatusOutput with the current server status.</p>"},{"location":"services/api/#mindtrace.services.core.launcher","title":"launcher","text":""},{"location":"services/api/#mindtrace.services.core.launcher.Launcher","title":"Launcher","text":"<pre><code>Launcher(options)\n</code></pre> <p>Uvicorn application launcher for Mindtrace services (Windows).</p>"},{"location":"services/api/#mindtrace.services.core.mcp_client_manager","title":"mcp_client_manager","text":""},{"location":"services/api/#mindtrace.services.core.mcp_client_manager.MCPClientManager","title":"MCPClientManager","text":"<pre><code>MCPClientManager(service_cls: Type[Service])\n</code></pre> <p>Manager for MCP client operations for a service class.</p> <p>Initialize the MCP client manager.</p> <p>Parameters:</p> Name Type Description Default <code>service_cls</code> <code>Type[Service]</code> <p>The service class this manager is bound to.</p> required connect <pre><code>connect(url: str | Url | None = None) -&gt; Client\n</code></pre> <p>Connect to an existing service via MCP protocol.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>The URL of the service. If None, uses the default URL for this service type.</p> <code>None</code> <p>Returns:</p> Type Description <code>Client</code> <p>FastMCP Client instance for MCP protocol communication</p> <p>Example::     from mindtrace.services.samples.echo_mcp import EchoService     # Connect to a running EchoService     mcp_client = EchoService.mcp.connect(\"http://localhost:8000\")</p> <pre><code># Use default URL\nmcp_client = EchoService.mcp.connect()\n\n# Use the connected client\nasync with mcp_client:\n    tools = await mcp_client.list_tools()\n    print(f\"Available tools: {tools}\")\n</code></pre> launch <pre><code>launch(**launch_kwargs) -&gt; Client\n</code></pre> <p>Launch a new service and return an MCP client for it.</p> <p>Launches a new service instance using the service's launch method, then returns an MCP client connected to the newly launched service.</p> <p>Parameters:</p> Name Type Description Default <code>**launch_kwargs</code> <p>Arguments passed to the service's launch method</p> <code>{}</code> <p>Returns:</p> Type Description <code>Client</code> <p>FastMCP Client instance connected to the newly launched service</p> <p>Example::     from mindtrace.services.samples.echo_mcp import EchoService</p> <pre><code>mcp_client = EchoService.mcp.launch(\n                                    host=\"localhost\",\n                                    port=8000,\n                                    wait_for_launch=True,\n                                    timeout=10\n                                    )\n\nprint(f\"Service launched and MCP client created: {mcp_client}\")\nasync with mcp_client:\n    tools = await mcp_client.list_tools()\n    print(f\"Available tools: {tools}\")\n</code></pre>"},{"location":"services/api/#mindtrace.services.core.middleware","title":"middleware","text":""},{"location":"services/api/#mindtrace.services.core.middleware.RequestLoggingMiddleware","title":"RequestLoggingMiddleware","text":"<pre><code>RequestLoggingMiddleware(\n    app: Any,\n    service_name: str,\n    *,\n    log_metrics: bool = False,\n    metrics_interval: Optional[int] = None,\n    metrics_to_collect: Optional[list[str]] = [\"cpu_percent\", \"memory_percent\"],\n    add_request_id_header: bool = True,\n    logger: Optional[Any] = None\n)\n</code></pre> <p>               Bases: <code>BaseHTTPMiddleware</code></p> <p>Minimal middleware for request-scoped logging without duplicating autolog.</p> <p>Responsibilities: - Generate/bind a correlation id (request_id) via structlog.contextvars - Log one request-level envelope (request_started, request_completed) - Optionally log system metrics at request time - Attach request_id to response headers - Global error capture with structured logs</p> <p>Avoids per-operation details already handled by @Mindtrace.autolog (duration_ms, per-endpoint metrics, start/completed of handlers).</p>"},{"location":"services/api/#mindtrace.services.core.service","title":"service","text":"<p>Service base class. Provides unified methods for all Mindtrace (micro)services.</p>"},{"location":"services/api/#mindtrace.services.core.service.Service","title":"Service","text":"<pre><code>Service(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    terms_of_service: str | None = None,\n    license_info: Dict[str, str | Any] | None = None,\n    live_service: bool = True,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Base class for all Mindtrace services.</p> <p>Initialize server instance. This is for internal use by the launch() method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (e.g. \"localhost\" or \"192.168.1.100\")</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number</p> <code>None</code> <code>summary</code> <code>str | None</code> <p>Summary of the server</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Description of the server</p> <code>None</code> <code>terms_of_service</code> <code>str | None</code> <p>Terms of service for the server</p> <code>None</code> <code>license_info</code> <code>Dict[str, str | Any] | None</code> <p>License information for the server</p> <code>None</code> <code>live_service</code> <code>bool</code> <p>bool: set to True when launching via .launch(), set to False when querying endpoints in mindtrace.services.core.utils.py::generate_connection_manager Used to allow Service subclasses to have expensive init() methods without making .connect() slow</p> <code>True</code> <p>Warning: Services should be created via the ServiceClass.launch() method. The init method here should be considered private internal use.</p> endpoints <code>property</code> <pre><code>endpoints: dict[str, TaskSchema]\n</code></pre> <p>Return the available commands for the service.</p> status <code>property</code> <pre><code>status: ServerStatus\n</code></pre> <p>Returns the current status of this service.</p> endpoints_func <pre><code>endpoints_func()\n</code></pre> <p>List all available endpoints for the service.</p> status_func <pre><code>status_func()\n</code></pre> <p>Get the current status of the service.</p> heartbeat_func <pre><code>heartbeat_func()\n</code></pre> <p>Perform a heartbeat check for the service.</p> status_at_host <code>classmethod</code> <pre><code>status_at_host(url: str | Url, timeout: int = 60) -&gt; ServerStatus\n</code></pre> <p>Check the status of the service at the given host url.</p> <p>This command may be used to check if a service (including this one) is available at a given host, useful for determining when a service has been successfully launched.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url</code> <p>The host URL of the service.</p> required connect <code>classmethod</code> <pre><code>connect(url: str | Url | None = None, timeout: int = 60) -&gt; Any\n</code></pre> <p>Connect to an existing service.</p> <p>The returned connection manager is determined by the registered connection manager for the service. If one has not explicitly been registered, the default connection manager (ConnectionManagerBase) will be used.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>The host URL of the service.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>A connection manager for the service.</p> <p>Raises:</p> Type Description <code>HTTPException</code> <p>If the server fails to connect, an HTTPException will be raised with status code 503.</p> launch <code>classmethod</code> <pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: Literal[False],\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n) -&gt; None\n</code></pre><pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: Literal[True] | bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n) -&gt; Any\n</code></pre> <pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n)\n</code></pre> <p>Launch a new server instance.</p> <p>The server can be configured through either explicit URL parameters or through kwargs. All kwargs are passed directly to the server instance's init method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object (highest priority)</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (used if url not provided)</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number (used if url not provided)</p> <code>None</code> <code>block</code> <code>bool</code> <p>If True, blocks the calling process and keeps the server running</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Number of worker processes</p> <code>1</code> <code>wait_for_launch</code> <code>bool</code> <p>Whether to wait for server startup</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for server startup in seconds</p> <code>60</code> <code>progress_bar</code> <code>bool</code> <p>Show progress bar during startup</p> <code>True</code> <code>**kwargs</code> <p>Additional parameters passed to the server's init method</p> <code>{}</code> heartbeat <pre><code>heartbeat() -&gt; Heartbeat\n</code></pre> <p>Request the server to do a complete heartbeat check.</p> shutdown <code>staticmethod</code> <pre><code>shutdown() -&gt; fastapi.Response\n</code></pre> <p>HTTP endpoint to shut down the server.</p> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup the server.</p> <p>Override this method in subclasses to shut down any additional resources (e.g. db connections) as necessary.</p> default_url <code>classmethod</code> <pre><code>default_url() -&gt; Url\n</code></pre> <p>Get the default URL for this server type from config.</p> <p>Priority:</p> <ol> <li>Server-specific URL from config</li> <li>Default ServerBase URL from config</li> <li>Fallback to localhost:8000</li> </ol> build_url <code>classmethod</code> <pre><code>build_url(\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n) -&gt; Url\n</code></pre> <p>Build a URL with consistent priority logic.</p> <p>Priority:</p> <ol> <li>Explicit URL parameter</li> <li>Host/port parameters</li> <li>Default URL from config</li> </ol> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (e.g. \"localhost\" or \"192.168.1.100\")</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number</p> <code>None</code> <p>Returns:</p> Type Description <code>Url</code> <p>Parsed URL object</p> get_mcp_paths <code>classmethod</code> <pre><code>get_mcp_paths() -&gt; tuple[str, str]\n</code></pre> <p>Return (mount_path, http_app_path) for MCP based on config defaults.</p> <p>Defaults: - mount_path: \"/mcp-server\" - http_app_path: \"/mcp\"</p> register_connection_manager <code>classmethod</code> <pre><code>register_connection_manager(connection_manager: Type[ConnectionManager])\n</code></pre> <p>Register a connection manager for this server.</p> default_log_file <code>classmethod</code> <pre><code>default_log_file() -&gt; str\n</code></pre> <p>Get the default log file for this server type.</p> add_endpoint <pre><code>add_endpoint(\n    path,\n    func,\n    schema: TaskSchema,\n    api_route_kwargs=None,\n    autolog_kwargs=None,\n    methods: list[str] | None = None,\n    scope: str = \"public\",\n    as_tool: bool = False,\n)\n</code></pre> <p>Register a new endpoint with optional role.</p> add_tool <pre><code>add_tool(tool_name, func)\n</code></pre> <p>Add a tool to the MCP server, with an informative description including the tool and service name.</p>"},{"location":"services/api/#mindtrace.services.core.types","title":"types","text":""},{"location":"services/api/#mindtrace.services.core.types.Heartbeat","title":"Heartbeat  <code>dataclass</code>","text":"<pre><code>Heartbeat(\n    status: ServerStatus = ServerStatus.DOWN,\n    server_id: UUID | None = None,\n    message: str | None = None,\n    details: Any = None,\n)\n</code></pre> <p>Heartbeat status of a server.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>ServerStatus</code> <p>The current status of the server.</p> <code>server_id</code> <code>UUID | None</code> <p>The unique identifier of the server.</p> <code>message</code> <code>str | None</code> <p>Human-readable message describing the status of the server.</p> <code>details</code> <code>Any</code> <p>Additional details about the server status. Individual server subclasses may define their own specific protocol for this field (though always a dict). A GatewayServer, for instance, will return a dict[UUID, Heartbeat], containing the Heartbeats of all connected services, keyed by their unique server IDs.</p>"},{"location":"services/api/#mindtrace.services.core.utils","title":"utils","text":""},{"location":"services/api/#mindtrace.services.core.utils.add_endpoint","title":"add_endpoint","text":"<pre><code>add_endpoint(app, path, self: Optional[Service], **kwargs)\n</code></pre> <p>Register a new endpoint.</p> <p>This decorator method is functionally identical as calling add_endpoint on a Service instance. It is useful when the endpoints are defined in a separate method, such as grouping api routes in a more complicated FastAPI app.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI app.</p> required <code>path</code> <p>The endpoint path.</p> required <code>self</code> <code>Optional[Service]</code> <p>The server instance.</p> required <code>**kwargs</code> <p>Additional arguments to pass when creating the FastAPI route.</p> <code>{}</code> <p>Example::</p> <pre><code>from fastapi import FastAPI\nfrom mindtrace.services import Service\n\nclass MyServer(Service):\n    def __init__(self):\n        super().__init__()\n\n        self.add_endpoint(path=\"/status_using_method\", func=self.status)\n        self.create_app()\n\n    def status(self):\n        return {\"status\": \"Available\"}\n\n    def create_app():\n        # May put all the endpoints in a single method, and call the method in __init__.\n\n        @add_endpoint(self.app, \"/status_using_decorator\", self=self)\n        def status():\n            return {\"status\": \"Available\"}\n\n        @add_endpoint(self.app, \"/another_hundred_endpoints\", self=self)\n        def another_hundred_endpoints():\n            return\n</code></pre>"},{"location":"services/api/#mindtrace.services.core.utils.register_connection_manager","title":"register_connection_manager","text":"<pre><code>register_connection_manager(connection_manager: Type[ConnectionManager])\n</code></pre> <p>Register a connection manager for a server class.</p> <p>This decorator is used to register a connection manager for a server class. The connection manager is used to communicate with the server. The connection manager must be a subclass of ConnectionManager.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>Type[ConnectionManager]</code> <p>The connection manager class.</p> required <p>Example::</p> <pre><code>import requests\nfrom mindtrace.services import ConnectionManager, Service\n\nclass MyConnectionManager(ConnectionManager):\n    def __init__(self, url):\n        super().__init__(url)\n\n    def add(arg1, arg2):\n        response = requests.request(\"POST\", str(self.url) + \"add\", json={\"arg1\": arg1, \"arg2\": arg2})\n        return json.loads(response.content)[\"sum\"]\n\n@register_connection_manager(MyConnectionManager)\nclass MyService(Service):\n    def __init__(self):\n        super().__init__()\n        self.add_endpoint(\"add\", self.add)\n\n    def add(self, arg1, arg2):\n        return {\"sum\": arg1 + arg2}\n\ncm = MyService.launch()  # Returns a MyConnectionManager instance, NOT a MyServer instance\nsum = cm.add(1, 2)  # Calls add method in MyConnectionManager\n</code></pre>"},{"location":"services/api/#mindtrace.services.core.utils.generate_connection_manager","title":"generate_connection_manager","text":"<pre><code>generate_connection_manager(\n    service_cls,\n    protected_methods: list[str] = [\n        \"shutdown\",\n        \"ashutdown\",\n        \"status\",\n        \"astatus\",\n    ],\n) -&gt; type\n</code></pre> <p>Generates a dedicated ConnectionManager class with one method per endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>service_cls</code> <p>The service class to generate a connection manager for.</p> required <code>protected_methods</code> <code>list[str]</code> <p>A list of methods that should not be overridden by dynamic methods.</p> <code>['shutdown', 'ashutdown', 'status', 'astatus']</code> <p>Returns:</p> Type Description <code>type</code> <p>A ConnectionManager class with one method per endpoint.</p>"},{"location":"services/api/#mindtrace.services.discord","title":"discord","text":"<p>Discord integration for Mindtrace services.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordClient","title":"DiscordClient","text":"<pre><code>DiscordClient(\n    *, token: str | None = None, intents: Optional[Intents] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Discord client that can be extended for different bot implementations.</p> <p>This class provides: - Command registration and management - Event handling system - Integration with Mindtrace patterns - Configurable bot behavior</p> <p>Initialize the Discord client.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str | None</code> <p>Discord bot token (optional, will use config if not provided)</p> <code>None</code> <code>intents</code> <code>Optional[Intents]</code> <p>Discord intents configuration</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Mindtrace</p> <code>{}</code>"},{"location":"services/api/#mindtrace.services.discord.DiscordClient.register_command","title":"register_command","text":"<pre><code>register_command(\n    name: str,\n    description: str,\n    usage: str,\n    handler: Callable,\n    aliases: Optional[List[str]] = None,\n    category: str = \"General\",\n    enabled: bool = True,\n    hidden: bool = False,\n    cooldown: Optional[int] = None,\n    permissions: Optional[List[str]] = None,\n    parameters: Optional[Dict[str, Dict[str, Any]]] = None,\n)\n</code></pre> <p>Register a new slash command with the bot.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Command name</p> required <code>description</code> <code>str</code> <p>Command description</p> required <code>usage</code> <code>str</code> <p>Usage instructions (for documentation)</p> required <code>handler</code> <code>Callable</code> <p>Function to handle the command</p> required <code>aliases</code> <code>Optional[List[str]]</code> <p>Alternative command names (not used in slash commands)</p> <code>None</code> <code>category</code> <code>str</code> <p>Command category</p> <code>'General'</code> <code>enabled</code> <code>bool</code> <p>Whether the command is enabled</p> <code>True</code> <code>hidden</code> <code>bool</code> <p>Whether to hide from help</p> <code>False</code> <code>cooldown</code> <code>Optional[int]</code> <p>Cooldown in seconds</p> <code>None</code> <code>permissions</code> <code>Optional[List[str]]</code> <p>Required permissions</p> <code>None</code> <code>parameters</code> <code>Optional[Dict[str, Dict[str, Any]]]</code> <p>Dictionary of parameter descriptions for slash commands</p> <code>None</code>"},{"location":"services/api/#mindtrace.services.discord.DiscordClient.register_event_handler","title":"register_event_handler","text":"<pre><code>register_event_handler(\n    event_type: DiscordEventType, handler: DiscordEventHandler\n)\n</code></pre> <p>Register an event handler.</p> <p>Parameters:</p> Name Type Description Default <code>event_type</code> <code>DiscordEventType</code> <p>Type of event to handle</p> required <code>handler</code> <code>DiscordEventHandler</code> <p>Event handler instance</p> required"},{"location":"services/api/#mindtrace.services.discord.DiscordClient.start_bot","title":"start_bot  <code>async</code>","text":"<pre><code>start_bot()\n</code></pre> <p>Start the Discord bot.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordClient.stop_bot","title":"stop_bot  <code>async</code>","text":"<pre><code>stop_bot()\n</code></pre> <p>Stop the Discord bot.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService","title":"DiscordService","text":"<pre><code>DiscordService(\n    *, token: str | None = None, intents: Optional[Any] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Service wrapper for DiscordClient.</p> <p>This class provides: - HTTP API endpoints for Discord bot control - MCP tool integration - Service lifecycle management - Integration with Mindtrace infrastructure</p> <p>Initialize the Discord service.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str | None</code> <p>Discord bot token (optional, will use config if not provided)</p> <code>None</code> <code>intents</code> <code>Optional[Any]</code> <p>Discord intents configuration</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Service</p> <code>{}</code>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Startup the Discord bot during service initialization.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.execute_command","title":"execute_command  <code>async</code>","text":"<pre><code>execute_command(payload: DiscordCommandInput) -&gt; DiscordCommandOutput\n</code></pre> <p>Execute a command via the service API.</p> <p>This method allows executing Discord slash commands programmatically through the FastAPI endpoint, useful for exposing AI models and other functionality through both Discord and HTTP interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>DiscordCommandInput</code> <p>Command input data</p> required <p>Returns:</p> Type Description <code>DiscordCommandOutput</code> <p>Command output</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.get_bot_status","title":"get_bot_status","text":"<pre><code>get_bot_status() -&gt; DiscordStatusOutput\n</code></pre> <p>Get the current bot status.</p> <p>Returns:</p> Type Description <code>DiscordStatusOutput</code> <p>Bot status information</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.get_commands","title":"get_commands","text":"<pre><code>get_commands() -&gt; DiscordCommandsOutput\n</code></pre> <p>Get list of registered commands.</p> <p>Returns:</p> Type Description <code>DiscordCommandsOutput</code> <p>Command information</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.register_command","title":"register_command","text":"<pre><code>register_command(*args, **kwargs)\n</code></pre> <p>Register a command with the Discord client.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.register_event_handler","title":"register_event_handler","text":"<pre><code>register_event_handler(*args, **kwargs)\n</code></pre> <p>Register an event handler with the Discord client.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.launch","title":"launch  <code>classmethod</code>","text":"<pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n)\n</code></pre> <p>Launch a Discord service and wait for the Discord bot to be ready.</p> <p>This overrides the base Service.launch() method to ensure the Discord bot is fully connected before returning the connection manager.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object (highest priority)</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (used if url not provided)</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number (used if url not provided)</p> <code>None</code> <code>block</code> <code>bool</code> <p>If True, blocks the calling process and keeps the server running</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Number of worker processes</p> <code>1</code> <code>wait_for_launch</code> <code>bool</code> <p>Whether to wait for server startup</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for server startup in seconds</p> <code>60</code> <code>progress_bar</code> <code>bool</code> <p>Show progress bar during startup</p> <code>True</code> <code>**kwargs</code> <p>Additional parameters passed to the server's init method</p> <code>{}</code>"},{"location":"services/api/#mindtrace.services.discord.DiscordService.shutdown_cleanup","title":"shutdown_cleanup  <code>async</code>","text":"<pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup when shutting down the service.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommand","title":"DiscordCommand  <code>dataclass</code>","text":"<pre><code>DiscordCommand(\n    name: str,\n    description: str,\n    usage: str,\n    aliases: List[str],\n    category: str,\n    enabled: bool = True,\n    hidden: bool = False,\n    cooldown: Optional[int] = None,\n    permissions: Optional[List[str]] = None,\n)\n</code></pre> <p>Represents a Discord command with its metadata.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommandInput","title":"DiscordCommandInput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base input schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommandOutput","title":"DiscordCommandOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base output schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommandSchema","title":"DiscordCommandSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Base schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommandsOutput","title":"DiscordCommandsOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output schema for commands list.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordCommandsSchema","title":"DiscordCommandsSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Schema for commands list endpoint.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordEventHandler","title":"DiscordEventHandler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for Discord event handlers.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordEventHandler.handle","title":"handle  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>handle(event_type: DiscordEventType, **kwargs) -&gt; None\n</code></pre> <p>Handle a Discord event.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordEventType","title":"DiscordEventType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of Discord events that can be handled.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordStatusOutput","title":"DiscordStatusOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output schema for bot status.</p>"},{"location":"services/api/#mindtrace.services.discord.DiscordStatusSchema","title":"DiscordStatusSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Schema for bot status endpoint.</p>"},{"location":"services/api/#mindtrace.services.discord.discord_client","title":"discord_client","text":"<p>Discord client implementation for Mindtrace services.</p> <p>This module provides a base Discord client that can be extended for different bot implementations. It follows the Mindtrace Service patterns and provides a clean interface for command registration.</p>"},{"location":"services/api/#mindtrace.services.discord.discord_client.DiscordClient","title":"DiscordClient","text":"<pre><code>DiscordClient(\n    *, token: str | None = None, intents: Optional[Intents] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>Mindtrace</code></p> <p>Discord client that can be extended for different bot implementations.</p> <p>This class provides: - Command registration and management - Event handling system - Integration with Mindtrace patterns - Configurable bot behavior</p> <p>Initialize the Discord client.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str | None</code> <p>Discord bot token (optional, will use config if not provided)</p> <code>None</code> <code>intents</code> <code>Optional[Intents]</code> <p>Discord intents configuration</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Mindtrace</p> <code>{}</code> register_command <pre><code>register_command(\n    name: str,\n    description: str,\n    usage: str,\n    handler: Callable,\n    aliases: Optional[List[str]] = None,\n    category: str = \"General\",\n    enabled: bool = True,\n    hidden: bool = False,\n    cooldown: Optional[int] = None,\n    permissions: Optional[List[str]] = None,\n    parameters: Optional[Dict[str, Dict[str, Any]]] = None,\n)\n</code></pre> <p>Register a new slash command with the bot.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Command name</p> required <code>description</code> <code>str</code> <p>Command description</p> required <code>usage</code> <code>str</code> <p>Usage instructions (for documentation)</p> required <code>handler</code> <code>Callable</code> <p>Function to handle the command</p> required <code>aliases</code> <code>Optional[List[str]]</code> <p>Alternative command names (not used in slash commands)</p> <code>None</code> <code>category</code> <code>str</code> <p>Command category</p> <code>'General'</code> <code>enabled</code> <code>bool</code> <p>Whether the command is enabled</p> <code>True</code> <code>hidden</code> <code>bool</code> <p>Whether to hide from help</p> <code>False</code> <code>cooldown</code> <code>Optional[int]</code> <p>Cooldown in seconds</p> <code>None</code> <code>permissions</code> <code>Optional[List[str]]</code> <p>Required permissions</p> <code>None</code> <code>parameters</code> <code>Optional[Dict[str, Dict[str, Any]]]</code> <p>Dictionary of parameter descriptions for slash commands</p> <code>None</code> register_event_handler <pre><code>register_event_handler(\n    event_type: DiscordEventType, handler: DiscordEventHandler\n)\n</code></pre> <p>Register an event handler.</p> <p>Parameters:</p> Name Type Description Default <code>event_type</code> <code>DiscordEventType</code> <p>Type of event to handle</p> required <code>handler</code> <code>DiscordEventHandler</code> <p>Event handler instance</p> required start_bot <code>async</code> <pre><code>start_bot()\n</code></pre> <p>Start the Discord bot.</p> stop_bot <code>async</code> <pre><code>stop_bot()\n</code></pre> <p>Stop the Discord bot.</p>"},{"location":"services/api/#mindtrace.services.discord.discord_service","title":"discord_service","text":"<p>Discord Service implementation for Mindtrace services.</p> <p>This module provides a Service wrapper around DiscordClient that enables HTTP API endpoints and MCP integration while maintaining the Discord bot functionality.</p>"},{"location":"services/api/#mindtrace.services.discord.discord_service.DiscordService","title":"DiscordService","text":"<pre><code>DiscordService(\n    *, token: str | None = None, intents: Optional[Any] = None, **kwargs\n)\n</code></pre> <p>               Bases: <code>Service</code></p> <p>Service wrapper for DiscordClient.</p> <p>This class provides: - HTTP API endpoints for Discord bot control - MCP tool integration - Service lifecycle management - Integration with Mindtrace infrastructure</p> <p>Initialize the Discord service.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str | None</code> <p>Discord bot token (optional, will use config if not provided)</p> <code>None</code> <code>intents</code> <code>Optional[Any]</code> <p>Discord intents configuration</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to Service</p> <code>{}</code> startup <code>async</code> <pre><code>startup()\n</code></pre> <p>Startup the Discord bot during service initialization.</p> execute_command <code>async</code> <pre><code>execute_command(payload: DiscordCommandInput) -&gt; DiscordCommandOutput\n</code></pre> <p>Execute a command via the service API.</p> <p>This method allows executing Discord slash commands programmatically through the FastAPI endpoint, useful for exposing AI models and other functionality through both Discord and HTTP interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>DiscordCommandInput</code> <p>Command input data</p> required <p>Returns:</p> Type Description <code>DiscordCommandOutput</code> <p>Command output</p> get_bot_status <pre><code>get_bot_status() -&gt; DiscordStatusOutput\n</code></pre> <p>Get the current bot status.</p> <p>Returns:</p> Type Description <code>DiscordStatusOutput</code> <p>Bot status information</p> get_commands <pre><code>get_commands() -&gt; DiscordCommandsOutput\n</code></pre> <p>Get list of registered commands.</p> <p>Returns:</p> Type Description <code>DiscordCommandsOutput</code> <p>Command information</p> register_command <pre><code>register_command(*args, **kwargs)\n</code></pre> <p>Register a command with the Discord client.</p> register_event_handler <pre><code>register_event_handler(*args, **kwargs)\n</code></pre> <p>Register an event handler with the Discord client.</p> launch <code>classmethod</code> <pre><code>launch(\n    *,\n    url: str | Url | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    block: bool = False,\n    num_workers: int = 1,\n    wait_for_launch: bool = True,\n    timeout: int = 60,\n    progress_bar: bool = True,\n    **kwargs\n)\n</code></pre> <p>Launch a Discord service and wait for the Discord bot to be ready.</p> <p>This overrides the base Service.launch() method to ensure the Discord bot is fully connected before returning the connection manager.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str | Url | None</code> <p>Full URL string or Url object (highest priority)</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host address (used if url not provided)</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Port number (used if url not provided)</p> <code>None</code> <code>block</code> <code>bool</code> <p>If True, blocks the calling process and keeps the server running</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Number of worker processes</p> <code>1</code> <code>wait_for_launch</code> <code>bool</code> <p>Whether to wait for server startup</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for server startup in seconds</p> <code>60</code> <code>progress_bar</code> <code>bool</code> <p>Show progress bar during startup</p> <code>True</code> <code>**kwargs</code> <p>Additional parameters passed to the server's init method</p> <code>{}</code> shutdown_cleanup <code>async</code> <pre><code>shutdown_cleanup()\n</code></pre> <p>Cleanup when shutting down the service.</p>"},{"location":"services/api/#mindtrace.services.discord.types","title":"types","text":""},{"location":"services/api/#mindtrace.services.discord.types.DiscordEventType","title":"DiscordEventType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of Discord events that can be handled.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommand","title":"DiscordCommand  <code>dataclass</code>","text":"<pre><code>DiscordCommand(\n    name: str,\n    description: str,\n    usage: str,\n    aliases: List[str],\n    category: str,\n    enabled: bool = True,\n    hidden: bool = False,\n    cooldown: Optional[int] = None,\n    permissions: Optional[List[str]] = None,\n)\n</code></pre> <p>Represents a Discord command with its metadata.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommandInput","title":"DiscordCommandInput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base input schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommandOutput","title":"DiscordCommandOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base output schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordStatusOutput","title":"DiscordStatusOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output schema for bot status.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommandsOutput","title":"DiscordCommandsOutput","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output schema for commands list.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommandSchema","title":"DiscordCommandSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Base schema for Discord commands.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordStatusSchema","title":"DiscordStatusSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Schema for bot status endpoint.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordCommandsSchema","title":"DiscordCommandsSchema","text":"<p>               Bases: <code>TaskSchema</code></p> <p>Schema for commands list endpoint.</p>"},{"location":"services/api/#mindtrace.services.discord.types.DiscordEventHandler","title":"DiscordEventHandler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for Discord event handlers.</p> handle <code>abstractmethod</code> <code>async</code> <pre><code>handle(event_type: DiscordEventType, **kwargs) -&gt; None\n</code></pre> <p>Handle a Discord event.</p>"},{"location":"services/api/#mindtrace.services.gateway","title":"gateway","text":""},{"location":"services/api/#mindtrace.services.gateway.gateway","title":"gateway","text":""},{"location":"services/api/#mindtrace.services.gateway.gateway.Gateway","title":"Gateway","text":"<pre><code>Gateway(**kwargs)\n</code></pre> <p>               Bases: <code>Service</code></p> register_app <pre><code>register_app(payload: AppConfig)\n</code></pre> <p>Register a FastAPI app with the gateway.</p> forward_request <code>async</code> <pre><code>forward_request(request: Request, app_name: str, path: str)\n</code></pre> <p>Forward the request to the registered app.</p> connect <code>classmethod</code> <pre><code>connect(url: str | Url | None = None, timeout: int = 60) -&gt; Any\n</code></pre> <p>Connect to an existing Gateway service with enhanced connection manager.</p>"},{"location":"services/api/#mindtrace.services.gateway.proxy_connection_manager","title":"proxy_connection_manager","text":""},{"location":"services/api/#mindtrace.services.gateway.proxy_connection_manager.ProxyConnectionManager","title":"ProxyConnectionManager","text":"<pre><code>ProxyConnectionManager(\n    gateway_url: str | Url, app_name: str, original_cm: ConnectionManager\n)\n</code></pre> <p>A schema-aware proxy that forwards requests through the gateway instead of directly through the wrapped connection manager.</p> <p>Initializes the ProxyConnectionManager.</p> <p>Parameters:</p> Name Type Description Default <code>gateway_url</code> <code>str | Url</code> <p>The base URL of the gateway.</p> required <code>app_name</code> <code>str</code> <p>The registered app name.</p> required <code>original_cm</code> <code>ConnectionManager</code> <p>The original connection manager.</p> required"},{"location":"storage/","title":"Storage","text":""},{"location":"storage/#storage-module","title":"Storage Module","text":"<p>This directory contains the storage-related components for the Mindtrace project. It provides abstractions and implementations for interacting with various storage backends, such as Google Cloud Storage (GCS).</p>"},{"location":"storage/#structure","title":"Structure","text":"<ul> <li><code>mindtrace/storage</code> \u2014 Contains the core storage handler implementations and interfaces.</li> <li><code>pyproject.toml</code> \u2014 Build and dependency configuration for the storage package.</li> </ul>"},{"location":"storage/#main-components","title":"Main Components","text":"<ul> <li>base.py: Defines the abstract <code>StorageHandler</code> interface for storage operations.</li> <li>gcs.py: Implements <code>GCSStorageHandler</code>, a wrapper around Google Cloud Storage APIs for uploading, downloading, listing, and managing objects in GCS buckets.</li> </ul>"},{"location":"storage/#google-cloud-storage-gcs-usage","title":"Google Cloud Storage (GCS) Usage","text":""},{"location":"storage/#usage-example","title":"Usage Example","text":"<p>To use the GCS storage handler:</p> <pre><code>from mindtrace.storage.gcs import GCSStorageHandler\n\nhandler = GCSStorageHandler(\n    bucket_name=\"your-bucket-name\",\n    project_id=\"your-gcp-project-id\",\n    credentials_path=\"/path/to/service-account.json\",  # Optional if using ADC\n    create_if_missing=True,\n)\n\n# Upload a file\ngcs_uri = handler.upload(\"local_file.txt\", \"remote/path/in/bucket.txt\")\n\n# List objects\nprint(handler.list_objects(prefix=\"remote/path/\"))\n</code></pre>"},{"location":"storage/#available-gcs-apis","title":"Available GCS APIs","text":"<p>The following methods are available via the <code>GCSStorageHandler</code> for explicit use:</p> <ul> <li><code>upload(local_path, remote_path, metadata=None)</code>: Upload a local file to a GCS bucket.</li> <li><code>download(remote_path, local_path)</code>: Download a file from GCS to a local path.</li> <li><code>delete(remote_path)</code>: Delete an object from the GCS bucket.</li> <li><code>list_objects(prefix=\"\", max_results=None)</code>: List objects in the bucket, optionally filtered by prefix.</li> <li><code>exists(remote_path)</code>: Check if an object exists in the bucket.</li> <li><code>get_presigned_url(remote_path, expiration_minutes=60, method=\"GET\")</code>: Generate a presigned URL for accessing an object.</li> <li><code>get_object_metadata(remote_path)</code>: Retrieve metadata for a specific object.</li> </ul>"},{"location":"storage/#notes","title":"Notes","text":"<ul> <li>Ensure you have the required Google Cloud credentials and permissions to access the target bucket.</li> <li>For local development, you can use <code>gcloud auth application-default login</code> to set up default credentials.</li> </ul>"},{"location":"storage/api/","title":"Storage Package API Reference","text":""},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler","title":"GCSStorageHandler","text":"<pre><code>GCSStorageHandler(\n    bucket_name: str,\n    *,\n    project_id: Optional[str] = None,\n    credentials_path: Optional[str] = None,\n    ensure_bucket: bool = True,\n    create_if_missing: bool = False,\n    location: str = \"US\",\n    storage_class: str = \"STANDARD\"\n)\n</code></pre> <p>               Bases: <code>StorageHandler</code></p> <p>A thin wrapper around <code>google-cloud-storage</code> APIs.</p> <p>Initialize a GCSStorageHandler. Args:     bucket_name: Name of the GCS bucket.     project_id: Optional GCP project ID.     credentials_path: Optional path to a service account JSON file.     ensure_bucket: If True, raise NotFound if bucket does not exist and create_if_missing is False.     create_if_missing: If True, create the bucket if it does not exist.     location: Location for bucket creation (if needed).     storage_class: Storage class for bucket creation (if needed). Raises:     FileNotFoundError: If credentials_path is provided but does not exist.     google.api_core.exceptions.NotFound: If ensure_bucket is True and the bucket does not exist and create_if_missing is False.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.upload","title":"upload","text":"<pre><code>upload(\n    local_path: str, remote_path: str, metadata: Optional[Dict[str, str]] = None\n) -&gt; str\n</code></pre> <p>Upload a file to GCS. Args:     local_path: Path to the local file to upload.     remote_path: Path in the bucket to upload to.     metadata: Optional metadata to associate with the blob. Returns:     The gs:// URI of the uploaded file.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.download","title":"download","text":"<pre><code>download(\n    remote_path: str, local_path: str, skip_if_exists: bool = False\n) -&gt; None\n</code></pre> <p>Download a file from GCS to a local path. Args:     remote_path: Path in the bucket to download from.     local_path: Local path to save the file.     skip_if_exists: If True, skip download if local_path exists.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.delete","title":"delete","text":"<pre><code>delete(remote_path: str) -&gt; None\n</code></pre> <p>Delete a file from GCS. Args:     remote_path: Path in the bucket to delete.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.list_objects","title":"list_objects","text":"<pre><code>list_objects(\n    *, prefix: str = \"\", max_results: Optional[int] = None\n) -&gt; List[str]\n</code></pre> <p>List objects in the bucket with an optional prefix and limit. Args:     prefix: Only list objects with this prefix.     max_results: Maximum number of results to return. Returns:     List of blob names (paths) in the bucket.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.exists","title":"exists","text":"<pre><code>exists(remote_path: str) -&gt; bool\n</code></pre> <p>Check if a blob exists in the bucket. Args:     remote_path: Path in the bucket to check. Returns:     True if the blob exists, False otherwise.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.get_presigned_url","title":"get_presigned_url","text":"<pre><code>get_presigned_url(\n    remote_path: str, *, expiration_minutes: int = 60, method: str = \"GET\"\n) -&gt; str\n</code></pre> <p>Get a presigned URL for a blob in the bucket. Args:     remote_path: Path in the bucket.     expiration_minutes: Minutes until the URL expires.     method: HTTP method for the URL (e.g., 'GET', 'PUT'). Returns:     A presigned URL string.</p>"},{"location":"storage/api/#mindtrace.storage.GCSStorageHandler.get_object_metadata","title":"get_object_metadata","text":"<pre><code>get_object_metadata(remote_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get metadata for a blob in the bucket. Args:     remote_path: Path in the bucket. Returns:     Dictionary of metadata for the blob, including name, size, content_type, timestamps, and custom metadata.</p>"},{"location":"storage/api/#mindtrace.storage.base","title":"base","text":""},{"location":"storage/api/#mindtrace.storage.base.BulkOperationResult","title":"BulkOperationResult","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Result of a bulk operation.</p> <p>Attributes:</p> Name Type Description <code>succeeded</code> <code>List[str]</code> <p>List of successfully processed file paths.</p> <code>failed</code> <code>List[Tuple[str, str]]</code> <p>List of tuples (file_path, error_message) for failed operations.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler","title":"StorageHandler","text":"<pre><code>StorageHandler(*args, **kwargs)\n</code></pre> <p>               Bases: <code>MindtraceABC</code>, <code>ABC</code></p> <p>Abstract interface all storage providers must implement.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.upload","title":"upload  <code>abstractmethod</code>","text":"<pre><code>upload(\n    local_path: str, remote_path: str, metadata: Optional[Dict[str, str]] = None\n) -&gt; str\n</code></pre> <p>Upload a file from local_path to remote_path in storage. Args:     local_path: Path to the local file to upload.     remote_path: Path in the storage backend to upload to.     metadata: Optional metadata to associate with the file. Returns:     The remote path or URI of the uploaded file.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.download","title":"download  <code>abstractmethod</code>","text":"<pre><code>download(\n    remote_path: str, local_path: str, skip_if_exists: bool = False\n) -&gt; None\n</code></pre> <p>Download a file from remote_path in storage to local_path. Args:     remote_path: Path in the storage backend to download from.     local_path: Local path to save the downloaded file.     skip_if_exists: If True, skip download if local_path exists.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.delete","title":"delete  <code>abstractmethod</code>","text":"<pre><code>delete(remote_path: str) -&gt; None\n</code></pre> <p>Delete a file at remote_path in storage. Args:     remote_path: Path in the storage backend to delete.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.upload_batch","title":"upload_batch","text":"<pre><code>upload_batch(\n    files: List[Tuple[str, str]],\n    metadata: Optional[Dict[str, str]] = None,\n    max_workers: int = 4,\n    on_error: str = \"raise\",\n) -&gt; BulkOperationResult\n</code></pre> <p>Upload multiple files concurrently. Args:     files: List of (local_path, remote_path) tuples to upload.     metadata: Optional metadata to associate with each file.     max_workers: Number of parallel upload workers.     on_error: 'raise' to raise on first error, 'skip' to continue on errors. Returns:     BulkOperationResult with succeeded and failed uploads.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.download_batch","title":"download_batch","text":"<pre><code>download_batch(\n    files: List[Tuple[str, str]],\n    max_workers: int = 4,\n    skip_if_exists: bool = False,\n    on_error: str = \"raise\",\n) -&gt; BulkOperationResult\n</code></pre> <p>Download multiple files concurrently. Args:     files: List of (remote_path, local_path) tuples to download.     max_workers: Number of parallel download workers.     skip_if_exists: If True, skip files that already exist locally.     on_error: 'raise' to raise on first error, 'skip' to continue on errors. Returns:     BulkOperationResult with succeeded and failed downloads.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.upload_folder","title":"upload_folder","text":"<pre><code>upload_folder(\n    local_folder: str,\n    remote_prefix: str = \"\",\n    include_patterns: Optional[List[str]] = None,\n    exclude_patterns: Optional[List[str]] = None,\n    metadata: Optional[Dict[str, str]] = None,\n    max_workers: int = 4,\n    on_error: str = \"raise\",\n) -&gt; BulkOperationResult\n</code></pre> <p>Upload all files in a local folder recursively. Args:     local_folder: Path to the local folder to upload.     remote_prefix: Prefix to prepend to all remote paths.     include_patterns: List of glob patterns to include.     exclude_patterns: List of glob patterns to exclude.     metadata: Optional metadata to associate with each file.     max_workers: Number of parallel upload workers.     on_error: 'raise' to raise on first error, 'skip' to continue on errors. Returns:     BulkOperationResult with succeeded and failed uploads.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.download_folder","title":"download_folder","text":"<pre><code>download_folder(\n    remote_prefix: str,\n    local_folder: str,\n    max_workers: int = 4,\n    skip_if_exists: bool = False,\n    on_error: str = \"raise\",\n) -&gt; BulkOperationResult\n</code></pre> <p>Download all objects with a given prefix to a local folder. Args:     remote_prefix: Prefix of remote objects to download.     local_folder: Local folder to download files into.     max_workers: Number of parallel download workers.     skip_if_exists: If True, skip files that already exist locally.     on_error: 'raise' to raise on first error, 'skip' to continue on errors. Returns:     BulkOperationResult with succeeded and failed downloads.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.list_objects","title":"list_objects  <code>abstractmethod</code>","text":"<pre><code>list_objects(\n    *, prefix: str = \"\", max_results: Optional[int] = None\n) -&gt; List[str]\n</code></pre> <p>List objects in storage with an optional prefix and limit. Args:     prefix: Only list objects with this prefix.     max_results: Maximum number of results to return. Returns:     List of object paths.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.exists","title":"exists  <code>abstractmethod</code>","text":"<pre><code>exists(remote_path: str) -&gt; bool\n</code></pre> <p>Check if a remote object exists in storage. Args:     remote_path: Path in the storage backend to check. Returns:     True if the object exists, False otherwise.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.get_presigned_url","title":"get_presigned_url  <code>abstractmethod</code>","text":"<pre><code>get_presigned_url(\n    remote_path: str, *, expiration_minutes: int = 60, method: str = \"GET\"\n) -&gt; str\n</code></pre> <p>Get a presigned URL for a remote object. Args:     remote_path: Path in the storage backend.     expiration_minutes: Minutes until the URL expires.     method: HTTP method for the URL (e.g., 'GET', 'PUT'). Returns:     A presigned URL string.</p>"},{"location":"storage/api/#mindtrace.storage.base.StorageHandler.get_object_metadata","title":"get_object_metadata  <code>abstractmethod</code>","text":"<pre><code>get_object_metadata(remote_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get metadata for a remote object. Args:     remote_path: Path in the storage backend. Returns:     Dictionary of metadata for the object.</p>"},{"location":"storage/api/#mindtrace.storage.gcs","title":"gcs","text":""},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler","title":"GCSStorageHandler","text":"<pre><code>GCSStorageHandler(\n    bucket_name: str,\n    *,\n    project_id: Optional[str] = None,\n    credentials_path: Optional[str] = None,\n    ensure_bucket: bool = True,\n    create_if_missing: bool = False,\n    location: str = \"US\",\n    storage_class: str = \"STANDARD\"\n)\n</code></pre> <p>               Bases: <code>StorageHandler</code></p> <p>A thin wrapper around <code>google-cloud-storage</code> APIs.</p> <p>Initialize a GCSStorageHandler. Args:     bucket_name: Name of the GCS bucket.     project_id: Optional GCP project ID.     credentials_path: Optional path to a service account JSON file.     ensure_bucket: If True, raise NotFound if bucket does not exist and create_if_missing is False.     create_if_missing: If True, create the bucket if it does not exist.     location: Location for bucket creation (if needed).     storage_class: Storage class for bucket creation (if needed). Raises:     FileNotFoundError: If credentials_path is provided but does not exist.     google.api_core.exceptions.NotFound: If ensure_bucket is True and the bucket does not exist and create_if_missing is False.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.upload","title":"upload","text":"<pre><code>upload(\n    local_path: str, remote_path: str, metadata: Optional[Dict[str, str]] = None\n) -&gt; str\n</code></pre> <p>Upload a file to GCS. Args:     local_path: Path to the local file to upload.     remote_path: Path in the bucket to upload to.     metadata: Optional metadata to associate with the blob. Returns:     The gs:// URI of the uploaded file.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.download","title":"download","text":"<pre><code>download(\n    remote_path: str, local_path: str, skip_if_exists: bool = False\n) -&gt; None\n</code></pre> <p>Download a file from GCS to a local path. Args:     remote_path: Path in the bucket to download from.     local_path: Local path to save the file.     skip_if_exists: If True, skip download if local_path exists.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.delete","title":"delete","text":"<pre><code>delete(remote_path: str) -&gt; None\n</code></pre> <p>Delete a file from GCS. Args:     remote_path: Path in the bucket to delete.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.list_objects","title":"list_objects","text":"<pre><code>list_objects(\n    *, prefix: str = \"\", max_results: Optional[int] = None\n) -&gt; List[str]\n</code></pre> <p>List objects in the bucket with an optional prefix and limit. Args:     prefix: Only list objects with this prefix.     max_results: Maximum number of results to return. Returns:     List of blob names (paths) in the bucket.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.exists","title":"exists","text":"<pre><code>exists(remote_path: str) -&gt; bool\n</code></pre> <p>Check if a blob exists in the bucket. Args:     remote_path: Path in the bucket to check. Returns:     True if the blob exists, False otherwise.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.get_presigned_url","title":"get_presigned_url","text":"<pre><code>get_presigned_url(\n    remote_path: str, *, expiration_minutes: int = 60, method: str = \"GET\"\n) -&gt; str\n</code></pre> <p>Get a presigned URL for a blob in the bucket. Args:     remote_path: Path in the bucket.     expiration_minutes: Minutes until the URL expires.     method: HTTP method for the URL (e.g., 'GET', 'PUT'). Returns:     A presigned URL string.</p>"},{"location":"storage/api/#mindtrace.storage.gcs.GCSStorageHandler.get_object_metadata","title":"get_object_metadata","text":"<pre><code>get_object_metadata(remote_path: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get metadata for a blob in the bucket. Args:     remote_path: Path in the bucket. Returns:     Dictionary of metadata for the blob, including name, size, content_type, timestamps, and custom metadata.</p>"}]}